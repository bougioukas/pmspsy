[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Statistical Methods for Analyzing Empirical Data",
    "section": "",
    "text": "Welcome!\nThis course introduces postgraduate students to advanced statistical methods used in the quantitative social, educational, and behavioral sciences. Students will learn:\n\nData management.\nAnalysis of Variance (ANOVA) Designs.\nMultiple Linear Regression. Interaction between variables.\nPrincipal Components Analysis and Factor Analysis.\nMediation and Path Analysis.\nBasic Structural Equation Modeling (SEM).\nPrinciples of Evidence Synthesis (Systematic reviews and Meta-analysis).\n\n \nThe students will also learn about the principles of data visualization and statistical software JAMOVI.\n     \nSources for reading\n\nAnalysis of Variance Designs: A Conceptual and Computational Approach with SPSS and SAS\nLearning Statistics with Jamovi",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "",
    "text": "1.1 Why Jamovi?\nJamovi is a new fee open “3rd generation” statistical software that is built on top of the programming language R (Figure 1.1). Designed from the ground up to be easy to use, Jamovi is a compelling alternative to costly statistical products such as SPSS and SAS.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#why-jamovi",
    "href": "introduction.html#why-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "",
    "text": "Figure 1.1: Jamovi is free and open statistical software\n\n\n\n\n\n\n\n\n\nSome other advantages are:\n\n\n\n\nUser-friendly point-and-click interface.\nDisplays informative tables and clear visuals.\nSupports add-on modules for advanced statistical analysis.\nAllows integration with R.\nProvides access to a user guide and community resources on the Jamovi website.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#downloading-and-installing-jamovi",
    "href": "introduction.html#downloading-and-installing-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.2 Downloading and installing Jamovi",
    "text": "1.2 Downloading and installing Jamovi\nJamovi is available for Windows (64-bit), macOS, Linux and ChromeOS. Installation on desktop is quite straight-forward. Just go to the Jamovi download page https://www.jamovi.org/download.html, and download the latest version (current release) for your operating system.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#navigating-jamovi",
    "href": "introduction.html#navigating-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.3 Navigating Jamovi",
    "text": "1.3 Navigating Jamovi\nWhen jamovi first opens, we will see a screen something like in Figure 1.2.\n\n\n\n\n\n\n\n\nFigure 1.2: Jamovi starts up!.\n\n\n\n\n\nTo the left is the spreadsheet view, and to the right is where the results of statistical tests appear. Down the middle is a bar separating these two regions, and this can be dragged to the left or the right to change their sizes.\n \nLet’s take a quick look at the Jamovi Main Menu, referred to hereafter as the Menu, as shown in Figure 1.3. This Menu is displayed at the very top of the Jamovi screen:\n\n\n\n\n\n\n\n\nFigure 1.3: The menu bar provides access to all functions of the program.\n\n\n\n\n\nThere are six tabs in the Menu (from left to right): 1. File (a layer with three horizontal levels \\(\\equiv\\)), 2. Variables, 3. Data, 4. Analyses, 5. Edit, and 6. Settings (the three dots \\(\\vdots\\) at the top right of the window) tabs. A toolbar appears whenever we click on a Menu tab (Table 1.1).\n \n\n\n\nTable 1.1: Menu and toolbars of Jamovi\n\n\n\n\n\n\n\n\n\nMenu tab\nToolbar\n\n\n\n\n\nFile tab (\\(\\equiv\\))\nThe file tab  allows us to open/import existing files, save and export our files.\n\n\n\n\n\nVariables tab\nThis allows us to view and search our variables in a list view.\n\n\nThis view allows us to easily navigate our variables and do the following:\n\nSearch for a variable by scrolling through the list or search for one by name.\nEdit the variable names and descriptions by double-clicking in the relevant field.\nEdit our variable details by double-clicking on the data symbol (the screen will appear for us to add all the necessary information).\nCreate a new variable by clicking on the in the bottom right corner. |\n\n\n\n\nData tab\nHere we will see our raw data which are organised like Excel in rows and columns. We can also manipulate our data and add new variables when necessary.\n\n\nSpecifically, this tab allows us to do the following:\n\nRename and add details to existing variables. Click on the Setup button, or double-click on the variable we want to manage.\nCompute and transform variables\nAdd and/or Delete variables (columns)\nAdd Filters\nAdd and/or Delete Rows\n\n\n\n\nAnalyses tab\nIt includes the available statistical analyses that can be performed by Jamovi.\n\n\nWe will spend most of our time in the Analyses Tab. The following six modules are pre-installed:\n\nExploration\nT-Tests\nANOVA\nRegression\nFrequencies\nFactor\n\nFor example, if we want to perform regression analysis, we simply click the ’’Regression” button.\nAll other modules need to be installed using the Modules button (Plus button) in our top-right  |\n\n\n\nEdit tab\nIt includes a toolbar similar to a word processor.\n\n\nWe can add extra information to our results using the buttons that are very similar to what we would find in Word (though there are fewer options).\n\n\n\nSettings tab\n(the three dots \\({\\vdots}\\) at the top right of the window)\n\nIt includes the application settings that can be manged by the users according to their preferences.\n\n\nWe can apply our preferences for a number of settings such as:\n\nHow many decimal numbers we want.\nIf we want to learn R, we can also display the R syntax.\nOur graph color scheme.\nOur default missing value.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#types-of-variables-in-jamovi",
    "href": "introduction.html#types-of-variables-in-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.4 Types of Variables in Jamovi",
    "text": "1.4 Types of Variables in Jamovi\nData variables can be one of four measure types:\n\n Nominal: This type is for nominal categorical variables.\n Ordinal: This type is for ordinal categorical variables.\n Continuous : this type is for variables with numeric values which are considered to be of Interval or Ratio scales.\n ID: This will usally be our first column. This can be text or numbers, but it should be unique to each row.\n\n \nAdditionally, data variables can be one of three data types:\n\nInteger: These are full numbers e.g. 1, 2, 3, … 100, etc. - Integers can be used for all three measure types . When used for Nominal/Ordinal data numbers will represent labels e.g. male=1; female=2.\nDecimal: These are numbers with decimal points. e.g. 1.3, 5.6, 7.8, etc. - This will usually only be used for continuous data.\nText: This can be used for ordinal and nominal data.\n\nThe measure types are designated by the symbol in the header of the variable’s column. Note that some combinations of data-type and measure-type don’t make sense, and Jamovi won’t let us choose these.\n\n\n\nTable 1.2: Types of data and measures\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasure\n\n\n\n\n\nData\nNominal\nOrdinal\nContinuous\n\n\nInteger\n\\({\\checkmark}\\)\n\\({\\checkmark}\\)\n\\({\\checkmark}\\)\n\n\nDecimal\n\n\n\\({\\checkmark}\\)\n\n\nText\n\\({\\checkmark}\\)\n\\({\\checkmark}\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#importing-data",
    "href": "introduction.html#importing-data",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.5 Importing data",
    "text": "1.5 Importing data\n\n1.5.1 The dataset\nIt is possible to simply begin typing values into the Jamovi spreadsheet as we would with any other spreadsheet software. Alternatively, existing datasets in a range of formats (OMV, Excel, CSV, SPSS, R data, Stata, SAS) can be opened in Jamovi. We will use the following dataset as an example (Figure 1.4).\n\n\n\n\n\n\n\n\nFigure 1.4: Table with raw data.\n\n\n\n\n(NOTE: You can find other formats of the data (OMV, Excel) at the link: https://osf.io/gvctz/).\n   \nThe meta-data (data about the data) for this dataset are as following:\n\nsex: sex (1 = male, 2 = female).\nage: age in years.\ntime_spend: hours spent on social media.\n\\(q_1 ... q_{10}\\): Ten questions (items) of Rosenberg Self-Esteem Scale (RSES). The 10 items are answered on a four point scale ranging from strongly agree to strongly disagree coded as follows: Strongly Agree = 3, Agree = 2, Disagree = 1, and Strongly Disagree = 0.\n\n\nPositively worded Items 1, 2, 4, 6, and 7.\nNegatively worded Items 3, 5, 8, 9, and 10 (codes should be reversed).\n\n\n\n\n\n\n\nFigure 1.5: Codes should be reversed for the negatively worded Items.\n\n\n\nThe scale ranges from 0-30 (we add the scores for all items), with 30 indicating the highest total score possible.\nMore information for the RSES: Rosenberg Self-Esteem Scale.\n\n\n1.5.2 Opening the file\nTo open this csv file, click on the File tab  at the top left hand corner (just left of the Variables tab) (Figure 1.6).\n\n\n\n\n\n\nFigure 1.6: Click on the File tab\n\n\n\nThis will open the menu shown in Figure 1.7. Select ‘Open’ and then ‘This PC’. Choose the downloaded file from the files listed on ‘Browse’ which are stored on our computer folders:\n\n\n\n\n\n\n\n\nFigure 1.7: Open an existing file stored on our computer into Jamovi.\n\n\n\n\n\n \nThe flowchart of the process is:\n\n\n\n\n\nflowchart LR\n  A(File tab) -.-&gt; B(Open) -.-&gt; C(This PC) -.-&gt; D(Browse) -.-&gt; E(Open \\n 'the downloaded file')\n\n\n\n\n\n\n \nWe should see data now in the Spreadsheet view (Figure 1.8).\n\n\n\n\n\n\n\n\nFigure 1.8: Our dataset.\n\n\n\n\n\nAs we can see this is a data set with 258 observations and 13 variables. JAMOVI has classified all the variables as nominal ; however, only the sex variable is actually nominal.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#adding-labels-to-codes",
    "href": "introduction.html#adding-labels-to-codes",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.6 Adding labels to codes",
    "text": "1.6 Adding labels to codes\n\nsex variable\n\nThe first variable, named sex, is a categorical variable coded as 1 for males and 2 for females. Notice that it is correctly identified as a nominal  variable in Jamovi.\nWe can assign labels to numerically coded values of categorical variables, such as sex, by accessing the data variable settings. One way to achieve this is by double-clicking on the variable name sex, which opens the additional menu of variable settings at the top of the Jamovi screen (Figure 1.9).\n\n\n\n\n\n\nFigure 1.9: An additional menu appears at the top of the Jamovi screen after double-clicking on the variable name sex.\n\n\n\n \nIn this menu, we will find the Levels setup. Here, we can specify the labels that should appear for each category level. Click on the number “1” in the Levels box to edit its label, changing it from “1” to “male”. Similarly, click on the number “2” and change it to “female” (Figure 1.10).\n\n\n\n\n\n\nFigure 1.10: Adding labels to numerically coded Values.\n\n\n\nNotice how the numbers “1” and “2” have moved to the lower right under the text we’re typing, allowing us to still see which label corresponds to each numerical code. Press Enter or click anywhere outside the labels box to save these labels.\nWe close the variable settings by pressing the arrow in the top-right corner .",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#changing-the-measure-type",
    "href": "introduction.html#changing-the-measure-type",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.7 Changing the measure type",
    "text": "1.7 Changing the measure type\nNext, we will change the measure type of age and time_spent variables from nominal to continuous.\n\nage variable\n\nDouble-click on the variable name age to open the data variable settings, as shown in Figure 1.11:\n\n\n\n\n\n\nFigure 1.11: Data variable menu settings for the age variable.\n\n\n\n \nFrom the drop-down list of “Measure type” we select the continuous type , as shown in Figure 1.12.\n\n\n\n\n\n\nFigure 1.12: Change the measure type of age from nominal to continuous. .\n\n\n\n \n\ntime_spent variable\n\nInstead of closing the data variable menu using the arrow in the top-right corner, we can click on the  to proceed to the next variable setting, time_spent. As before, we select the continuous type for this variable from the “Measure type” drop-down list, as shown in Figure 1.13.\n\n\n\n\n\n\nFigure 1.13: Change the measure type of time_spent from nominal to continuous.\n\n\n\nWe close the variable settings by pressing the arrow in the top-right corner .\n \n\nq1 to q10 variables\n\nFinally, we will change the measure type of q1 to q10 variables from nominal to ordinal. In the Variables tab, we select the checkboxes for the q1 through q10 variables, as shown in Figure 1.14.\n\n\n\n\n\n\nFigure 1.14: Change the measure type of time_spent from nominal to continuous.\n\n\n\n \nAfter that, we click on the Edit button  to open the data variable settings, as shown in Figure 1.15.\n\n\n\n\n\n\nFigure 1.15: Change the measure type of time_spent from nominal to continuous.\n\n\n\n \nFrom the drop-down list of “Measure type” we select the ordinal type , as shown in Figure 1.16.\n\n\n\n\n\n\nFigure 1.16: Change the measure type of q1 to q10 from nominal to ordinal.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#filtering-rows",
    "href": "introduction.html#filtering-rows",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.8 Filtering rows",
    "text": "1.8 Filtering rows\nNext, we select the Filters button  from the Data tab. This opens the “Row FILTERS” view at the top of the Jamovi screen where we can add a filter called “Filter 1” (Figure 1.17). Let’s say that we want to study only the adults from the participants in this survey.\n\nSimple condition\n\nIn order to access functions, press the  icon in the filter settings and from “VARIABLES” double-click on age (or we just type the variable name but if the variable has a space, we must use ticks '' around the variable name). Then type the condition age &gt;= 18 in the formula box and press ENTER from the keyboard (Figure 1.17).\n\n\n\n\n\n\nFigure 1.17: Adding a filter.\n\n\n\n \n\n\n\n\n\n\nRelational (or comparison) operators in Jamovi\n\n\n\n\n\n\nsymbol\nread as\n\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n==\nequal to\n\n\n&lt;=\nless than or equal to\n\n\n&gt;=\ngreater than or equal to\n\n\n!=\nnot equal to\n\n\n\n\n\n \nNotice that a column named Filter 1 has been added to the Spreadsheet view. Cells that meet the condition age &gt;= 18 are checked with a green tick , while the rest have a red x symbol . Lines with an X are grayed out indicating that these observations are now outside of the current dataset.\nThere is also a switch where we can activate  or inactivate  the filter (note that an inactivate filter will remain visible and can be toggled to active at any time).\nIt is also possible to hide all filter columns by clicking on the eye symbol  of the filters. In this case, all filters and the filtered data will remain active but will be invisible.\nFinally, if we want to delete the filter permanently, we can click on the  of the filter .\n \n\nMultiple conditions\n\nBut we can do more complicated filters than this! Let’s say that we’re interested in the adult females. In fact we can specify this in three ways:\na) by using the and operator in “Filter 1” which means that both conditions (adults and females) in the expression must be true at the same time. Therefore, we type the expression age &gt;= 18 and sex == 'female' (Figure 1.18):\n\n\n\n\n\n\nFigure 1.18: Combining conditions with “and” operator in one expression.\n\n\n\nNote that in the above expression we can also use double quotes around the \"female\" (i.e., age &gt;= 18 and sex == \"female\") or even the coded value (i.e., age &gt;= 18 and sex == 2).\nb) by adding the second condition (i.e. sex == \"female\") as another expression to “Filter 1” (by clicking the small + beside the first expression) (Figure 1.19):\n\n\n\n\n\n\nFigure 1.19: Multiple expressions in the same filter.\n\n\n\nThis additional expression comes to be represented with its own column F1(2) (Figure 1.19), and by looking at the ticks and crosses, we can see which expression is responsible for excluding each row.\nc) adding a new “Filter 2” (by selecting the large + to the left of the filters dialog box) (Figure 1.20). In this case, we can activate or inactivate the filters separately.\n\n\n\n\n\n\nFigure 1.20: Multiple expressions using multiple filters.\n\n\n\nWe close the filter settings by pressing the arrow in the top-right corner .\n\n\n\n\n\n\nImportant\n\n\n\nFilters in Jamovi exclude the rows for which the expression is not true. When filters are active, all results will be based on the filtered data. If we want to see unfiltered results we will either need to delete the filter or toggle it to inactive.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#transforming-a-variable",
    "href": "introduction.html#transforming-a-variable",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.9 Transforming a variable",
    "text": "1.9 Transforming a variable\n\n1.9.1 Transform a quantitative variable into a qualitative variable\nSometimes it can be useful to convert a quantitative variable into a qualitative variable with levels. For example, the time_spent can be categorized as follows:\n\nless than or equal to 3  “0-3”\n4 to 7  “4-7”\n8 to 11  “8-11”\ngreater than 11  “&gt;11”\n\nSelect time_spent variable and click the Transform button  from the toolbar of the Data tab. This opens the “TRANSFORMED VARIABLE” view, where we can set the name of the transformed variable such as time_spent2 and create the transformation. To do this, select the source variable, the time_spent in this case, in the Source Variable field and create a new transformation using transform field (Figure 1.21), which is initially set to ‘none’.\n\n\n\n\n\n\nFigure 1.21: Setting up a new transformation of a variable.\n\n\n\n \nThis opens the “TRANSFORM” view where Jamovi gives each transformation a name (e.g., Transform 1; if we want we can change it). This allows us to use it again later on other variables if we wish. We can also add a description (Figure 1.22).\n\n\n\n\n\n\nFigure 1.22: Box for adding conditions to the transformation.\n\n\n\nNow we need to add conditions. Jamovi uses simple if ... else statements and executes each statement starting from the top. So let’s start!\nFirst, select + Add recode condition. Second, we need to fill the boxes with the information as follows (Figure 1.23):\n\nThe $source is the variable we want to transform (here time_spent)- don’t change this.\nSelect the appropriate comparison operator (here &lt;= )\nIn the next box, we will put the time_spent value we want as the cut off point (e.g., 3).\nAfter the use, add our new label (here '0-3'). If we are using text we must enclose it in '...'\n\n\n\n\n\n\n\nFigure 1.23: Adding the first condition (0-3).\n\n\n\n \nWe can add as many conditions as we want by selecting + Add recode condition. This will add a new if $source line into the box (Figure 1.24). Remember they will be executed in order.\n\n\n\n\n\n\nFigure 1.24: Adding the second condition (4-7).\n\n\n\n \n\n\n\n\n\n\nFigure 1.25: Adding the third condition (8-11).\n\n\n\n \nFinally, after the else use box just add the label for the data that does not meet the above conditions (here '&gt;11'), as shown in Figure 1.26.\n\n\n\n\n\n\nFigure 1.26: Adding the final label for the data that does not meet the above conditions (&gt;11).\n\n\n\n \n\n\n1.9.2 Reverse scoring of items\nTo compute the total score for all items of the RSES, we first need to reverse the scores of the negatively worded questions (3, 5, 8, 9, and 10). To do this, we can follow these simple steps.\nIn the Variables tab, we select the checkboxes for the q3, q5, q8, q9, and q10 variables, as shown in Figure 1.27.\n\n\n\n\n\n\nFigure 1.27: Select the variables to be reversed.\n\n\n\n \nAfter that, we click on the Transform button ) from the toolbar of the Variables tab to open the Transform variable settings. Then, we Create New Transform, as shown in Figure 1.28.\n\n\n\n\n\n\nFigure 1.28: Open the Transform variable settings.\n\n\n\n \nIn the Transform view, we enter _R as a suffix for the variable names and specify 3-$source in the condition box, as shown in Figure 1.29.\n\n\n\n\n\n\nFigure 1.29: Transform variable settings.\n\n\n\n\n\n\n\n\n\nFigure 1.30: Data with the reversed variables.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#compute-a-new-variable",
    "href": "introduction.html#compute-a-new-variable",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.10 Compute a new variable",
    "text": "1.10 Compute a new variable\nFinally, we compute each participant’s total score (ranging from 0 to 30) based on their responses to the 10 questions of the Rosenberg Self-Esteem Scale.\nAdding computed variables to a Jamovi spreadsheet is straightforward. Click on the Compute button ) from the toolbar of the Data tab. An empty column has been created at the end of our dataset (Figure 1.31). The black dot symbol in the right of the column header indicates that this is a computed variable.\n\n\n\n\n\n\nFigure 1.31: Compute a new variable.\n\n\n\nTo set up the computed variable, either double-click the column header, or click the Setup button ) in the Data tab. This opens the “COMPUTED VARIABLE” view, where we can name the computed variable score. Next, we select the SUM function from the available options for use in the Formula box. Finally, we add the q-variables in the formula separated by comma (note that we must use the reversed variables in the sum) and we press ENTER (Figure 1.32).\n\n\n\n\n\n\nFigure 1.32: Computation of the total score.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "anova1.html",
    "href": "anova1.html",
    "title": "2  ANOVA Designs (1)",
    "section": "",
    "text": "2.1 One-way between-subjects Analysis of Variance (One-way ANOVA)\nThe one-way between-subjects analysis of variance (one-way ANOVA) is used to compare more than two independent (unrelated or unpaired) samples. We may think of it as an extension of Student’s t-test.\nAlthough, ANOVA can detect whether there are mean differences between groups, it does not identify which groups are different from the others. At first, we might consider to compare all groups in pairs with t-tests. However, this approach can lead to incorrect conclusions due to the multiple comparisons problem. Each additional t-test increases the likelihood of making at least one Type I error (false positive) across the set (often called a family) of comparisons.\nThis is why, after an ANOVA test concludes that at least one difference exists between groups (omnibus analysis), we should perform statistical tests that account for the number of comparisons (post hoc tests). Some of the most commonly used post hoc tests include the Tukey test, Bonferroni correction, and Holm test.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ANOVA Designs (1)</span>"
    ]
  },
  {
    "objectID": "anova1.html#one-way-between-subjects-analysis-of-variance-one-way-anova",
    "href": "anova1.html#one-way-between-subjects-analysis-of-variance-one-way-anova",
    "title": "2  ANOVA Designs (1)",
    "section": "",
    "text": "2.1.1 Importing data\nThe SAT is used by a wide range of colleges and universities as part of the application process for college admission. Assume we are interested in the effect of preparation time on SAT performance.\nIn this example, we have five student groups, each containing seven cases. The groups contain students who have studied for either zero, two, four, six, or eight months prior to taking the SAT.\n\n\n\n\n\n\n\n\nFigure 2.1: Table with raw data.\n\n\n\n\nOpen the dataset named “sat” from the file tab in the menu (Figure 2.2).\n\n\n\n\n\n\nFigure 2.2: The sat dataset.\n\n\n\n \nWe prepare the data as follows (Figure 2.3):\n\n\n\n\n\n\nFigure 2.3: The modified dataset.\n\n\n\n\n\n2.1.2 Research question\nA quaziexperimental study explored the effect of preparation time on SAT performance, with students having studied for different duration (zero, two, four, six, or eight months). The question of interest is whether the mean SAT score differs across these preparation times.\n\n\n2.1.3 Hypothesis testing for the one-way ANOVA test\n\n\n\n\n\n\nNull hypothesis and alternative hypothesis\n\n\n\n\n\\(H_0\\): all group means are equal (the means of SAT in the five conditions are equal: \\(\\mu_{1} = \\mu_{2} = \\mu_{3} = \\mu_{4} = \\mu_{5}\\))\n\\(H_1\\): at least one group mean differs from the others (there is at least one group with mean SAT score different from the others)\n\n\n\n\n\n2.1.4 Assumptions\n\nThe dependent variable, satscore, should be approximately normally distributed for all groups. To increase the number of observations used in assessing normality, we often examine the residuals from the ANOVA model for the entire dataset using a normal quantile plot of the standardized residuals (Normal Q-Q plot).\nThe data in groups have similar variance (also named as homogeneity of variance or homoscedasticity).\n\n\n\n2.1.5 Descriptive statistics and plots\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Exploration) -.-&gt; B(Descriptives)\n\n\n\n\n\n\nas shown below in Figure 2.4.\n\n\n\n\n\n\nFigure 2.4: Select exploration and Desctriptives.\n\n\n\nHighlight satscore in the left panel and click it (or drug it) over the the Variables. Then highlight the group and click it over the Split by (Figure 2.5). Additionally, select variables across rows.\n\n\n\n\n\n\nFigure 2.5: Descriptive dialog box.\n\n\n\n \nThe default descriptive statistics are shown in Figure 2.6: the mean, median, standard deviation, minimum and maximum.\n\n\n\n\n\n\nFigure 2.6: Descriptive statistics.\n\n\n\nTo generate boxplots, click the Plots, and check Box plot, Data, and Mean.\n\n\n\n\n\n\nFigure 2.7: Selection of boxplots.\n\n\n\n\n\n\n\n\n\nFigure 2.8: Boxplots.\n\n\n\nThe plot suggests that the mean SAT score (black square) increases as the months progress, suggesting a positive association between time and SAT score improvement.\n\n\n2.1.6 ANOVA (omnibus analysis)\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(ANOVA) -.-&gt; C(ANOVA)\n\n\n\n\n\n\nas shown below in Figure 4.4.\n\n\n\n\n\n\nFigure 2.9: Conducting ANOVA test in Jamovi. In the menu at the top, choose Analyses -&gt; ANOVA  -&gt; ANOVA.\n\n\n\nNOTE: There is also a One-Way ANOVA menu option. This version of the ANOVA analysis does not have all the options we want so we are not going to use this method, so we will run our analysis via “ANOVA” rather than “One-Way ANOVA”.\n \nIn the ANOVA dialog box, highlight satscore in the left panel and click it (or drug it) over the the Dependent Variable. Then highlight the group and click it over the Fixed Factors (Figure 2.10). Additionally, check \\(\\eta^2\\).\n\n\n\n\n\n\nFigure 2.10: ANOVA dialog box.\n\n\n\n \nAssumptions Checks\nClick the Assumptions Checks, and check Homogeneity test, Normality test, and Q-Q plot (Figure 4.9).\n\n\n\n\n\n\nFigure 2.11: Assumption selections for ANOVA.\n\n\n\n\nNormality of distributions\n\n\n\n\n\n\n\nRemember: Hypothesis testing for Shapiro-Wilk test for normality\n\n\n\n\\(H_{0}\\): the data came from a normally distributed population.\n\\(H_{1}\\): the data tested are not normally distributed.\n\nIf p − value &lt; 0.05, reject the null hypothesis, \\(H_{0}\\).\nIf p − value ≥ 0.05, do not reject the null hypothesis, \\(H_{0}\\).\n\n\n\n\n\n\n\n\n\nFigure 2.12: Normality test.\n\n\n\nThe Shapiro-Wilk test of normality suggests normal distributions (p=0.56 &gt; 0.05; \\(H_o\\) is not rejected).\n \n\n\n\n\n\n\nFigure 2.13: Normal Q-Q plot.\n\n\n\nThe data points mostly fall along the diagonal line, indicating that the residuals are approximately normally distributed. Additionally, there are no extreme deviations or systematic patterns, suggesting that normality holds well.\n \n\nEquality of variances\n\n\n\n\n\n\n\nRemember: Hypothesis testing for Levene’s test for equality of variances\n\n\n\n\\(H_{0}\\): the variances of WeightLoss in all groups are equal (\\(σ^2_1=σ^2_2=σ^2_3=σ^2_4=σ^2_5\\))\n\\(H_{1}\\): the variances of satscore differ between groups (\\(σ^2_i\\neq σ^2_j\\), where \\(i,j= 1, 2, 3, 4, 5\\) and \\(i\\neq j\\))\n\nIf p − value &lt; 0.05, reject the null hypothesis, \\(H_{0}\\).\nIf p − value ≥ 0.05, do not reject the null hypothesis, \\(H_{0}\\).\n\n\n\n\n\n\n\n\n\nFigure 2.14: Levene’s test.\n\n\n\nSince p = 0.239 &gt; 0.05, the \\(H_0\\) of the Levene’s test is not rejected and the variances of the five conditions are comparable; in short, it appears that the assumption of homogeneity of variance is not violated.\n \nANOVA table\n\n\n\n\n\n\nFigure 2.15: Summary table of ANOVA.\n\n\n\n \nIn Figure 2.15, the F-statistic is calculated as follows:\n\\[F= \\frac{Mean \\ Square \\ between \\ groups}{Mean \\ Square \\ within \\ groups} = \\frac{Mean \\ Square \\ group}{Mean \\ Square \\ residuals} = \\frac{57624.3}{1325.7} = 43.467\\]\nNote that we compare this value to an F-distribution (F-test). The degrees of freedom in the numerator (df1) and the denominator (df2) are 4 and 30, respectively.\nThe p-value &lt; 0.001 (reject \\(H_0\\) of the ANOVA test). There is at least one condition with mean SAT score which is different from the other means.\nThis table also presents the eta squared (\\(\\eta^2 = 0.85\\)) , which expresses the proportion of variability explained by the group relative to the total variability:\n\\[\\eta^2 = \\frac{Sum \\ of \\ squares \\ group}{Total \\ sum \\ of \\ squares} = \\frac{230497}{230497 + 39771} = \\frac{230497}{270268}=0.85\\]\nA value of 0.85 (85%) means that 85% of the variation in SAT scores can be attributed to the preparation time and would be considered a large effect size. (NOTE: Whether the \\(\\eta^2\\) value is considered “high” or not is relative and depends on the research context).\n \n\n\n2.1.7 Post hoc tests\nClick the Post Hoc Tests, then highlight the group in the left panel and click it (or drug it) over the the right panel. Check Tukey correction.\n\n\n\n\n\n\nFigure 2.16: Post Hoc Tests panels.\n\n\n\n \n\n\n\n\n\n\nFigure 2.17: Post Hoc Tests (Tukey correction).\n\n\n\nFor example, the mean difference between zero months and two months is: 412.857 - 474.286 = -61.429, which is significant (p=0.028).\n \n\nInterpretation\nAn analysis of variance showed that the amount of preparation for the SAT in which students engaged appeared to significantly affect their performances on the test, F(4, 30) = 43.47, p &lt; 0.001, \\(\\eta^2 = 0.85\\). Post-hoc analyses with Tukey’s test, adjusting p-values for multiple comparisons, indicated that each additional two months of study up to six months was associated with significantly higher SAT scores. However, there was no significant difference in scores between the six month and eight month study groups.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ANOVA Designs (1)</span>"
    ]
  },
  {
    "objectID": "anova2.html",
    "href": "anova2.html",
    "title": "3  ANOVA Designs (2)",
    "section": "",
    "text": "3.1 One-way within-subjects Analysis of Variance (repeated one-way ANOVA)\nThe one-way repeated measures analysis of variance (also known as a within-subjects ANOVA) is an extension of the paired t-test designed to assess whether there are significant differences in the means of three or more related groups, such as comparing the difference between three or more time points.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA Designs (2)</span>"
    ]
  },
  {
    "objectID": "anova2.html#one-way-within-subjects-analysis-of-variance-repeated-one-way-anova",
    "href": "anova2.html#one-way-within-subjects-analysis-of-variance-repeated-one-way-anova",
    "title": "3  ANOVA Designs (2)",
    "section": "",
    "text": "3.1.1 Importing data\nIn hypothetical study, it is hoped that a certain drug will alleviate the intensity of symptoms of a certain disease. Symptom intensity was evaluated on a twelve-point scale with higher values indicating more intense symptoms. Two pre-treatment baseline measurements are made, the first a month prior to treatment and the second one week prior to treatment. Post-treatments measures of symptom intensity are made after one week, one month, and one year following administration of the drug. In this simplified example, we have eight patients in the study.\n\n\n\n\n\n\n\n\nFigure 3.1: Table with raw data.\n\n\n\n\nOpen the dataset named “symptoms” from the file tab in the menu (Figure 3.2).\n\n\n\n\n\n\nFigure 3.2: The symptoms dataset.\n\n\n\n \nWe prepare the data as follows (Figure 3.3):\n\n\n\n\n\n\nFigure 3.3: The modified dataset.\n\n\n\n\n\n3.1.2 Research question\nA study investigated the effect of a drug on symptom intensity in a specific disease, assessing eight patients before (two pre-test baseline measures) and after treatment (three post-test measures). The primary question is whether the mean symptom intensity score changed over time.\n\n\n3.1.3 Hypothesis testsing for the one-way repeated ANOVA test\n\n\n\n\n\n\nNull hypothesis and alternative hypothesis\n\n\n\n\n\\(H_0\\): all related group means are equal (the means of symptom intensity score in the five time points are equal: \\(\\mu_{1} = \\mu_{2} = \\mu_{3} = \\mu_{4} = \\mu_{5}\\))\n\\(H_1\\): at least one group mean differs from the others (there is at least one group with mean symptom intensity score different from the others)\n\n\n\n\n\n3.1.4 Assumptions\n\nThe data are normally distributed in all time points.\nThe variances of the differences between all possible pairs of within-subject conditions are equal (sphericity assumption).\n\n\n\n3.1.5 ANOVA (omnibus analysis)\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(ANOVA) -.-&gt; C(Repeated Measures ANOVA)\n\n\n\n\n\n\nas shown below in Figure 3.4.\n\n\n\n\n\n\nFigure 3.4: Conducting ANOVA test in Jamovi. In the menu at the top, choose Analyses -&gt; ANOVA  -&gt; Repeated Measures ANOVA.\n\n\n\n \nIn the repeated ANOVA dialog box, define the levels of the “RM Factor 1” which we will rename as time. Then, highlight the variables from pre1 to post3 in the left panel and click them (or drug them) to the Repeated Measure Cells. Additionally, check \\(\\eta^2\\) and Partial \\(\\eta^2\\) (Figure 3.5).\n\n\n\n\n\n\nFigure 3.5: Repeated ANOVA dialog box.\n\n\n\n \n\n\n3.1.6 Descriptive statistics and plots\n\n\n\n\n\n\nFigure 3.6: The estimated marginal means panels.\n\n\n\n\n\n\n\n\n\nFigure 3.7: Descriptive statistics.\n\n\n\n\n\n\n\n\n\nFigure 3.8: Plot with means.\n\n\n\nThe graph shows a clear reduction in mean symptom intensity after the treatment.\n \nAssumptions Checks\nClick on Assumptions Checks, select Sphericity tests, and Q-Q Plot (Figure 3.9).\n\n\n\n\n\n\nFigure 3.9: Assumption selections for repeated ANOVA.\n\n\n\n\nNormality of distributions\n\n\n\n\n\n\n\nFigure 3.10: Normal Q-Q plot.\n\n\n\n\nSphericity assumption\n\nThis assumption is usually checked with the Mauchly’s sphericity test, where null hypothesis states that the variances of the differences are equal (Figure 3.11).\n\n\n\n\n\n\nFigure 3.11: Assumption selections for repeated ANOVA.\n\n\n\nIn our example, the assumption of sphericity has not been met (p = 0.043). In this case, we have to correct the degrees of freedom in repeated ANOVA analysis.\nThere are two correction options \\(\\epsilon\\) available: Greenhouse-Geisser (GGe), or Huynh-Feldt (HFe) (Figure 3.12). The general recommendation is to use the Greenhouse-Geisser \\(\\epsilon\\) correction when it is less than 0.75; otherwise, we should use the Huynh-Feldt \\(\\epsilon\\) correction.\nAs the GGe value is less than 0.75, we use the Greenhouse-Geisser adjustment of 0.488.\n\n\n\n\n\n\nFigure 3.12: Assumption selections for repeated ANOVA.\n\n\n\nThe corrected degrees of freedom are:\n\\(df_1*GGe=4*0.488=1.95\\)\nand\n\\(df_2*HFe=28*0.488=13.66\\).\n \nRepeated ANOVA table\n\n\n\n\n\n\nFigure 3.13: Summary table of repeated ANOVA.\n\n\n\nAs we can see from Figure 3.13, the within-subjects variable (time) was statistically significant under the Greenhouse-Geisser correction, F(1.95, 13.66) = 18.624, p &lt; 0.001, \\(\\eta^2_p = 0.727\\).\n\n\n3.1.7 Post hoc tests\nClick the Post Hoc Tests, then highlight the time in the left panel and click it (or drug it) over the the right panel. Check Bonferroni correction.\n\n\n\n\n\n\nFigure 3.14: Post Hoc Tests panels.\n\n\n\n \n\n\n\n\n\n\nFigure 3.15: Post Hoc Tests (Bonferroni correction).\n\n\n\n \n\nInterpretation\nBased on Greenhouse-Geisser correction for violation of sphericity, a one-way within-subjects ANOVA revealed a significant difference in the pre-test and post-test means, F(1.95, 13.66) = 18.62, p &lt; 0.001, within-subjects \\(\\eta^2 = 0.73\\). Pairwise comparisons using a Bonferroni correction to maintain an alpha level of 0.05 revealed that intensity of symptoms remained constant from the two pre-test baseline measures, significantly decreased after a week following drug therapy, and further significantly decreased after one month. Symptom intensity did not significantly differ from that level at the end of a year.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA Designs (2)</span>"
    ]
  },
  {
    "objectID": "anova3.html",
    "href": "anova3.html",
    "title": "4  ANOVA Designs (3)",
    "section": "",
    "text": "4.1 Two-way between-subjects Analysis of Variance (Two-way ANOVA)\nA research design is not limited to examining the effects of a single independent variable. In this section, we will explore how to incorporate a second independent variable. A design that includes multiple independent variables is known as a factorial design, where each level of one independent variable is combined with each level of the other.\nAfter obtaining a significant ANOVA result, it is essential to conduct post hoc tests that account for the number of comparisons to ensure accurate statistical interpretation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA Designs (3)</span>"
    ]
  },
  {
    "objectID": "anova3.html#two-way-between-subjects-analysis-of-variance-two-way-anova",
    "href": "anova3.html#two-way-between-subjects-analysis-of-variance-two-way-anova",
    "title": "4  ANOVA Designs (3)",
    "section": "",
    "text": "4.1.1 Importing data\nAssume that researchers are interested in exploring the role of analogical thinking in the problem-solving skills of children and adolescents. The researchers sample 21 students from primary school (6th grade students from “Dimotiko”, ages 11-12) and 21 students from secondary school (3rd grade students from “Gymnasium”, ages 14-15). The students are then randomly assigned to one of three groups, each consisting of 7 students: a control group, experimental group 1 (exposure to similar examples without instructions), and experimental group 2 (exposure to similar examples with instructions). The outcome measured is the number of mistakes made while attempting to solve the problems.\n\n\n\n\n\n\n\n\nFigure 4.1: Table with raw data.\n\n\n\n\nOpen the dataset named “mistakes” from the file tab in the menu (Figure 4.2).\n\n\n\n\n\n\nFigure 4.2: The mistakes dataset.\n\n\n\n \nWe prepare the data as follows (Figure 4.3):\n\n\n\n\n\n\nFigure 4.3: The modified dataset.\n\n\n\n\n\n4.1.2 Research question\nThe question of interest is whether the effect of school age and instructions on the number of mistakes. Specifically, we want to answer the following questions:\n\nDoes the number of mistakes differ based on instructions?\nDoes it differ based on school age?\nDoes the effect of instructions on the number of mistakes depend on school age (moderator)?\n\n\n\n4.1.3 Hypothesis testing for the one-way ANOVA test\n\n\n\n\n\n\nNull and alternative hypotheses\n\n\n\nMain effect: intervention\n\n\\(H_0\\): There is no significant difference in number of mistakes between intervention groups (\\(\\mu_{control} = \\mu_{exper1} = \\mu_{exper2}\\))\n\\(H_1\\): At least one intervention has a significantly different mean number of mistakes.\n\nMain effect: school age\n\n\\(H_0\\): There is no significant difference in number of mistakes between primary and secondary school. (\\(\\mu_{primary} = \\mu_{secondary}\\))\n\\(H_1\\): There is a significant difference in number of mistakes between primary and secondary school (\\(\\mu_{primary} \\neq \\mu_{secondary}\\)).\n\nInteraction effect between intervention and school age\n\n\\(H_0\\): There is no interaction effect between intervention and school age on number of mistakes (i.e., the effect of intervention on number of mistakes does not depend on school age).\n\\(H_1\\): There is a significant interaction effect between intervention and school age on number of mistakes (i.e., the effect of intervention on number of mistakes varies depending on school age).\n\n\n\n\n\n4.1.4 Assumptions\n\nNormality of Residuals: The number of mistakes should be approximately normally distributed within each group (i.e., for each combination of gender and residential community).\nHomogeneity of Variance (Homoscedasticity): The variance of number of mistakes should be approximately equal across all groups. (also named as homogeneity of variance or homoscedasticity).\n\n\n\n4.1.5 ANOVA (omnibus analysis)\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(ANOVA) -.-&gt; C(ANOVA)\n\n\n\n\n\n\nas shown below in Figure 4.4.\n\n\n\n\n\n\nFigure 4.4: Conducting ANOVA test in Jamovi. In the menu at the top, choose Analyses -&gt; ANOVA  -&gt; ANOVA.\n\n\n\n \nIn the ANOVA dialog box, highlight intervention in the left panel and drug it to the the Dependent Variable. Then highlight the gender and school_age and drug them to the Fixed Factors (Figure 4.5). Additionally, check \\(\\eta^2\\).\n\n\n\n\n\n\nFigure 4.5: ANOVA dialog box.\n\n\n\n \n\n\n4.1.6 Descriptive statistics and plots\n\n\n\n\n\n\nFigure 4.6: The estimated marginal means panels.\n\n\n\n\n\n\n\n\n\nFigure 4.7: Descriptive statistics.\n\n\n\n\n\n\n\n\n\nFigure 4.8: Plot with means.\n\n\n\nWe have created an interaction plot that illustrates the simple effects of intervention for primary and secondary school students. The resulting plot shows an interaction because the lines are not parallel. In this example, school age is a moderator.\n \nAssumptions Checks\nClick the Assumptions Checks, and check Homogeneity test, Normality test, and Q-Q plot (Figure 4.9).\n\n\n\n\n\n\nFigure 4.9: Assumption selections for ANOVA.\n\n\n\n\n\n\n\n\n\nFigure 4.10: Normality test.\n\n\n\nThe Shapiro-Wilk test of normality suggests normal distributions (p=0.08 &gt; 0.05; \\(H_o\\) is not rejected).\n \n\n\n\n\n\n\nFigure 4.11: Normal Q-Q plot.\n\n\n\nThe data points mostly fall along the diagonal line, indicating that the residuals are approximately normally distributed.\n \n\nEquality of variances\n\n\n\n\n\n\n\nFigure 4.12: Levene’s test.\n\n\n\nSince p = 0.19 &gt; 0.05, the \\(H_0\\) of the Levene’s test is not rejected and the variances are comparable.\n \nANOVA table\n\n\n\n\n\n\nFigure 4.13: Summary table of ANOVA.\n\n\n\nWe observe that both main effects—intervention (F = 14.2, p &lt;0.001) and school age (F = 48.9, p &lt;0.001), are significant. Additionally, the interaction is also significant (F = 23.1, p &lt;0.001).\nA key principle in interpreting and reporting factorial analysis results is that interactions take precedence over main effects. This is because interactions offer a more detailed and comprehensive understanding of the data.\nTherefore, we can conduct a simple effects analysis (which can be performed in the Linear Models module) and follow up with post hoc tests.\n\n\n\n\n\n\nFigure 4.14: Simple effects (school age as moderator).\n\n\n\nThe number of mistakes in the intervention groups differs significantly only among secondary school students (F = 36.7, p &lt;0.001).\n \n\n\n\n\n\n\nFigure 4.15: Simple effects (intervention as moderator).\n\n\n\nThe number of mistakes between primary school and secondary school students are significant for the experimental groups (F = 12.2, p = 0.001 and F = 82.8, p &lt;0.001).\n\n\n4.1.7 Post hoc tests\nClick the Post Hoc Tests, then highlight the gender x residence in the left panel and click it over the the right panel. Check Tukey correction.\n\n\n\n\n\n\nFigure 4.16: Post Hoc Tests panels.\n\n\n\n \n\n\n\n\n\n\nFigure 4.17: Post Hoc Tests (Bonferroni correction).\n\n\n\n \n\nInterpretation\nSimple effects tests were conducted using the Tukey adjustment to maintain an alpha level of 0.05. Results showed that the effect of instructions on the number of mistakes depends on school age.\nPrimary school students showed a relatively stable number of mistakes across all three groups, with their mistakes remaining high even with experimental interventions.\nSecondary school students demonstrated a significant decrease in mistakes. Specifically, there was a significant reduction in mistakes when comparing the control group to the group exposed to examples (MD = 12.6, p = 0.019). Adding instructions led to an even greater reduction in mistakes (MD = 18.9, p &lt;0.001), indicating that explicit guidance further enhanced their problem-solving skills.\nAdditionally, secondary school students made significantly fewer mistakes than primary school students in both experimental interventions, suggesting that older children may have a stronger ability to apply analogical reasoning in problem-solving after being exposed to similar examples and instructions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA Designs (3)</span>"
    ]
  },
  {
    "objectID": "linear1.html",
    "href": "linear1.html",
    "title": "5  Linear regression (1)",
    "section": "",
    "text": "5.1 Introduction to simple linear regression\nSimple linear regression involves a numeric dependent (or response) variable \\(Y\\) and one independent (or explanatory) variable \\(X\\) that is either numeric or categorical.\nOften it is of interest to quantify the linear association between two numeric variables, \\(X\\) and \\(Y\\), and given the value of one variable for an individual, to predict the value of the other variable. This is not possible from the correlation coefficient as it simply indicates the strength of the association as a single number; in order to describe the association between the values of the two variables, a technique called regression is used. In regression, we assume that a change in the independent variable, \\(X\\), will lead directly to a change in the dependent variable \\(Y\\). However, the term “dependent” does not necessarily imply a cause-and-effect relationship between the two variables.\nWe may recall from secondary/high school algebra that the equation of a line is: \\[y = \\beta_o + \\beta_1 \\cdot x \\tag{5.1}\\]\nThe Equation 5.1 is defined by two coefficients (parameters) \\(\\beta_o\\) and \\(\\beta_1\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#introduction-to-simple-linear-regression",
    "href": "linear1.html#introduction-to-simple-linear-regression",
    "title": "5  Linear regression (1)",
    "section": "",
    "text": "Figure 5.1: The equation of line.\n\n\n\n\n\nThe intercept coefficient \\(\\beta_o\\) is the value of \\(y\\) when \\(x = 0\\) (the point where the fitted line crosses the y-axis; Figure 5.1).\nThe slope coefficient \\(\\beta_1\\) for \\(x\\) is the mean change in \\(y\\) for every one unit increase in \\(x\\) (Figure 5.1).\n\n\n5.1.1 Importing data\n\n\n\n\n\n\n\n\nFigure 5.2: Table with raw data.\n\n\n\n\nOpen the dataset named “BirthWeight” from the file tab in the menu (Figure 5.3).\n\n\n\n\n\n\nFigure 5.3: The BirthWeight dataset.\n\n\n\nData of 550 infants at 1 month age was collected. The following variables were recorded:\n• Body weight of the infant in g (weight)\n• Body height of the infant in cm (height)\n• Head circumference in cm (headc)\n• Gender of the infant (gender: Female, Male)\n• Birth order in their family (parity: Singleton, One sibling, 2 or more siblings)\n• Education of the mother (education: tertiary, year10, year12)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#research-question",
    "href": "linear1.html#research-question",
    "title": "5  Linear regression (1)",
    "section": "5.2 Research question",
    "text": "5.2 Research question\nLet’s say that we want to model the association between height and weight for the sample of 550 infants of 1 month age. In other words, we want to find the parameters of a mathematical equation, such as \\(y = \\beta_o + \\beta_1 \\cdot x\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#hypothesis-testsing",
    "href": "linear1.html#hypothesis-testsing",
    "title": "5  Linear regression (1)",
    "section": "5.3 Hypothesis Testsing",
    "text": "5.3 Hypothesis Testsing\n\n\n\n\n\n\nNull hypothesis and alternative hypothesis\n\n\n\n\n\\(H_{0}:\\) the two variables are not linearly related. There is no effect between height and weight (\\(β_1 = 0\\)).\n\\(H_{1}:\\) the two variables are linearly related. There is an effect between height and weight (\\(β_1 \\neq 0\\)).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#scatter-plot",
    "href": "linear1.html#scatter-plot",
    "title": "5  Linear regression (1)",
    "section": "5.4 Scatter plot",
    "text": "5.4 Scatter plot\nWe start our analysis by creating the scatter plot of the response variable weight and the explanatory variable height. The pattern of the plotted points typically reveals the nature and strength of the association between the two variables.\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Exploration) -.-&gt; C(Scatterplot)\n\n\n\n\n\n\nas shown below in Figure 5.4.\n\n\n\n\n\n\nFigure 5.4: In the menu at the top, choose Analyses &gt; Exploration  &gt; Scatterplot.\n\n\n\nIn the ANOVA dialog box, highlight height in the left panel and drug it to the the X-axis. Then highlight the weight drug it to the Y-axis (Figure 5.5). Additionally, check from the Regression Line “Linear”.\n\n\n\n\n\n\nFigure 5.5: The Scatterplot dialogue box options.\n\n\n\n\n\n\n\n\n\nFigure 5.6: The Scatter plot of height and weight.\n\n\n\nAs we can see in Figure 5.6, the points seem to be scattered around a line. The scatter plot also shows that, in general, infants with high height tend to have high weight (positive association).\nTo select the best fitting straight line of the data set, it is necessary to determine the estimated values \\(b_o\\) and \\(b_1\\) of parameters \\(\\beta_o\\) and \\(\\beta_1\\) in Equation 5.1. The regression equation of the model becomes:\n\\[\\widehat{y} = b_o  + b_1 \\cdot x \\tag{5.2}\\]\nWhy do we put a “hat” on top of the \\(y\\)? It’s a form of notation commonly used in regression to indicate that we have a predicted value, or the value of \\(y\\) on the regression line for a given \\(x\\) value.\n\n5.4.1 Linear regression\nThe process of fitting a linear regression model to the data involves finding a straight line that can be considered as the best representation of the overall association between age and lung capacity.\nTo choose a line, we need to explain what we mean by the “best representation” of the data. A “best-fitting” line refers to the line that minimizes the sum of squared residuals (RSS). Therefore, we refer to the resulting model as the least-squares linear regression model and to the corresponding line as the least-squares regression line.\n\n\n5.4.2 Fit a simple linear regression model\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Regression) -.-&gt; C(Linear Regression)\n\n\n\n\n\n\nas shown below (Figure 6.4).\n\n\n\n\n\n\nFigure 5.7: In the menu at the top, choose Analyses &gt; Regression  &gt; Linear Regression.\n\n\n\nThe Linear Regression dialogue box opens (Figure 5.8). From the left-hand pane drag the variable weight into the Dependent Variable field and the variable height into the Covariates field on the right-hand side, as shown below:\n\n\n\n\n\n\nFigure 5.8: The Linear Regression dialogue box options. Drag and drop the weight into the Dependent Variable field and the height into the Covariates field.\n\n\n\nNext, from the Assumption Checks section tick the box “Q-Q plot of residuals” (Figure 5.9).\n\n\n\n\n\n\nFigure 5.9: Assumption Checks choices.\n\n\n\n\n\n\n\n\n\nFigure 5.10: Normal Q-Q plot of the residuals.\n\n\n\nThe Figure 5.9 shows no significant deviation from normality.\n \nAdditionally, from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 6.16):\n\n\n\n\n\n\nFigure 5.11: Check the Confidence interval box in the Model Coefficients section.\n\n\n\nThe output table with the model coefficients should look like the following (Figure 5.12):\n\n\n\n\n\n\nFigure 5.12: The model coefficients table.\n\n\n\n \nNow, let’s focus on interpreting the regression table in Figure 5.12. In the estimate column are the intercept \\(b_o\\) = -5411.95 \\(\\approx 5412\\) and the slope \\(b_1\\) = 178.3 \\(\\approx 178\\) for height. Thus the equation of the regression line becomes:\n\\[\n\\begin{aligned}\n\\widehat{y} &= b_o + b_1 \\cdot x\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{height}\\\\\n\\widehat{\\text{weight}}&= -5412 + 178\\cdot\\text{height}\n\\end{aligned}\n\\]\n \nThe intercept \\(b_o\\)\nThe intercept \\(b_o =5412\\) is the average weight for those infants with height of 0. In graphical terms, it’s where the line intersects the \\(y\\) axis when \\(x\\) = 0 (Figure 5.13). Note, however, that while the intercept of the regression line has a mathematical interpretation, it has no physical interpretation here, since observing a weight of 0 is impossible.\n\n\n\n\n\n\n\n\nFigure 5.13: Data of infants’ body height-body weight with fitted line crossing the y-axis.\n\n\n\n\n\n \nThe slope \\(b_1\\)\nOf greater interest is the slope of height, \\(b_1 = 178\\), as it summarizes the association between the height and weight variables.\n\n\n\n\n\n\n\n\nFigure 5.14: Scatter plot of infants’ body height-body weight and graphically calculation of the slope.\n\n\n\n\n\nThe graphical calculation of the slope from two points of the fitted line is (Figure 5.14):\n\\[  \nb =\\frac{dy}{dx}=\\frac{5270-4560}{60-56}= \\frac{710}{4} \\approx 178\n\\] Note that, in this example, the coefficient has units g/cm.\nAdditionally, note that the sign is positive, suggesting a positive association between these two variables, meaning infants with higher height also tend to have higher weight. Recall from earlier that the correlation coefficient was \\(r = 0.71\\). They both have the same positive sign, but have a different value. Recall further that the correlation’s interpretation is the “strength of linear association”. The slope’s interpretation is a little different:\n\nFor every 1 cm increase in height, there is on average an associated increase of 178 g of weight.\n\nWe only state that there is an associated increase and not necessarily a causal increase. In other words, just because two variables are strongly associated, it doesn’t necessarily mean that one causes the other. This is summed up in the often quoted phrase, “correlation is not necessarily causation.”\nFurthermore, we say that this associated increase is on average 178 g of weight, because we might have two infants whose height differ by 1 cm, but their difference in weight won’t necessarily be exactly 178. What the slope of 178 is saying is that across all possible infants, the average difference in weight between two infants whose height differ by 1 cm is 178 g.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#the-standard-error-se-of-the-regression-slope",
    "href": "linear1.html#the-standard-error-se-of-the-regression-slope",
    "title": "5  Linear regression (1)",
    "section": "5.5 The Standard error (SE) of the regression slope",
    "text": "5.5 The Standard error (SE) of the regression slope\nThe third column of the regression table in Figure 5.12 corresponds to the standard error of our estimates. We are interested in understanding the standard error of the slope (\\(SE_{b}\\)).\n\nSay we hypothetically collected 1000 samples of pairs of weight and height, computed the 1000 resulting values of the fitted slope \\(b\\), and visualized them in a histogram. This would be a visualization of the sampling distribution of \\(b\\). The standard deviation of the sampling distribution of \\(b\\) has a special name: the standard error of \\(b\\).\n\nThe coefficient for the independent variable ‘height’ is 178.31. The standard error is 7.49, which is a measure of the variability around this estimate for the regression slope.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#test-statistic-and-confidence-intervals-for-the-slope",
    "href": "linear1.html#test-statistic-and-confidence-intervals-for-the-slope",
    "title": "5  Linear regression (1)",
    "section": "5.6 Test statistic and confidence intervals for the slope",
    "text": "5.6 Test statistic and confidence intervals for the slope\nThe 6th column of the regression table in Figure 5.12 corresponds to a t-statistic. The hypothesis testing for the slope is:\n\\[\n\\begin{aligned}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs } H_1&: \\beta_1 \\neq 0.\n\\end{aligned}\n\\]\nThe null hypothesis, \\(H_{0}\\), states that the coefficient of the independent variable (height) is equal to zero, and the alternative hypothesis, \\(H_{1}\\), states that the coefficient of the independent variable is not equal to zero.\nThe t-statistic for the slope is defined by the following equation:\n\\[\\ t = \\frac{\\ b_1}{\\text{SE}_{b_1}} \\tag{5.3}\\]\nIn our example:\n\\[\\ t = \\frac{\\ b_1}{\\text{SE}_{b_1}}=\\frac{\\ 178.31}{\\text{7.49}} = 23.81\\]\nIn practice, we use the p-value (as generated by Jamovi based on the value of the t-statistic Equation 5.3) to guide our decision:\n\nIf p − value &lt; 0.05, reject the null hypothesis, \\(H_{0}\\).\nIf p − value ≥ 0.05, do not reject the null hypothesis, \\(H_{0}\\).\n\nIn our example p &lt;0.001 \\(\\Rightarrow\\) reject \\(H_{0}\\).\nThe \\(95\\%\\) CI of the coefficient \\(b\\) for a significance level α = 0.05, \\(df=n-2\\) degrees of freedom and for a two-tailed t-test is given by:\n\\[ 95\\% \\ \\text{CI}_{b} = b \\pm t_{df; 0.05/2} \\cdot \\text{SE}_{b_1} \\tag{5.4}\\]\nIn our example:\n\\[ 95\\% \\ \\text{CI}_{b_1} = 178.31 \\pm 1.96 \\cdot \\text{7.49}= 178.31 \\pm 14.68 \\Rightarrow 95\\% \\text{CI}_{b_1}= \\ (163.6, 193)\\]  \n\n\n\n\n\n\nInterpretation of linear regression\n\n\n\nIn summary, we can say that the regression coefficient of the height (178) is significantly different from zero (p &lt; 0.001) and indicates that there’s on average an increase of 178 g (\\(95\\%\\)CI: 164 to 193) in weight for every 1 cm increase in height. Note that the \\(95\\%\\)CI does not include the hypothesized null value of zero for the slope.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#observed-predicted-fitted-values-and-residuals",
    "href": "linear1.html#observed-predicted-fitted-values-and-residuals",
    "title": "5  Linear regression (1)",
    "section": "5.7 Observed, predicted (fitted) values and residuals",
    "text": "5.7 Observed, predicted (fitted) values and residuals\nWe define the following three concepts:\n\nObserved values \\(y\\), or the observed value of the dependent variable for a given \\(x\\) value\nPredicted (or fitted) values \\(\\widehat{y}\\), or the value on the regression line for a given \\(x\\) value\nResiduals \\(y - \\widehat{y}\\), or the error (ε) between the observed value and the predicted value for a given \\(x\\) value\n\n\n\n\n\n\n\nFigure 5.15: The equation of line.\n\n\n\nThe residuals are exactly the vertical distance between the observed data point and the associated point on the regression line (predicted value) (Figure 5.15). Positive residuals have associated y values above the fitted line and negative residuals have values below. We want the residuals to be small in magnitude, because large negative residuals are as bad as large positive residuals.\nFigure 5.16 shows these values:\n\n\n\n\n\n\n\n\nID\n\n\nweight\n\n\nheight\n\n\nweight_hat\n\n\nresidual\n\n\n\n\n\n\n1\n\n\n3950\n\n\n55.5\n\n\n4483.486\n\n\n-533.486\n\n\n\n\n2\n\n\n4630\n\n\n57.0\n\n\n4750.930\n\n\n-120.930\n\n\n\n\n3\n\n\n4750\n\n\n56.0\n\n\n4572.634\n\n\n177.366\n\n\n\n\n4\n\n\n3920\n\n\n56.0\n\n\n4572.634\n\n\n-652.634\n\n\n\n\n5\n\n\n4559\n\n\n55.0\n\n\n4394.338\n\n\n164.662\n\n\n\n\n6\n\n\n3639\n\n\n51.5\n\n\n3770.301\n\n\n-131.301\n\n\n\n\n7\n\n\n3550\n\n\n56.0\n\n\n4572.634\n\n\n-1022.634\n\n\n\n\n8\n\n\n4530\n\n\n57.0\n\n\n4750.930\n\n\n-220.930\n\n\n\n\n9\n\n\n4969\n\n\n58.5\n\n\n5018.375\n\n\n-49.375\n\n\n\n\n10\n\n\n3740\n\n\n52.0\n\n\n3859.449\n\n\n-119.449\n\n\n\n\n\n\nFigure 5.16: Regression points (first 10 out of 550 infants).\n\n\n\n\nObserve in the above table that weight_hat contains the predicted (fitted) values \\(\\widehat{y}\\) = \\(\\widehat{\\text{weight}}\\).\nThe residual column is simply \\(e_i = y - \\widehat{y} = weight - weight\\_hat\\).\nLet’s see, for example, the values for the first infant and have a visual representation:\n\nThe observed value \\(y\\) = 3950 is infant’s weight for \\(x\\) = 55.5.\nThe predicted value \\(\\widehat{y}\\) is the value 4483.939 on the regression line for \\(x\\) = 55.5. This value is computed using the intercept and slope in the previous regression in Figure 5.16: \\[\\widehat{y} = b_o + b_1 \\cdot x = -5411.953 + 178.296 \\cdot 55.5 = 4483.48\\]\nThe residual is computed by subtracting the predicted (fitted) value \\(\\widehat{y}\\) from the observed value \\(y\\). The residual can be thought of as a model’s error or “lack of fit” for a particular observation. In the case of this infant, it is \\(y - \\widehat{y}\\) = 3950 - 4483.4 = -533.4 .\n\nA “best-fitting” line refers to the line that minimizes the sum of squared residuals (RSS), also known as sum of squared estimate of errors (SSE) out of all possible lines we can draw through the points. The method of least squares is the most popular method used to calculate the coefficients of the regression line.\n\\[ min(RSS) =min\\sum_{i=1}^{n}(y_i - \\widehat{y}_i)^2  \\tag{5.5}\\]\nIn Figure 5.17, we have found the minimum value of RSS (it turns out to be 97723317) and have drawn a horizontal dashed green line. At the point where this minimum touches the graph, we have read down to the x axis to find the best value of the slope. This is the value 178.\n\n\n\n\n\n\n\n\nFigure 5.17: The sum of the squares of the residuals against the value of the coefficient of the slope which we are trying to estimate.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#quality-of-a-linear-regression-fit",
    "href": "linear1.html#quality-of-a-linear-regression-fit",
    "title": "5  Linear regression (1)",
    "section": "5.8 Quality of a linear regression fit",
    "text": "5.8 Quality of a linear regression fit\nThe quality of a linear regression fit is typically assessed using two related quantities: residual standard error (RSE) and the coefficient of determination R\\(^2\\).\nResidual standard error (RSE)\nRSE represents the average distance that the observed values fall from the regression line. Conveniently, it tells us how wrong the regression model is on average using the units of the response variable. Smaller values are better because it indicates that the observations are closer to the fitted line. In our example:\n\\[\\ RSE = \\sqrt{\\frac{\\ RSS}{n-2}}= \\sqrt{\\frac{\\ 97723317}{550-2}}= 422.3 \\tag{5.6}\\]\n \nCoefficient of determination R\\(^2\\)\nThe quality of our simple linear model is presented in Figure 5.18:\n\n\n\n\n\n\nFigure 5.18: The coefficient of determination \\(R^2\\).\n\n\n\nThe R\\(^2\\) is the fraction of the total variation in \\(y\\) that is explained by the regression.\n\\[\\ R^2 = \\frac{\\ explained \\ \\ variation}{total \\ \\ variation} \\tag{5.7}\\]\nThe R\\(^2\\) value is called the coefficient of determination and indicates the percentage of the variance in the dependent variable that can be explained or accounted for by the independent variable. Hence, it is a measure of the ‘goodness of fit’ of the regression line to the data. It ranges between 0 and 1 (it won’t be negative). An R\\(^2\\) statistic that is close to 1 indicates that a large proportion of the variability in the response has been explained by the regression. A number near 0 indicates that the regression did not explain much of the variability in the response.\nIn our example takes the value 0.509. It indicates that about 50.9% of the variation in infant’s body weight can be explained by the variation of the infant’s body height. In simple linear regression \\(\\sqrt{0.509} = 0.713\\) which equals to the Pearson’s correlation coefficient, r.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#simple-linear-regression-with-a-binary-explanatory-variable",
    "href": "linear1.html#simple-linear-regression-with-a-binary-explanatory-variable",
    "title": "5  Linear regression (1)",
    "section": "5.9 Simple linear regression with a binary explanatory variable",
    "text": "5.9 Simple linear regression with a binary explanatory variable\nUsing the same sample of 550 infants of 1 month age we want to examine how body weight is associated with the gender of the infant. Now we have an explanatory variable x that is binary (Male/Female), as opposed to the numerical explanatory variable model (height) that we used previously.\nIn the Linear Regression dialogue box opens (Figure 5.19) drag the variable gender into the Factors field.\n\n\n\n\n\n\nFigure 5.19: The Linear Regression dialogue box options. Drag and drop the weight into the Dependent Variable field and the height into the Factors field.\n\n\n\nA graphical comparison of the weight between the males and females is presented below using the JJStatsPlot:\n\n\n\n\n\n\nFigure 5.20: Violin plot by gender.\n\n\n\nHow can we handle this variable in a mathematical equation? Well, we will use a trick. All cases in which the respondent is Male will be coded as 1 and all other cases, in which the respondent is Female, will be coded as 0 (reference category). This allows us to enter in the gender values as numerical (note that these numbers are just indicators).\n\\[\n\\text{gender} =\n\\begin{cases}\n1 & \\text{if infant is Male} \\\\\n0 & \\text{otherwise (ref.)}\n\\end{cases}\n\\]\nThe equation of the regression line will have the following form:\n\\[\n\\begin{aligned}\n\\widehat{y} &= b_o + b_1 \\cdot x\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{gender}\n\\end{aligned}\n\\]\nAdditionally, from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 6.16):\n\n\n\nCheck the Confidence interval box in the Model Coefficients section.\n\n\nThe output table with the model coefficients should look like the following (Figure 5.21):\n\n\n\n\n\n\nFigure 5.21: The model coefficients table.\n\n\n\nThe equation of the model becomes:\n\\[\n\\begin{aligned}\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{gender}\\\\\n\\widehat{\\text{weight}} &= 4140 + 452 \\cdot\\text{gender}\n\\end{aligned}\n\\]\n\nThe “intercept” represents the average weight of a female infant, which is 4140 g and serves as the reference category.\nThe “gender” term denotes the average weight difference between male and female infants, which is 452 g.\n\nTherefore, the mean weight of a male infant is (4140 + 452) 4592 g which is significantly higher (on average) about 452 g relative to a female infant (p&lt;0.001). The 95% confidence interval for this estimation (the difference in means) is 358 to 545 g.\nIt is important to note that the above analysis is equivalent to run a two-sample t-test.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#simple-linear-regression-with-a-categorical-explanatory-variable-2-categories",
    "href": "linear1.html#simple-linear-regression-with-a-categorical-explanatory-variable-2-categories",
    "title": "5  Linear regression (1)",
    "section": "5.10 Simple linear regression with a categorical explanatory variable (> 2 categories)",
    "text": "5.10 Simple linear regression with a categorical explanatory variable (&gt; 2 categories)\nSuppose that infants are categorized into three categories based on parity: singletons, having one sibling, or having 2 or more siblings. We choose as the reference category the singleton infants.\nIn the Linear Regression dialogue box opens (Figure 5.19) drag the variable gender into the Factors field.\n\n\n\n\n\n\nFigure 5.22: The Linear Regression dialogue box options. Drag and drop the weight into the Dependent Variable field and the parity into the Factors field.\n\n\n\nA graphical comparison of the weight between the males and females is presented below using the JJStatsPlot:\n\n\n\n\n\n\nFigure 5.23: Violin plot by gender.\n\n\n\nWe will use the previous trick and we will create 2 dummy variables to assign numerical values to the levels of parity. So each dummy variable will represent one category of the explanatory variable and will be coded with 1 if the case falls in that category and with 0 if not.\n\\[\n\\text{parity1} =\n\\begin{cases}\n1 & \\text{if infant has one sibling} \\\\\n0 & \\text{otherwise (ref.)}\n\\end{cases}\n\\]\n\\[\n\\text{parity2} =\n\\begin{cases}\n1 & \\text{if infant has 2 or more siblings} \\\\\n0 & \\text{otherwise (ref.)}\n\\end{cases}\n\\]\nThe equation of the regression line will have the following form:\n\\[\n\\begin{aligned}\n\\widehat{y} &= b_o + b_1 \\cdot x\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{parity1} + b_2 \\cdot\\text{parity2}\n\\end{aligned}\n\\]\nTherefore, we are including all the categories to the linear regression model except the one which is going to be used as the reference category (here is the Singleton). Actually, we create a multiple regression model which we will examine later analytically.\nWe also select from the Reference Level the “Singleton” category and from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 5.24):\n\n\n\n\n\n\nFigure 5.24: Select the reference level and check the Confidence interval box in the Model Coefficients section.\n\n\n\nThe output table with the model coefficients should look like the following (Figure 5.25):\n\n\n\n\n\n\nFigure 5.25: The model coefficients table.\n\n\n\nThe equation of the model becomes:\n\\[\n\\begin{aligned}\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{parity1} + b_2 \\cdot\\text{parity2}\\\\\n\\widehat{\\text{weight}} &= 4259 + 130 \\cdot\\text{parity1} + 192 \\cdot\\text{parity2}\n\\end{aligned}\n\\]\n\nThe intercept corresponds to the mean weight 4259 g for a singleton infant which is the reference category.\nThe mean weight of an infant with one sibling is 4389 g which is significantly higher (on average) about 130 g relative to a singleton infant (p=0.037). The 95% confidence interval for this estimation (the difference in means) is 8 to 252 g.\nThe mean weight of an infant with 2 or more siblings is 4451 g which is significantly higher (on average) about 192 g relative to a singleton infant (p=0.002). The 95% confidence interval for this estimation (the difference in means) is 68 to 316 g.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear2.html",
    "href": "linear2.html",
    "title": "6  Linear regression (2)",
    "section": "",
    "text": "6.1 Multiple linear regression model\nAlthough multivariable regression may appear complex, its concepts, computations, and interpretations are direct extensions of those in simple regression.\nThe general form of a linear regression model is given by:\n\\[\\widehat{y} = b_o  + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_3 + ...+b_p \\cdot x_p \\tag{6.1}\\]\nThe objective is to obtain the coefficients-also known as partial regression slopes- \\(b_o, b_1, b_2, b_3,...,b_p\\).\nIt is important to emphasize that the term “linear” refers to the model’s linearity in the coefficients b, rather than in the explanatory variables x. For example, the following is still considered a general linear model:\n\\[\\widehat{y} = b_o  + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_1 \\cdot x_2 + b_4 \\cdot x_1^2 \\tag{6.2}\\]\nFor example, in Figure 6.1 we present a model consisted of one response variable (weight) and two continuous explanatory variables (height, headc):\n\\[\n\\begin{aligned}\n\\widehat{\\text{y}} &= b_o + b_1 \\cdot x_1 + b_2 \\cdot x_2\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot \\text{height} + b_2 \\cdot \\text{headc}\n\\end{aligned}\n\\]\nWe have visualized some of the points as being located above the plane and some as being located below the plane. The deviation of a point from the plane is represented by the dashed red line and is the residual. When the model contains more than two independent variables, it is described geometrically as a hyperplane.\nIt is important to note that the residuals in linear regression are assumed to be independent and identically distributed following the normal distribution with mean equals to zero and constant variance.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#multiple-linear-regression-model",
    "href": "linear2.html#multiple-linear-regression-model",
    "title": "6  Linear regression (2)",
    "section": "",
    "text": "Figure 6.1: For a model consisted of one response variable and two explanatory variables a plane in three-dimensional space may be fitted to the data points.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#basic-criteria-for-model-selection",
    "href": "linear2.html#basic-criteria-for-model-selection",
    "title": "6  Linear regression (2)",
    "section": "6.2 Basic criteria for model selection",
    "text": "6.2 Basic criteria for model selection\nIn simple linear regression, there is only one possible model, as it involves a single explanatory variable. However, in multiple linear regression, where multiple explanatory variables are involved, the challenge becomes identifying the best model. But what does “best” really mean?\nShould we select a model with only a few explanatory variables, or include as many as possible? For instance, if we have 20 potential explanatory variables, should we use all of them—or just a subset? And if we choose to use a subset, how do we decide which variables to include in order to optimize a particular function or goal?\nSurprisingly, these questions do not have straightforward answers—even for experienced researchers and data analysts. Variable selection in regression modeling is a complex task, and there is no universal agreement on the best approach. As we’ll see, choosing the “best” model often depends as much on scientific or practical considerations as on statistical criteria.\nA fundamental principle in model selection is the preference for simplicity. When comparing two models that explain the data equally well, the simpler model is generally favored. This principle, known as Occam’s Razor (or the law of parsimony), is widely embraced across scientific disciplines, including statistics.\n\nParcimonious model: We typically prefer simpler models, provided they account for similar amounts of variance as more complex ones.\n\nThe idea behind a parsimonious model is to avoid overfitting, where a model becomes too complex and starts to capture noise rather than the underlying patterns in the data. A parsimonious model aims to find a balance between complexity and performance, ensuring that the model is neither too simple (underfitting) nor too complex (overfitting).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#strategies-for-model-selection",
    "href": "linear2.html#strategies-for-model-selection",
    "title": "6  Linear regression (2)",
    "section": "6.3 Strategies for model selection",
    "text": "6.3 Strategies for model selection\nNext we present some commonly used strategies for model selection:\n\nSimultaneous Regression\n\nThe first and most straightforward approach to model selection is to include all available explanatory variables and assess model fit based on this complete model. This is known as full entry or simultaneous regression. In this method, the regression model is built by estimating all parameters simultaneously. However, there are cases where full-entry or simultaneous regression may not be the best choice for model-building. In such instances, the researcher may prefer to adopt a more complex algorithm for constructing the regression model.\n\nHierarchical Regression\n\nIn hierarchical regression, unlike in simultaneous regression, where all explanatory variables are entered into the model at once, researchers typically follow a pre-specified order for introducing variables creating multiple models or blocks. The order is usually driven by theory, reflecting the researcher’s prior knowledge. Hierarchical regression is particularly popular among social scientists when testing mediational hypotheses.\n\nAutomated regression methods (Best subset selection)\n\n(NOTE: This approach is not supported by JAMOVI.)\nThese methods combine the explanatory variables in all possible ways. The best subset selection (using backward elimination, forward selection, or both[stepwise selection]) seek to find the best model according to statistical criteria in many steps (stepwise method, the model is re-avaluated in each step). However, as you might imagine, the number of possible models quickly becomes quite large.\nIt is important to note that several statistical criteria can be used to assess the efficiency or fit of a model, with penalties for the number of explanatory variables. These criteria are calculated and compared across a set of competing models, providing an objective basis for selecting the “best” regression model. Examples include adjusted R-squared, Akaike Information Criterion (AIC)—where a smaller AIC indicates a better model—and Bayesian Information Criterion (BIC).\nAt first glance, especially for those new to statistics, automated selection methods may seem like an ideal solution for many multiple regression problems. They can appear to be the “panacea” for model selection—after all, allowing the computer to determine the “correct” model using its complex computational abilities seems like a logical approach.\nHowever, the issue is not as straightforward as it may seem, and several statistical and substantive challenges complicate the application of these methods. While automation offers convenience, it also has significant drawbacks, and not all decisions can or should be left to a computer. In addition to these statistical issues, there are substantive considerations to account for when selecting a model. The final model chosen by automated methods may not always offer the most practical value or utility.\nFrom a statistical perspective, automated selection methods, such as forward and backward regression, can introduce bias into parameter estimates, making the resulting inferential model unreliable. After multiple iterations, the probability of a Type I error becomes higher than the nominal \\(\\alpha\\) (typically 0.05). In addition to these statistical issues, there are substantive considerations to account for when selecting a model. The final model chosen by automated methods may not always offer the most practical value or utility.\n\nMaximizing statistical criteria is not the same as maximizing utility of the model.\n\n\nPurposeful selection process\n\nThe purposeful selection process begins with a univariable analysis of each candidate variable. A general decision rule is then applied to determine which variables to include. For example, any variable with a p-value &lt; 0.20 in the univariable analysis may be selected for the multivariable analysis.\nHowever, since the primary goal of a multivariable model is typically to assess the effect of the study intervention while controlling for potential confounders, variable selection should also take into account existing knowledge and the clinical significance of the variables. If necessary, the initial rule can be adjusted. For example, a potential confounder may be included in the model if it alters the coefficient of the primary exposure variable by 10% in the multivariable model.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#importing-data",
    "href": "linear2.html#importing-data",
    "title": "6  Linear regression (2)",
    "section": "6.4 Importing data",
    "text": "6.4 Importing data\nContinuing from the previous chapter, we will work with the BirthWeight dataset. This time, we aim to explore the association between infant weight and all other measured explanatory variables.\n\n\n\n\n\n\n\n\nFigure 6.2: Table with raw data.\n\n\n\n\nOpen the dataset named “BirthWeight” from the file tab in the menu.\n\n\n\n\n\n\nFigure 6.3: The BirthWeight dataset.\n\n\n\nData of 550 infants at 1 month age was collected. The following variables were recorded (Figure 6.3):\n• Body weight of the infant in g (weight)\n• Body height of the infant in cm (height)\n• Head circumference in cm (headc)\n• Gender of the infant (gender: Female, Male)\n• Birth order in their family (parity: Singleton, One sibling, 2 or more siblings)\n• Education of the mother (education: tertiary, year10, year12)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#simultaneous-regression",
    "href": "linear2.html#simultaneous-regression",
    "title": "6  Linear regression (2)",
    "section": "6.5 Simultaneous Regression",
    "text": "6.5 Simultaneous Regression\nFirst, we will include all available explanatory variables and assess model fit based on this complete model.\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Regression) -.-&gt; C(Linear Regression)\n\n\n\n\n\n\nas shown below (Figure 6.4).\n\n\n\n\n\n\nFigure 6.4: In the menu at the top, choose Analyses &gt; Regression  &gt; Linear Regression.\n\n\n\nThe Linear Regression dialogue box opens (Figure 5.8). From the left-hand pane drag the variable weight into the Dependent Variable field, the variables height and headc into the Covariates field, and the variables gender, parity, and education into the factors field on the right-hand side, as shown below (Figure 6.5):\n\n\n\n\n\n\nFigure 6.5: The Linear Regression dialogue box options. Drag and drop the variables in the fields on the right-hand side.\n\n\n\nWe also set reference groups for the categorical variables from the Reference Level box: “Female” for the gender variable, “Singleton” for the parity variable, and “year10” for the education variable.\n\n\n\n\n\n\nFigure 6.6: Reference Level box. Specify the reference group for the categorical variables.\n\n\n\n\n6.5.1 Assumptions\nSpecific assumptions have to be met for reliable hypothesis testing and confidence intervals in linear regression: independence of the residuals, linearity and homoscedasticity of the data, normality of the residuals, no multicollinearity and outliers. We will describe some statistical tests and diagnostic plots in Jamovi for testing the assumptions underlying linear regression model.\nFrom the Assumption Checks section tick the all the boxes and from the Data Summary the “Cook’s distance” (Figure 6.7):\n\n\n\n\n\n\nFigure 6.7: Assumption Checks choices.\n\n\n\n \nIndependence of residuals\nThe independence of residuals assumption means that for any two observations, the residual terms should be uncorrelated (or independent).\n\n\n\n\n\n\nFigure 6.8: The Durbin-Watson test.\n\n\n\nThe Durbin-Watson test assesses whether the residuals from a regression model are independent—that is, whether there is autocorrelation. Ideally, the Durbin-Watson statistic should be close to 2. Values significantly below 1 or above 3 suggest a violation of the independence assumption. In our case, the Durbin-Watson statistic is 1.83, which is close to 2, indicating no evidence of problematic autocorrelation.\n \nLinearity and homoscedasticity of the data\nTo examine linearity and homoscedasticity we examine the Residuals vs Fitted value Plot.\n\n\n\n\n\n\nFigure 6.9: Residuals vs Fitted values plot.\n\n\n\nWe would expect to see a random scatter of points around zero on the y-axis. In our example, the residuals appear randomly dispersed in a cloud-like pattern, which indicates that the assumption of linearity and homoscedasticity is satisfied.\n\nIf the residuals display a pattern—such as being more spread out at the ends and tighter in the middle (a bow tie shape), or more spread out on one side of the x-axis and tighter on the other (a funnel or fan shape)—this suggests heteroscedasticity. In such cases, the assumption of homoscedasticity is violated.\n\n\n\n\n\n\n\nFigure 6.10: Homoscedasticity Vs heteroscedasticity.\n\n\n\n \n\n\n6.5.2 Normality of the residuals\nThe check normality of the residuals with the Shapiro-Wilk’s test and the normal Q-Q plot of the residuals.\n\n\n\n\n\n\nFigure 6.11: The Durbin-Watson test.\n\n\n\nNote that this test almost always yields significant results for the distribution of residuals for large samples and visual inspection (e.g., Q-Q plots) are preferable.\n\n\n\n\n\n\nFigure 6.12: The Durbin-Watson test.\n\n\n\nThe Figure 6.12 shows no significant deviation from normality.\n \n\n\n6.5.3 No multicollinearity\nThis assumption means there should be no perfect or near-perfect linear relationship between two or more of the explanatory variables (predictors) in our regression model. Multicollinearity is a problem for three reasons:\n\nUntrustworthy \\(b\\): As multicollinearity increases, so do the standard errors of the \\(b\\) coefficients. We want smaller standard errors, so this is problematic.\nLimits the size of R, and therefore the size of \\(R^2\\), and we want to have the largest \\(R^2\\) possible, given our data.\nImportance of explanatory variables (predictors): When two explanatory variables are highly correlated, it is very hard to determine which variable is more important than the other.\n\nTo test for multicollinearity, we examine the VIF and Tolerance values. VIF is actually a transformation of Tolerance (Tolerance = 1/VIF). In general, we want VIF values 5 or lower, which corresponds to Tolerance values greater than (1/5) 0.2.\n\n\n\n\n\n\nFigure 6.13: VIF.\n\n\n\nIn our data, the VIF values satisfy the assumption of no multicollinearity.\n \n\nProposed remedies for multicollinearity\n• Increase the sample size: A larger sample can reduce the standard errors of the coefficient estimates, thereby improving the precision and stability of the model.\n• Model respecification: Remove some of the highly associated explanatory variables or replace them with a linear combination of them (if possible).\n• Regularization (Tolerant) techniques: Some regression techniques may be more sensitive to multicollinearity than others. Recent developments in model selection methods have introduced new methods for balancing model complexity and fit. For example two special linear regression model — Lasso and Ridge regression. Although not necessarily designed to be tolerant of collinearity, they offer approaches that may be less sensitive.\n• Principal Component Regression: This technique transforms the original correlated variables into a smaller set of uncorrelated components and uses them in the regression, effectively addressing multicollinearity.\n• Change the reference category for categorical variables: In cases where multicollinearity arises from dummy variables, selecting a different reference category can sometimes alleviate the problem.\n\n\n\n6.5.4 No outliers that influence the model (influential points)\nThere shouldn’t be any data point in the dataset that is an outlier which would strongly influence our results.\nOutliers are points that fall away from the cloud of points. Outliers that actually influence the parameters of the regression model are called influential points. Therefore, not all outliers are influential in linear regression analysis. Even though data have extreme values, they might not be influential to determine a regression model. That means, the results wouldn’t be much different if we either include or exclude them from analysis.\nCook’s distance is a measure used to identify influential data points in regression analysis. In general, Cook’s distances greater than 1 indicate an outlier that may influence the model.\n\n\n\n\n\n\nFigure 6.14: Cook’s distance.\n\n\n\nOur Cook’s distances are very small, so we do not have a problem with outliers.\n \n\n\n6.5.5 The model fit and coefficients\nFrom the Model Fit section tick the box “Adjusted \\(R^2\\)” in Fit Measures (Figure 6.16):\n\n\n\n\n\n\nFigure 6.15: Adjusted R square.\n\n\n\nAdditionally, from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 6.16):\n\n\n\n\n\n\nFigure 6.16: Check the Confidence interval box in the Model Coefficients section.\n\n\n\nAdjusted R-squared: This metric adjusts the R-squared value to account for the number of explanatory variables (predictors) in the model.\n\n\n\n\n\n\nFigure 6.17: The model coefficients table.\n\n\n\nAbout 59% of the variation in infant’s body weight can be explained by the independent variables (such as height, head circumference, gender, etc.) in the model.\n \nThe output table with the model coefficients should look like the following (Figure 6.18):\n\n\n\n\n\n\nFigure 6.18: The model coefficients table.\n\n\n\nThe equation of our model with all variables is:\n\\[\\begin{align}\n\\widehat{Weight} &= -7082 + 131 \\cdot height + 109 \\cdot headc + 196 \\cdot gender \\\\\n&\\quad +\\ 76 \\cdot parity1 + 96 \\cdot parity2 - 35 \\cdot edu1 - 36 \\cdot edu2\n\\end{align}\\]\nAll variables in the model are statistically significant except for the comparison between infants with two or more siblings and singletons (p = 0.06), as well as the mother’s education level (year12-year10, p = 0.47; tertiary-year10 p = 0.33).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#hierarchical-regression",
    "href": "linear2.html#hierarchical-regression",
    "title": "6  Linear regression (2)",
    "section": "6.6 Hierarchical regression",
    "text": "6.6 Hierarchical regression\nFirst, we check Akaike Information Criterion (AIC) from the Model Fit (Figure 6.19).\n\n\n\n\n\n\nFigure 6.19: Akaike Information Criterion (AIC).\n\n\n\nThe AIC is a statistical measure used to evaluate the goodness of fit of a model while penalizing for the number of parameters used. It helps compare different models and choose the one that best balances model fit and complexity. A lower AIC indicates a better model.\n\n6.6.1 Model 1\nWe can specify hierarchical regression using the Model Builder drop-down menu in jamovi (Figure 6.20). Let’s select height and gender variables (predictors) as Block 1 (Model 1).\n\n\n\n\n\n\nFigure 6.20: Model builder: Block 1.\n\n\n\n\n\n\n\n\n\nFigure 6.21: Model fit table.\n\n\n\nAbout 55% of the variation in infant’s body weight can be explained by height and gender in the model 1.\n \nThe output table with the model coefficients should look like the following (Figure 6.22):\n\n\n\n\n\n\nFigure 6.22: Model 1 coefficients table.\n\n\n\nThe equation of model 1 is:\n\\[\\widehat{Weight} = -4814 + 165 \\cdot height + 251 \\cdot gender\\]\nBoth variables in the model are statistically significant (p&lt;0.001).\n\n\n6.6.2 Model 2\nNext, we select Add New Block and include the headc and parity variables in Block 2 (Model 2).\n\n\n\n\n\n\nFigure 6.23: Model builder: Block 2.\n\n\n\n\n\n\n\n\n\nFigure 6.24: Model fit table.\n\n\n\nModel 2 explains approximately 59% of the variation in infant body weight using the variables height, gender, headc, and parity, compared to 55% in Model 1 (\\(\\Delta R_{adj}^2 = 0.04\\) or 4%). Additionally, the AIC of Model 2 (8115) is lower than that of Model 1 (8169), indicating that Model 2 has a better fit.\n \nThe output table with the new model coefficients should look like the following (Figure 6.25):\n\n\n\n\n\n\nFigure 6.25: Model 2 coefficients table.\n\n\n\nThe equation of model 2 is:\n\\[\\begin{align}\n\\widehat{Weight} &= -7072 + 130 \\cdot height + 197 \\cdot gender + 110 \\cdot headc \\\\\n&\\quad +\\ 82 \\cdot parity1 + 105 \\cdot parity2\n\\end{align}\\]\nAll variables in the model are statistically significant (p&lt;0.05).\n\n\n6.6.3 Model 3\nFinally, we select Add New Block and include the education variable in Block 3 (Model 3).\n\n\n\n\n\n\nFigure 6.26: Model builder: Block 3.\n\n\n\n\n\n\n\n\n\nFigure 6.27: Model fit table.\n\n\n\nModel 3 does not explain more variation than Model 2. Additionally, the AIC of Model 3 (8118) is greater than that of Model 2 (8115), indicating that Model 3 provides a worse fit.\n \nThe output table with the new model coefficients should look like the following (Figure 6.25):\n\n\n\n\n\n\nFigure 6.28: Model 3 coefficients table.\n\n\n\nThe equation of model 3 is:\n\\[\\begin{align}\n\\widehat{Weight} &= -7082 + 131 \\cdot height + 109 \\cdot headc + 196 \\cdot gender \\\\\n&\\quad +\\ 76 \\cdot parity1 + 96 \\cdot parity2 - 35 \\cdot edu1 - 36 \\cdot edu2\n\\end{align}\\]\nNOTE: This model is the complete that we have previously explored.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#model-with-an-interaction-term",
    "href": "linear2.html#model-with-an-interaction-term",
    "title": "6  Linear regression (2)",
    "section": "6.7 Model with an interaction term",
    "text": "6.7 Model with an interaction term\nFinally, we remove education from Block 3 and add the interaction term between height and gender.\n\n\n\n\n\n\nFigure 6.29: Model builder: Block 3.\n\n\n\n\n\n\n\n\n\nFigure 6.30: Model fit table.\n\n\n\nThe AIC of Model 3 (8101) is lower than that of Model 2 (8115), indicating that Model 3 with the interaction term has a better fit.\n \nThe output table with the new model coefficients should look like the following (Figure 6.25):\n\n\n\n\n\n\nFigure 6.31: Model 3 coefficients table.\n\n\n\nThe interaction term is statistically significant (Estimate = 57, p &lt; 0.001), suggesting that the effect of height on body weight differs by gender. This indicates effect modification (also known as a moderation effect), where gender alters the strength of the association between height and body weight.\nThe equation of model 3 with the interaction term is:\n\\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc -2921 \\cdot gender \\\\\n&\\quad +\\ 91 \\cdot parity1 + 116 \\cdot parity2 + 57 \\cdot heigh * gender\n\\end{align}\\]\nIn this case, the main effects of height and gender are not interpreted independently, as the interaction term modifies their meanings. Specifically:\n\nFor females (reference; gender = 0):\n\n\\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc -2921 \\cdot 0 \\\\\n&\\quad +\\ 91 \\cdot parity1 + 116 \\cdot parity2 + 57 \\cdot heigh * 0\n\\end{align}\\] \\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc + 91 \\cdot parity1 + 116 \\cdot parity2\n\\end{align}\\]\nThus, the effect of height on body weight is 98 g/cm.\n\nFor males (gender = 1):\n\n\\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc -2921 \\cdot 1 \\\\\n&\\quad +\\ 91 \\cdot parity1 + 116 \\cdot parity2 + 57 \\cdot heigh * 1\n\\end{align}\\] \\[\\begin{align}\n\\widehat{Weight} &= -8220 + (98 + 57) \\cdot height + 108 \\cdot headc + 91 \\cdot parity1 + 116 \\cdot parity2 \\\\\n\\end{align}\\]\nThus, the effect of height is 98 + 57 = 155 g/cm.\nThis implies that height has a stronger influence on weight for males than for females.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "pca.html",
    "href": "pca.html",
    "title": "7  Principal Components Analysis",
    "section": "",
    "text": "7.1 Introduction\nSuppose that we have \\(n\\) observations with measurements on a set of \\(p\\) observed variables (features), \\(X_1,X_2, . . . ,X_p\\). This means that each of the \\(n\\) observations lives in p-dimensional space, but not all of these dimensions are equally interesting. Principal Component Analysis (PCA) is a statistical technique that seeks a small number of dimensions, called principal components, that are as interesting as possible, where the concept of interesting is measured by the amount that the observations vary along each dimension.\nTherefore, PCA is commonly used to reduce the dimensionality of a dataset while preserving as much of the total variance as possible. In other words, it transforms a large set of correlated variables into a smaller set of uncorrelated representative variables (principal components), which collectively explain most of the variability in the original data.\nIt is important to note that there are \\(p\\) possible principal components representing the full-dimensional space of the data. The first principal component of a set of observed variables \\(X_1, X_2, . . . ,X_p\\) is the normalized linear combination of the \\(p\\) observed variables:\n\\[PC1: Z_1 = \\phi_{11} X_1 + \\phi_{21} X_2  + ...+ \\phi_{p1} X_p \\] that has the largest variance. By normalized, we mean that \\(\\sum_{j=1}^p \\phi_{j1}^2 = 1\\). We refer to the elements \\(\\phi_{11}, \\phi_{21},..., \\phi_{p1}\\) as the loadings of the first principal component.\nTo obtain the loadings of the first principal component (PC1), we solve an optimization problem that maximizes the variance of the data projected onto a linear combination of the original variables. This can be solved via an eigen decomposition, a standard technique in linear algebra (algebra of matrices).\nAfter the first principal component \\(Z_1\\) of the observed variables has been determined, we can find the second principal component \\(Z_2\\).\n\\[PC2: Z_2 = \\phi_{12} X_1 + \\phi_{22} X_2  + ...+ \\phi_{p2} X_p \\]\nThe second principal component (PC2) explaines the next highest amount of variance. The elements \\(\\phi_{12}, \\phi_{22},..., \\phi_{p2}\\) are referred to as the loadings of the second principal component. The same procedure can be applied to obtain the third principal component (PC3), the fourth component (PC4) and so on for subsequent components.\nEXAMPLE DATA\nOur data analysis is based on the paper published by Lewis and Neville on the Gendered Racial Microaggressions Scale for Black Women (Lewis and Neville 2015). The article presents two separate studies that contributed to the development, refinement, and psychometric evaluation of two parallel versions of the scale: one measuring stress appraisal and the other measuring frequency. For the purposes of our analysis, we focus on the final construction of the stress appraisal version. Items were rated on a 6-point Likert scale ranging from 0 (not at all stressful) to 5 (extremely stressful).\nFigure 7.1: Table with raw data.\nBelow is an outline of the 25 items included in the article by Lewis and Neville.\nOur objective is to to reduce the set of 25 correlated items to a smaller set of uncorrelated variables, known as principal components, that capture the most significant variation in the original data. Ideally, these resulting components (or dimensions) should represent meaningful underlying concepts.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#introduction",
    "href": "pca.html#introduction",
    "title": "7  Principal Components Analysis",
    "section": "",
    "text": "While PCA computes all \\(p\\) principal components, the goal is to reduce the dimensionality by keeping only the most important components. We might choose to keep just the top k components that explain a large portion of the total variance, and discard the remaining components.\n\n\n\n\n\n\n\nUnattractive because of size of butt (Obj1)\nNegative comments about size of facial features (Obj2)\nImitated the way they think Black women speak (Obj3)\nSomeone made me feel unattractive (Obj4)\nNegative comment about skin tone (Obj5)\nSomeone assumed I speak a certain way (Obj6)\nObjectified me based on physical features(Obj7)\nSomeone assumed I have a certain body type (Obj8)\nMade a sexually inappropriate comment (Obj9)\nNegative comments about my hair when natural (Obj10)\nI have felt unheard (Marg1)\nMy comments have been ignored (Marg2)\nSomeone challenged my authority (Marg3)\nI have been disrespected in workplace (Marg4)\nSomeone has tried to “put me in my place” (Marg5)\nFelt excluded from networking opportunities (Marg6)\nAssumed I did not have much to contribute to the conversation (Marg7)\nSomeone assumed I was sassy and straightforward (Str1)\nI have been told that I am too independent (Str2)\nSomeone made me feel exotic as a Black woman (Str3)\nI have been told that I am too assertive (Str4)\nAssumed to be a strong Black woman (Str5)\nSomeone has told me to calm down (Ang1)\nPerceived to be “angry Black woman” (Ang2)\nSomeone accused me of being angry when speaking calm (Ang3)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#the-technical-part-of-pca",
    "href": "pca.html#the-technical-part-of-pca",
    "title": "7  Principal Components Analysis",
    "section": "7.2 The technical part of PCA",
    "text": "7.2 The technical part of PCA\n\n\n\n\n\n\nFigure 7.2: The method of PCA for dimensionality reduction.\n\n\n\nFigure 7.2 illustrates the workflow of principal component analysis (PCA), as a method to reduce the number of dimensions of the data. It starts with a large table of data (\\(X_{n \\times p}\\)), standardizes it (\\(X^c_{n \\times p}\\)), and calculates the covariance matrix (\\(C_{p \\times p}\\)) between observed variables (features). Then, it finds the principal directions (eigenvectors) and their importance (eigenvalues). By selecting the most important directions (the top k) using some criterion (e.g., eigenvalues greater than 1, cumulative variance), the original data is projected onto a lower-dimensional space applying the projection matrix \\(W_{p \\times k}\\), resulting in a smaller table that still captures most of the data’s variability. The scatter plots visually show this reduction from a higher to a lower dimension.\n\nR-matrix\n\nFirst, we calculate the R-matrix, which is a correlation matrix—a table of correlation coefficients between variables.\n\n\n      Obj1 Obj2 Obj3 Obj4 Obj5 Obj6 Obj7  Obj8 Obj9 Obj10 Marg1 Marg2 Marg3\nObj1  1.00 0.35 0.25 0.27 0.28 0.25 0.28  0.35 0.15  0.24  0.19  0.25  0.17\nObj2  0.35 1.00 0.31 0.25 0.27 0.23 0.31  0.28 0.26  0.24  0.22  0.21  0.25\nObj3  0.25 0.31 1.00 0.24 0.28 0.28 0.20  0.25 0.21  0.22  0.17  0.23  0.17\nObj4  0.27 0.25 0.24 1.00 0.39 0.23 0.28  0.30 0.26  0.28  0.22  0.18  0.14\nObj5  0.28 0.27 0.28 0.39 1.00 0.15 0.18  0.29 0.25  0.20  0.17  0.20  0.23\nObj6  0.25 0.23 0.28 0.23 0.15 1.00 0.20  0.14 0.21  0.12  0.10  0.14  0.05\nObj7  0.28 0.31 0.20 0.28 0.18 0.20 1.00  0.31 0.19  0.28  0.30  0.21  0.20\nObj8  0.35 0.28 0.25 0.30 0.29 0.14 0.31  1.00 0.19  0.23  0.27  0.14  0.14\nObj9  0.15 0.26 0.21 0.26 0.25 0.21 0.19  0.19 1.00  0.20  0.10  0.12  0.21\nObj10 0.24 0.24 0.22 0.28 0.20 0.12 0.28  0.23 0.20  1.00  0.09  0.12  0.17\nMarg1 0.19 0.22 0.17 0.22 0.17 0.10 0.30  0.27 0.10  0.09  1.00  0.43  0.41\nMarg2 0.25 0.21 0.23 0.18 0.20 0.14 0.21  0.14 0.12  0.12  0.43  1.00  0.35\nMarg3 0.17 0.25 0.17 0.14 0.23 0.05 0.20  0.14 0.21  0.17  0.41  0.35  1.00\nMarg4 0.19 0.18 0.24 0.26 0.20 0.10 0.25  0.24 0.07  0.12  0.38  0.23  0.32\nMarg5 0.17 0.22 0.21 0.27 0.25 0.16 0.23  0.19 0.19  0.11  0.41  0.40  0.25\nMarg6 0.18 0.27 0.16 0.23 0.22 0.26 0.28  0.26 0.15  0.26  0.35  0.27  0.25\nMarg7 0.13 0.19 0.14 0.19 0.06 0.17 0.16  0.14 0.10  0.11  0.31  0.33  0.20\nStr1  0.22 0.18 0.14 0.06 0.23 0.07 0.25  0.17 0.19  0.10  0.19  0.25  0.20\nStr2  0.19 0.18 0.19 0.19 0.12 0.15 0.13  0.06 0.18  0.19  0.12  0.18  0.17\nStr3  0.10 0.09 0.09 0.08 0.11 0.09 0.19  0.05 0.12  0.10  0.13  0.18  0.10\nStr4  0.09 0.14 0.18 0.15 0.12 0.08 0.07  0.13 0.05  0.02  0.08  0.12  0.08\nStr5  0.20 0.15 0.15 0.08 0.19 0.11 0.15  0.04 0.07  0.09  0.10  0.23  0.12\nAng1  0.06 0.07 0.07 0.09 0.12 0.04 0.15  0.07 0.17  0.06  0.16  0.23  0.18\nAng2  0.06 0.15 0.08 0.06 0.09 0.20 0.13 -0.03 0.00  0.14  0.17  0.19  0.19\nAng3  0.21 0.13 0.11 0.14 0.11 0.16 0.23  0.07 0.06  0.08  0.28  0.28  0.11\n      Marg4 Marg5 Marg6 Marg7 Str1 Str2 Str3 Str4 Str5 Ang1  Ang2 Ang3\nObj1   0.19  0.17  0.18  0.13 0.22 0.19 0.10 0.09 0.20 0.06  0.06 0.21\nObj2   0.18  0.22  0.27  0.19 0.18 0.18 0.09 0.14 0.15 0.07  0.15 0.13\nObj3   0.24  0.21  0.16  0.14 0.14 0.19 0.09 0.18 0.15 0.07  0.08 0.11\nObj4   0.26  0.27  0.23  0.19 0.06 0.19 0.08 0.15 0.08 0.09  0.06 0.14\nObj5   0.20  0.25  0.22  0.06 0.23 0.12 0.11 0.12 0.19 0.12  0.09 0.11\nObj6   0.10  0.16  0.26  0.17 0.07 0.15 0.09 0.08 0.11 0.04  0.20 0.16\nObj7   0.25  0.23  0.28  0.16 0.25 0.13 0.19 0.07 0.15 0.15  0.13 0.23\nObj8   0.24  0.19  0.26  0.14 0.17 0.06 0.05 0.13 0.04 0.07 -0.03 0.07\nObj9   0.07  0.19  0.15  0.10 0.19 0.18 0.12 0.05 0.07 0.17  0.00 0.06\nObj10  0.12  0.11  0.26  0.11 0.10 0.19 0.10 0.02 0.09 0.06  0.14 0.08\nMarg1  0.38  0.41  0.35  0.31 0.19 0.12 0.13 0.08 0.10 0.16  0.17 0.28\nMarg2  0.23  0.40  0.27  0.33 0.25 0.18 0.18 0.12 0.23 0.23  0.19 0.28\nMarg3  0.32  0.25  0.25  0.20 0.20 0.17 0.10 0.08 0.12 0.18  0.19 0.11\nMarg4  1.00  0.30  0.26  0.16 0.10 0.21 0.05 0.06 0.03 0.12  0.22 0.17\nMarg5  0.30  1.00  0.29  0.28 0.16 0.13 0.16 0.14 0.18 0.12  0.14 0.21\nMarg6  0.26  0.29  1.00  0.20 0.13 0.18 0.15 0.13 0.08 0.11  0.21 0.12\nMarg7  0.16  0.28  0.20  1.00 0.14 0.05 0.04 0.02 0.12 0.17  0.13 0.09\nStr1   0.10  0.16  0.13  0.14 1.00 0.21 0.30 0.23 0.23 0.18  0.05 0.10\nStr2   0.21  0.13  0.18  0.05 0.21 1.00 0.20 0.20 0.12 0.16  0.12 0.16\nStr3   0.05  0.16  0.15  0.04 0.30 0.20 1.00 0.27 0.18 0.20  0.07 0.15\nStr4   0.06  0.14  0.13  0.02 0.23 0.20 0.27 1.00 0.12 0.15  0.03 0.02\nStr5   0.03  0.18  0.08  0.12 0.23 0.12 0.18 0.12 1.00 0.22  0.15 0.11\nAng1   0.12  0.12  0.11  0.17 0.18 0.16 0.20 0.15 0.22 1.00  0.24 0.23\nAng2   0.22  0.14  0.21  0.13 0.05 0.12 0.07 0.03 0.15 0.24  1.00 0.25\nAng3   0.17  0.21  0.12  0.09 0.10 0.16 0.15 0.02 0.11 0.23  0.25 1.00\n\n\nOur objective is to turn the R-matrix (correlation matrix) into an output which represents the degree to which each observed variable contributes to a component.\nPrincipal components are derived through an eigen-decomposition of the correlation matrix. This process involves re-expressing the matrix in terms of its eigenvectors and eigenvalues. The eigenvectors define the directions (or axes) of the new feature space, while the corresponding eigenvalues indicate the amount of variance explained by each component.\n\n7.2.1 PC1\n\nEigenvector and eigenvalue for PC1\n\nThe first eigenvector \\(v_1=(\\alpha_{11}, \\alpha_{21}, ..., \\alpha_{p1})\\) is:\n\n\n [1] 0.225 0.239 0.214 0.226 0.220 0.173 0.240 0.207 0.175 0.179 0.251 0.250\n[13] 0.220 0.214 0.242 0.234 0.176 0.185 0.173 0.141 0.123 0.146 0.149 0.140\n[25] 0.166\n\n\nTherefore, \\(a_{11} = 0.225\\), \\(a_{21} = 0.239\\), \\(a_{31} = 0.214\\), …, \\(a_{25 \\ 1} = 0.166\\) etc.\n \nThe corresponding eigenvalue, \\(\\lambda_{1}\\), is:\n\n\n[1] 5.365\n\n\n \n\nLoadings of PC1\n\nNow, we are ready to calculate the loadings \\(\\phi_{11}, \\phi_{21},..., \\phi_{p1}\\) of the first principal component according to the formula:\n\\[\\phi_{i1} = \\alpha_{i1} \\sqrt{\\lambda_{1}}\\]\nwhere \\(i= 1,...p\\).\nFor example:\n\\(\\phi_{11} = \\alpha_{11} \\sqrt{\\lambda_{1}} = 0.225 \\ \\cdot \\sqrt{5.365}= 0.225 \\ \\cdot 2.32 = 0.52\\)\n\\(\\phi_{21} = \\alpha_{21} \\sqrt{\\lambda_{1}} = 0.239 \\ \\cdot \\sqrt{5.365}= 0.239 \\ \\cdot 2.32 = 0.55\\)\n\\(\\phi_{31} = \\alpha_{31} \\sqrt{\\lambda_{1}} = 0.214 \\ \\cdot \\sqrt{5.365}= 0.214 \\ \\cdot 2.32 = 0.49\\)\n…\n\\(\\phi_{25 \\ 1} = \\alpha_{25 \\ 1} \\sqrt{\\lambda_{1}} = 0.166 \\ \\cdot \\sqrt{5.365}= 0.166 \\ \\cdot 2.32 = 0.38\\)\n \nAll 25 loadings for the first principal component (PC1) are shown below:\n\n\n [1] 0.52 0.55 0.49 0.52 0.51 0.40 0.56 0.48 0.40 0.42 0.58 0.58 0.51 0.50 0.56\n[16] 0.54 0.41 0.43 0.40 0.33 0.29 0.34 0.35 0.33 0.38\n\n\n \n\n\n7.2.2 PC2\n\nEigenvector and eigenvalue for PC2\n\nThe second eigenvector \\(v_2=(\\alpha_{12}, \\alpha_{22}, ..., \\alpha_{p2})\\) is:\n\n\n [1] -0.224 -0.212 -0.201 -0.265 -0.221 -0.156 -0.082 -0.308 -0.212 -0.245\n[11]  0.240  0.287  0.173  0.079  0.143 -0.005  0.159  0.093  0.025  0.168\n[21]  0.022  0.151  0.309  0.284  0.237\n\n\nTherefore, \\(a_{12} = -0.224\\), \\(a_{22} = -0.212\\), \\(a_{32} = -0.201\\),…, \\(a_{25 \\ 2} = 0.237\\) etc.\n \nThe corresponding eigenvalue, \\(\\lambda_{2}\\), is:\n\n\n[1] 1.706\n\n\n \n\nLoadings of PC2\n\nNow, we are ready to calculate the loadings \\(\\phi_{12}, \\phi_{22},..., \\phi_{p2}\\) of the second principal component according to the formula:\n\\[\\phi_{i2} = \\alpha_{i2} \\sqrt{\\lambda_{2}}\\]\nwhere \\(i= 1,...p\\).\nFor example:\n\\(\\phi_{12} = \\alpha_{12} \\sqrt{\\lambda_{2}} = -0.224 \\ \\cdot \\sqrt{1.706}= -0.224 \\ \\cdot 1.3 = -0.29\\)\n\\(\\phi_{22} = \\alpha_{22} \\sqrt{\\lambda_{2}} = -0.212 \\ \\cdot \\sqrt{1.706}= -0.212 \\ \\cdot 1.3 = -0.28\\)\n\\(\\phi_{32} = \\alpha_{32} \\sqrt{\\lambda_{2}} = -0.201 \\ \\cdot \\sqrt{1.706}= -0.201 \\ \\cdot 1.3 = -0.26\\)\n…\n\\(\\phi_{25 \\ 2} = \\alpha_{25 \\ 2} \\sqrt{\\lambda_{2}} = 0.237 \\ \\cdot \\sqrt{1.706}= 0.237 \\ \\cdot 1.3 = 0.31\\)\n \nAll 25 loadings for the second principal component (PC2) are shown below:\n\n\n [1] -0.29 -0.28 -0.26 -0.35 -0.29 -0.20 -0.11 -0.40 -0.28 -0.32  0.31  0.38\n[13]  0.23  0.10  0.19 -0.01  0.21  0.12  0.03  0.22  0.03  0.20  0.40  0.37\n[25]  0.31\n\n\nThe same procedure can be applied to calculate the loadings of the third principal component (PC3), the fourth component (PC4) and so on for subsequent components. Therefore, the loadings are scaled versions of eigenvectors that reflect both direction and strength of association.\n(NOTE: The previously computed component loadings were obtained without applying any rotation method.)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#eigenvalues-and-variance",
    "href": "pca.html#eigenvalues-and-variance",
    "title": "7  Principal Components Analysis",
    "section": "7.3 Eigenvalues and variance",
    "text": "7.3 Eigenvalues and variance\nA fundamental aspect of principal component analysis (PCA) is understanding how eigenvalues relate to the variance in the dataset.\nEach of the 25 eigenvectors has an associated eigenvalue, \\(\\lambda_1, \\lambda_2, ... \\lambda_p\\), as shown below:\n\n\n [1] 5.3654707 1.7059541 1.5384132 1.2206643 1.0777632 1.0395105 1.0223027\n [8] 0.9764029 0.9456935 0.9039208 0.8420446 0.8298040 0.7462031 0.7344016\n[15] 0.6934445 0.6803484 0.6360415 0.6105103 0.5829854 0.5460390 0.5059900\n[22] 0.4808372 0.4546453 0.4498703 0.4107389\n\n\nThe sum of the eigenvalues will equal the number of variables in the data set:\n\\[\\lambda_1 + \\lambda_2 + \\lambda_3 + ...+ \\lambda_p = 5.37 + 1.71 + 1.54 +...+ 0.41 = 25\\]\nTo determine the proportion of variance explained by the first principal component (i.e., direction by that component), we use the following formula:\n\\[\\frac{\\lambda_1}{\\lambda_1 + \\lambda_2 + \\lambda_3 + ...+ \\lambda_p} = \\frac{5.37}{25} = 0.215 \\ or \\ 21.5\\%\\]\nSimilarly, the explained variance by the second principal component is:\n\\[\\frac{\\lambda_2}{\\lambda_1 + \\lambda_2 + \\lambda_3 + ...+ \\lambda_p} = \\frac{1.71}{25} = 0.068 \\ or \\ 6.8\\%\\]\nNote that the first component captures the maximum variance, the second captures the next highest variance orthogonal to the first, and so on.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#steps-in-the-process-of-pca",
    "href": "pca.html#steps-in-the-process-of-pca",
    "title": "7  Principal Components Analysis",
    "section": "7.4 Steps in the process of PCA",
    "text": "7.4 Steps in the process of PCA\n\nPrepare the Data: (a) Standardize the items to have a mean of 0 and a standard deviation of 1. This ensures that variables with larger scales do not dominate the principal components. However, in practice, Likert scale data are typically not standardized, as the scale is generally considered consistent across items. (b) Address outliers in the data. Note that outliers in Likert data are often extreme values, such as respondents who consistently select the “0 = not at all stressful” or “5 = extremely stressful” option. (c) Additionally, it is important to reverse-score negatively worded items (if applicable) to ensure that all items are scaled in the same direction.\nEvaluate Assumptions: Assess the suitability of the data for PCA using diagnostic tests such as the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and Bartlett’s test of sphericity. These tests determine whether the correlation matrix is appropriate for component extraction.\nDetermine the Number of Components: Identify how many components to retain, guided by criteria such as eigenvalues greater than one (Kaiser Criterion), scree plot inspection, parallel analysis, interpretability of components, or a combination of these methods. The goal is to select the number of components that represent meaningful dimensions, effectively capturing the most important sources of variance in the data.\nExtract the principal components: Once the number of components to retain is decided, select the eigenvectors that correspond to the most important directions (those with the largest eigenvalues). These eigenvectors represent the principal components (PCs) of interest, which are the new axes that capture the most variance in the data.\nRotate Components (optional): After extracting the components, consider applying an orthogonal rotation (e.g., varimax) to clarify the component structure. Keep in mind that rotation is optional in PCA and affects interpretability but not the total variance explained.\nCompute the component scores: Once the component structure is finalized, compute the component scores for each observation. These scores represent the data projected onto the new principal component axes. Component scores can be used in further analyses, such as visualization (e.g., creating scatter plots of the first two components), clustering, or regression.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#example-of-grms-stress-appraisal",
    "href": "pca.html#example-of-grms-stress-appraisal",
    "title": "7  Principal Components Analysis",
    "section": "7.5 Example of GRMS Stress Appraisal",
    "text": "7.5 Example of GRMS Stress Appraisal\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Factor) -.-&gt; C(Principal Component Analysis)\n\n\n\n\n\n\nas shown below (Figure 7.3).\n\n\n\n\n\n\nFigure 7.3: Select from Factor the Principal Component Analysis.\n\n\n\nThe Principal Component Analysis box opens (Figure 7.3). From the left-hand pane drag all the variables into the Variables field on the right-hand side, as shown below (Figure 7.4):\n\n\n\n\n\n\nFigure 7.4: Principal Component Analysis box options. Drag and drop the variables in the fields on the right-hand side.\n\n\n\nAll variables in the dataset are on the same scale (Likert scale).\n\n7.5.1 Assumptions\nFrom the Assumption Checks, tick both boxes: Bartlett’s test of sphericity and KMO measure of Sampling Adequacy.\n\n\n\n\n\n\nFigure 7.5: Assumptions for PCA.\n\n\n\n\nBartlett’s test of sphericity\n\nBartlett’s test examines the null hypothesis that the correlation matrix is an identity matrix—meaning all the variables are uncorrelated (i.e., the off-diagonal elements are zero). A significant result (p &lt; 0.05) indicates that the correlation matrix significantly differs from an identity matrix, suggesting that the variables share enough correlation to justify the use of principal component analysis (PCA).\n\n\n\n\n\n\nFigure 7.6: Bartlett’s test.\n\n\n\nOur Bartlett’s test is significant: \\(\\chi^2 = 1217\\) (p&lt;0.001). This means that our sample correlation matrix is statistically significantly different than an identity matrix and, therefore, supports a component analytic approach for investigating the data.\n\nKaiser-Meyer-Olkin (MKO) index of Sampling Adequacy\n\nThe Kaiser-Meyer-Olkin index (KMO) is an index of sampling adequacy that varies between 0 and 1. Kaiser’s 1974 recommendations were:\n\nbare minimum of 0.5\nvalues between 0.5 and 0.7 as mediocre\nvalues between 0.7 and 0.8 as good\nvalues between 0.8 and 0.9 as great\nvalues above 0.9 are superb\n\nIf the KMO is below the recommendations, we should probably collect more data to see if it can achieve a satisfactory value.\n\n\n\n\n\n\nFigure 7.7: Kaiser-Meyer-Olkin measure.\n\n\n\nThe Kaiser–Meyer–Olkin (KMO) measure verified the sampling adequacy for the analysis KMO = 0.85, which is considered “great”. Additionally, all individual KMO values were above 0.74—well above the acceptable threshold of 0.50.\n\n\n7.5.2 Specify the Number of Components\nSince PCA produces as many components as there are original variables, we need criteria to decide how many of them capture meaningful structure in the data\nOur decisions on how many components to keep can be guided by several methods:\n\nCumulative variance explained – Retain enough components to account for a desired proportion of total variance.\nParallel analysis – Compare the observed eigenvalues with those obtained from randomly generated data to determine which components are meaningful.\nKaiser’s criterion – Retain components with eigenvalues greater than 1.\nTheoretical justification (“meaningfulness criterion”) – Retain components that align with prior knowledge, conceptual frameworks, or hypotheses relevant to the domain of study (fixed number).\n\nJamovi allows users to choose the number of components based on parallel analysis, eigenvalues, or by manually specifying a fixed number.\n\n\n\n\n\n\nFigure 7.8: Choose a method to define the number of components.\n\n\n\nAdditionally, a scree plot displays the eigenvalues associated with each principal component in descending order. It is used to visually identify the “elbow point”—the point at which the rate of decline in eigenvalues noticeably levels off. This point suggests the optimal number of components to retain, as additional components contribute relatively little to explaining variance.\n\n\n\n\n\n\nFigure 7.9: Scree plot.\n\n\n\n\n\n\n\n\n\nFigure 7.10: Scree plot determining the number of components based on parallel analysis.\n\n\n\n\n\n\n\n\n\nFigure 7.11: Scree plot determining the number of components based on Kaiser’s criterion.\n\n\n\nIn our example, parallel analysis suggests retaining 3 components (Figure 7.10), while Kaiser’s criterion indicates 7 components (Figure 7.11). We could also explore retaining 4, 5, or 6 components, as these values fall between the two suggested numbers.\nFor the purposes of this analysis, let’s retain the first four components.\n\n\n\n\n\n\nFigure 7.12: Select four principal components.\n\n\n\n\n\n7.5.3 Component Rotation\nIn PCA, components are by definition orthogonal and ordered by the amount of variance each explains. Although the unrotated solution already maximizes total variance, applying a rotation—while not mathematically required—can greatly enhance interpretability. Rotation redistributes variance across components (without changing the overall variance explained) to achieve a “simple structure,” in which each variable loads highly on one component and minimally on the others. This clarifies the grouping of variables and makes the underlying dimensions easier to understand.\nJamovi supports two options for rotation in PCA:\n\nOrthogonal Rotation: Methods like Varimax keep the components uncorrelated (i.e., orthogonal). This preserves the core mathematical properties of PCA, ensuring that the components remain independent.\nOblique Rotation: Jamovi offers methods like Promax and Oblimin that allow components to be correlated, which are more commonly used in Exploratory Factor Analysis (EFA). While oblique rotation can improve interpretability when underlying constructs are expected to be correlated, it departs from the strict orthogonality assumption of PCA. As a result, the components are no longer independent, which can make PCA less appropriate in situations where correlated factors are theorized.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#pca-with-varimax-rotation",
    "href": "pca.html#pca-with-varimax-rotation",
    "title": "7  Principal Components Analysis",
    "section": "7.6 PCA with Varimax rotation",
    "text": "7.6 PCA with Varimax rotation\nSelect the Varimax rotation method (which is the default):\n\n\n\n\n\n\nFigure 7.13: Select the Varimax method of rotation.\n\n\n\nAfter rotation, there are four clear components/dimensions (NOTE: In the unrotated method, that is “Rotation None” in Jamovi, most variables loaded on the first component).\n\n\n\n\n\n\nFigure 7.14: Loadings with orthogonal rotation.\n\n\n\nThere is clear (or at least reasonable) component membership for each variable. By default, the table displays all component loadings greater than 0.30. When an observed variable loads on multiple components above this threshold, it is examined for potential cross-loading. In this analysis, cross-loadings greater than 0.30 were identified for the following variables: Obj6, Marg6, and Ang1.\nIt is important to note that in PCA with orthogonal rotation (such as Varimax), the component loadings can be interpreted as correlation coefficients (Pearson’s r) between the original observed variables and the (rotated) component scores (see bellow in 7.7 how we can calculate these scores).\nIn the Figure 7.14, there is also a column labeled “uniqueness”. This represents the portion of a variable’s variance that is not explained by the \\(k\\) retained principal components.\n \nMoreover, under the Additional Output section, select Component summary:\n\n\n\n\n\n\nFigure 7.15: Select component summary.\n\n\n\nFigure 7.16 presents the percentage of variance in the variable set that is captured by the derived components after Varimax rotation.\n\n\n\n\n\n\nFigure 7.16: Variance with orthogonal rotation.\n\n\n\nThe SS Loadings column represents the eigenvalues for each component after Varimax rotation, with Principal Component 1 explaining 13.2% of the total variance, Principal Component 2 explaining an additional 11.7%, Principal Component 3 explaining an additional 8.2%, and Principal Component 4 explaining an additional 6.2%, resulting a cumulative variance of 39.3%.\nThe component analysis diagram below displays the dominant loading for each observed variable on its corresponding principal component (PC):\n\n\n\n\n\n\n\n\n\nBy examining the observed variables that load onto each principal component, we can assign conceptual meaning to the extracted dimensions as follows:\n\nPC 1: Assumptions of Beauty and Sexual Objectification (10 items; Obj1-Obj10)\nPC 2: Silenced and Marginalized (7 items; Marg1-Marg7)\nPC 3: Strong Woman Stereotype (6 items; Str1-Str5, Ang1)\nPC 4: Angry Woman Stereotype (2 items; Ang2 and Ang3)\n\nNote that the arrows originate from the items (Obj1, Obj2,…, Arg1, Str1, Ang1, etc.) and point toward the principal components (PC1, PC2, PC3, PC4).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#component-scores",
    "href": "pca.html#component-scores",
    "title": "7  Principal Components Analysis",
    "section": "7.7 Component scores",
    "text": "7.7 Component scores\nComponent scores represent each observation’s position on the extracted components. They are calculated as weighted combinations of the original variables, using the component loadings derived from PCA. After rotation, these scores reflect the rotated solution, providing insight into how each case (e.g., participant) scores on the newly defined components.\nTo compute the component scores, click on the Save dropdown menu and select the Component scores option (Figure 7.17).\n\n\n\n\n\n\nFigure 7.17: From the Save dropdown menu select the Component scores.\n\n\n\nNew variables have been created, each containing the component scores for the extracted components (Figure 7.18).\n\n\n\n\n\n\nFigure 7.18: Component scores after Varimax rotation.\n\n\n\n\n\n\n\nLewis, Jioni A., and Helen A. Neville. 2015. “Construction and Initial Validation of the Gendered Racial Microaggressions Scale for Black Women.” Journal of Counseling Psychology 62 (2): 289–302. https://doi.org/10.1037/cou0000062.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "efa.html",
    "href": "efa.html",
    "title": "8  Exploratory Factor Analysis",
    "section": "",
    "text": "8.1 Introduction\nAs we discussed in the previous chapter, Principal Component Analysis (PCA) is primarily used to reduce the dimensionality of the dataset while retaining as much of its total variance as possible. In this chapter, Exploratory Factor Analysis (EFA) focuses on identifying unobserved latent variables (also known as common factors) that explain the correlations among observed variables, with the aim of uncovering the data’s underlying structure.\nLet’s say we have \\(p\\) observed variables, denoted as \\(X_1, X_2, ..., X_p\\). The factor model for the \\(i\\)-th observed variable (\\(X_i\\)) for a single individual can be expressed as a regression on the common factors:\n\\[X_i = l_{i1}F_1 + l_{i2}F_2 + ...+ l_{ij}F_j +... + l_{ik}F_k + u_i\\]\nWhere:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "efa.html#introduction",
    "href": "efa.html#introduction",
    "title": "8  Exploratory Factor Analysis",
    "section": "",
    "text": "Observed variables (also called manifest variables) are the variables that we can directly measure or observe.\nLatent variables are hidden or abstract concepts inferred from manifest variables.\n\n\nExploratory Factor Analysis\nExploratory Factor Analysis (EFA) can be used to explore the dimensionality of a measurement instrument by identifying the smallest number of interpretable factors that explain the common variance among variables.\n\n\n\n\n\n\\(X_i\\) is the \\(i\\)-th observed variable (often standardized to have a mean of 0 and a standard deviation of 1).\n\\(F_j\\) is the \\(j\\)-th common factor (\\(j = 1, 2, ..., k\\)), which are the latent constructs we’re trying to uncover.\n\\(l_{ij}\\) is the factor loading of the \\(i\\)-th observed variable on the \\(j\\)-th common factor. It represents the strength and direction of the association between the observed variable and the factor.\n\\(k\\) is the number of common factors (where \\(k &lt; p\\)). This is a key parameter to determine in EFA.\n\\(u_i\\) is the unique factor associated with the observed variable \\(X_i\\). It represents the portion of the variance in \\(X_i\\) that cannot be explained by the common factors and is considered the specific variance of \\(X_i\\), unique to it and not shared with the other variables. The \\(u_i\\) terms are assumed to be uncorrelated with each other and with the common factors, and have a mean of 0.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "efa.html#steps-in-the-process-of-efa",
    "href": "efa.html#steps-in-the-process-of-efa",
    "title": "8  Exploratory Factor Analysis",
    "section": "8.2 Steps in the process of EFA",
    "text": "8.2 Steps in the process of EFA\n\nPrepare the Data: Standardize the data. In practice, Likert scale data are typically not standardized, as the scale is generally considered consistent across items. (b) Address outliers in the data. Note that outliers in Likert data are often extreme values, such as respondents who consistently select the “0 = not at all stressful” or “5 = extremely stressful” option. (c) Additionally, it is important to reverse-score negatively worded items to ensure that all items are scaled in the same direction (though this step is not applicable in our example).\nEvaluate Assumptions: Assess the suitability of the data for EFA using diagnostic tests such as the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and Bartlett’s test of sphericity. Additionally, examine the correlation matrix to ensure that variables are sufficiently correlated for factor analysis but without multicollinearity (extremely high correlations) or singularity (perfect correlations of 1 or -1). These tests determine whether the correlation matrix is appropriate for factor extraction.\nChoose the Extraction Method: Select an extraction method for factors (e.g., Principal Axis Factoring, Maximum Likelihood, or Maximum Residuals). Principal Axis Factoring is commonly used when we assume that underlying latent factors are driving correlations.\nDetermine the Number of Factors: Identify how many factors to extract, guided by criteria such as eigenvalues greater than one, scree plot inspection, or parallel analysis. These factors often correspond to underlying subscales.\nFactor Rotation: Apply a rotation method to simplify the factor structure. Orthogonal rotation (e.g., Varimax) assumes factors are uncorrelated. Oblique rotation (e.g., Oblimin, Promax) assumes factors are correlated.\nInterpret the Factors: Examine the factor loadings to interpret each factor. Look for variables that load highly on each factor and assign meaningful labels to the factors.\nAssess Factor Reliability: Use Cronbach’s Alpha to assess the internal consistency or reliability of the factors. A value above 0.7 indicates good reliability.\nRefine the Model: Based on the results, you may choose to drop items with low factor loadings or revise the number of factors. Ensure that any issues of singularity are addressed by removing highly correlated variables.\nFinalize the Factor Solution: Once the factors are interpretable and reliable, finalize the model and prepare the results for reporting.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "efa.html#example-of-grms-stress-appraisal",
    "href": "efa.html#example-of-grms-stress-appraisal",
    "title": "8  Exploratory Factor Analysis",
    "section": "8.3 Example of GRMS Stress Appraisal",
    "text": "8.3 Example of GRMS Stress Appraisal\nEXAMPLE DATA\nWe will use the same data from the study by Lewis and Neville (Lewis and Neville 2015) on the Gendered Racial Microaggressions Scale for Black Women.\n\n\n\n\n\n\n\n\nFigure 8.1: Table with raw data.\n\n\n\n\n\nUnattractive because of size of butt (Obj1)\nNegative comments about size of facial features (Obj2)\nImitated the way they think Black women speak (Obj3)\nSomeone made me feel unattractive (Obj4)\nNegative comment about skin tone (Obj5)\nSomeone assumed I speak a certain way (Obj6)\nObjectified me based on physical features(Obj7)\nSomeone assumed I have a certain body type (Obj8)\nMade a sexually inappropriate comment (Obj9)\nNegative comments about my hair when natural (Obj10)\nI have felt unheard (Marg1)\nMy comments have been ignored (Marg2)\nSomeone challenged my authority (Marg3)\nI have been disrespected in workplace (Marg4)\nSomeone has tried to “put me in my place” (Marg5)\nFelt excluded from networking opportunities (Marg6)\nAssumed I did not have much to contribute to the conversation (Marg7)\nSomeone assumed I was sassy and straightforward (Str1)\nI have been told that I am too independent (Str2)\nSomeone made me feel exotic as a Black woman (Str3)\nI have been told that I am too assertive (Str4)\nAssumed to be a strong Black woman (Str5)\nSomeone has told me to calm down (Ang1)\nPerceived to be “angry Black woman” (Ang2)\nSomeone accused me of being angry when speaking calm (Ang3)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "efa.html#efa-in-jamovi",
    "href": "efa.html#efa-in-jamovi",
    "title": "8  Exploratory Factor Analysis",
    "section": "8.4 EFA in Jamovi",
    "text": "8.4 EFA in Jamovi\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Factor) -.-&gt; C(Exploratory Factor Analysis)\n\n\n\n\n\n\nas shown below (Figure 8.2).\n\n\n\n\n\n\nFigure 8.2: Select Exploratory Factor Analysis from Factor.\n\n\n\nThe Exploratory Factor Analysis box opens. From the left-hand pane drag all the variables into the Variables field on the right-hand side, as shown below (Figure 8.3):\n\n\n\n\n\n\nFigure 8.3: Exploratory Factor Analysis box options. Drag and drop the variables in the fields on the right-hand side.\n\n\n\nAll variables in the dataset are on the same scale (Likert scale).\n\n8.4.1 Assumptions\nThe assumption checks for EFA are similar to those in PCA (Bartlett’s test of sphericity, Kaiser-Meyer-Olkin (MKO) index of Sampling Adequacy; see Chapter 7). However, in Exploratory Factor Analysis, we are also particularly concerned with issues of multicollinearity and singularity in the data, as these can affect the reliability and interpretability of the factor model.\nOne way to assess this is by examining the determinant of the correlation matrix. If the determinant is smaller than 0.00001, this may indicate that some variables are too highly correlated (multicollinearity), or some variables are perfectly correlated (singularity), which can distort factor extraction.\n \nNOTE: The simplest case of a 2 × 2 correlation matrix, for example, with Obj1 and Obj2 variables, consists of two rows and two columns and is written as:\n\\[C = \\begin{bmatrix}\n    r_{11}       & r_{12} \\\\\n    r_{21}       & r_{22} \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n    1       & 0.35 \\\\\n    0.35       & 1 \\\\\n\\end{bmatrix} \\]\nHere, \\(r_{11}\\) and \\(r_{22}\\) represent the correlation of each variable with itself (which is always 1), and \\(r_{12}\\) and \\(r_{21}\\) represent the correlation between Obj1 and Obj2 (which is 0.35 in this example).\nThe determinant of C is calculated as: \\(\\text{det}(C) = r_{11} \\cdot r_{22} - r_{12} \\cdot r_{21} = 1 \\cdot 1 - 0.35 \\cdot 0.35 = 1-0.123 = 0.877\\).\n \nIn our example, the determinant of the correlation matrix (a 25 x 25 matrix with Pearson’s correlations) can be calculated using a simple line of code in the Rj Editor+ of Jamovi:\n\n\n\n\n\n\nFigure 8.4: Calculation of determinant of correlation matrix in RJ Editor.\n\n\n\n\n\n[1] 0.0075\n\n\nWith a value of 0.0075, the determinant is comfortably above the 0.00001 threshold, indicating that our data is appropriate for factor analysis.\nIf the determinant were below the threshold, we would need to identify and address problematic variables—those that are either overly correlated or not correlated sufficiently with others—and then re-run the diagnostic checks.\n\n\n8.4.2 Specify the Number of Factors\nWhen researchers lack a clear theoretical framework to guide their analysis, they often adopt an iterative approach, exploring multiple solutions by extracting varying numbers of factors. For example, Lewis and Neville (2015) examined models with two, three, four, and five factors. In this example, we will present a four-factor solution as the selected model:\nTherefore, we select “Fixed number” and type 4 in the number of factors:\n\n\n\n\n\n\nFigure 8.5: Select the number of factor for a four-factor model.\n\n\n\nWe can also obtain the scree plot from the Additional Output:\n\n\n\n\n\n\nFigure 8.6: Select Scree plot from the Additional Output.\n\n\n\n\n\n\n\n\n\nFigure 8.7: Scree plot.\n\n\n\n\n\n8.4.3 Extraction of factors and rotation\nLewis and Neville (2015) used parallel analysis as their extraction method. In this example, we demonstrate the use of Principal Axis Factoring (PAF) for extraction and Oblimin (the default option) as the rotation method.\n\n\n\n\n\n\nFigure 8.8: Select the Principal Axis for extraction and Oblimin method of rotation.\n\n\n\nAdditionally, we hide loading below 0.23 (the default is 0.3):\n\n\n\n\n\n\nFigure 8.9: Hide loadings below 0.23.\n\n\n\nFigure 8.10 shows the loadings of the factors after Oblimin rotation.\n\n\n\n\n\n\nFigure 8.10: Factor Loadings using Pricipal axis factoring in combination with Oblimin rotation (pattern matrix).\n\n\n\nIn the rotated factor matrix, a few items exhibit cross-loadings, meaning they load significantly on more than one factor:\n\nObj6 loads on both Factor 1 and Factor 4, with loadings of 0.43 and 0.25, respectively. While the item shows some association with both factors, its stronger loading on Factor 1 suggests it aligns more closely with the Objectification construct.\nMarg6 also displays cross-loadings, with loadings of 0.31 on Factor 1 and 0.25 on Factor 2. Though both values are relatively low, the item may still require closer evaluation to determine its conceptual alignment.\nAng1 loads on both Factor 3 and Factor 4, with loadings of 0.33 and 0.24, respectively. Although neither loading is particularly high, this item should be reviewed in the context of theoretical expectations.\n\nNOTE: In oblique rotation, a distinction is made between the pattern matrix and the structure matrix. The pattern matrix (Figure 8.10) displays the standardized regression coefficients (i.e., factor loadings) of each factor on each observed variable, reflecting the direct effects while controlling for the influence of other factors. In contrast, the structure matrix presents the simple correlations between each observed variable and each factor, reflecting both direct and indirect effects (due to factor intercorrelations) without controlling for the overlap among factors (this matrix is not included in the Jamovi output).\n \nPartitioning the variance in factor analysis\nFactor analysis assumes that variance can be partitioned into two types of variance: common and unique.\n\nCommon variance (communality), denoted usually as \\(h^2\\), represents the portion of a variable’s variance that is shared with other variables and is explained by the underlying common factors (NOTE: A critical difference between PCA and EFA is that factor analysis only attempts to account for common variance, not total variance).\nUnique variance (uniqueness), denoted usually as \\(u^2\\), represents the portion of variance that is specific to the variable itself and not explained by the common factors. The greater “uniqueness” the lower the relevance of the variable in the factor model. For example, if a variable has high uniqueness (close to 1), it indicates that the variable is poorly explained by the selected number of factors.\n\n\n\n8.4.4 Explained variance and model fit\nUnder the Additional Output section, select Factor summary, Factor correlations, and Model fit measures:\n\n\n\n\n\n\nFigure 8.11: Select Factor summary, correlations, and model fit measures.\n\n\n\n \nExplained variance\nFigure 8.12 presents the percentage of common variance in the variable set that is captured by the derived factors after Oblimin rotation.\n\n\n\n\n\n\nFigure 8.12: Common variance explained.\n\n\n\nFactor 1 explains 11.2% of the shared variance, Factor 2 explains an additional 8.1%, Factor 3 explains another 5.5%, and Factor 4 explains an additional 3.6%, resulting in a cumulative common variance of 28.4% explained by the first four factors.\nAlthough explaining about 30% of the common variance may seem modest, it is not uncommon in social science research, particularly when dealing with psychological or behavioral constructs. These constructs are often complex and difficult to measure precisely, which can lead to lower levels of explained variance.\nThe Inter-Factor Correlation Matrix reveals that the four factors are positively correlated with each other, with correlations ranging from 0.17 to 0.46 (Figure 8.13).\n\n\n\n\n\n\nFigure 8.13: Inter-Factor Correlation Matrix.\n\n\n\n \nModel fit\nThe chi-square test can be used to assess whether the model fits the data. The null hypothesis for the chi-square test is that the model fits the data perfectly. Therefore, a non-significant chi-square value (e.g., p &gt; 0.05) indicates that the model fits the data reasonably well. However, the chi-square test is sensitive to sample size and non-normal variable distributions (Figure 8.14).\nIn addition to the chi-square test, the root mean square error of approximation (RMSEA) serves as an absolute fit index that takes model complexity into account by incorporating a penalty for lack of parsimony. RMSEA values less than or equal to 0.08 are typically interpreted as good model fit.\n\n\n\n\n\n\nFigure 8.14: Measures of model fit.\n\n\n\nIn our model: \\(\\chi^2(206)= 189.19\\), p = 0.794, which is non-significant and suggests that the model fits the data well. Moreover, the RMSEA value is 0.00, indicating a close fit between the model and the observed data.\nThese results suggest that the model structure is appropriate, even if the strength of the factors is modest.\n\n\n8.4.5 Path diagram\nThe path diagram for the four-factor, 25 items EFA, showing only the dominant loading per item (for clarity) follows:\n\n\n\n\n\n\n\n\n\nThis diagram illustrates how the observed variables can be grouped together, allowing us to identify the following common factors (latent variables). These factors can also be considered as the subscales of the questionnaire:\n\nFactor 1: Assumptions of Beauty and Sexual Objectification (11 items; Obj1-Obj10 and Marg6)\nFactor 2: Silenced and Marginalized (6 items; Marg1-Marg5, Marg7)\nFactor 3: Strong Woman Stereotype (6 items; Str1-Str5, Ang1)\nFactor 4: Angry Woman Stereotype (2 items; Ang2 and Ang3)\n\nIt is important to note that the arrows point from the factor (oval) to the observed variables (items in squares) illustrating that the factor “explains” the item’s score. This represents a reflective model, in which the latent construct exists independently of the measures. Additionally, note that the path diagram includes links with numerical values between latent factors, representing the correlation coefficients among them.\n\n\n8.4.6 Factor scores\nFactor scores can be estimated for each case (row) on each latent factor (unobserved variables). These scores can be used to investigate the associations between the factors and other variables or to represent the underlying factors for subsequent analysis. For example, factor scores are often used in regression models (in place of means or sums) when predictors are highly correlated, helping to address multicollinearity.\nThere are several estimation methods for obtaining factor scores in EFA using Jamovi, with each method having different assumptions and advantages.\nWhen using Oblimin rotation (which allows factors to be correlated), the best methods for estimating factor scores are ten Berge’s method and Bartlett’s method. Ten Berge’s method is generally considered the most accurate because it specifically adjusts for factor correlations using generalized least squares. Bartlett’s method is also a strong choice, producing consistent scores while accounting for factor correlations. In contrast, Anderson-Rubin’s method should be avoided because it forces factor scores to be uncorrelated, which conflicts with the purpose of Oblimin. Thurstone’s method can be used but is less optimal, and Harman’s method is not recommended because it does not properly adjust for correlated factors.\nIn our example, we select the ten Berge’s method (Figure 8.15).\n\n\n\n\n\n\nFigure 8.15: Select Factor scores and ten Berge estimation method.\n\n\n\n \n\n\n\n\n\n\nFigure 8.16: Factor scores usin ten Berge estimation method.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "efa.html#reliability-analysis",
    "href": "efa.html#reliability-analysis",
    "title": "8  Exploratory Factor Analysis",
    "section": "8.5 Reliability analysis",
    "text": "8.5 Reliability analysis\nAn important step in establishing the integrity of factors derived from a factor analysis (which will ultimately be presented as subscales of the scale) is to assess their internal consistency as an initial indicator of reliability.\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Factor) -.-&gt; C(Reliability Analysis)\n\n\n\n\n\n\nas shown below (Figure 8.17).\n\n\n\n\n\n\nFigure 8.17: Select Reliability Analysis from Factor.\n\n\n\n \nWe have four derived factors, so we will run Cronbach’s reliability analyis four times-once for each subset of observed variables (items) grouped by the factor analysis.\nFrom the Scale Statistics options, select Cronbach’s \\(\\alpha\\) :\n\n\n\n\n\n\nFigure 8.18: Select Cronbach’s alpha from Scale Statistics.\n\n\n\n(Note that there is also a menu option for “Reverse Scaled Items” for items that need to have their scores reversed).\n \n\n\n\n\n\n\nFigure 8.19: Cronbach’s alpha for factor 1.\n\n\n\n \n\n\n\n\n\n\nFigure 8.20: Cronbach’s alpha for factor 2.\n\n\n\n \n\n\n\n\n\n\nFigure 8.21: Cronbach’s alpha for factor 3.\n\n\n\n \n\n\n\n\n\n\nFigure 8.22: Cronbach’s alpha for factor 4.\n\n\n\n\n\n\n\nLewis, Jioni A., and Helen A. Neville. 2015. “Construction and Initial Validation of the Gendered Racial Microaggressions Scale for Black Women.” Journal of Counseling Psychology 62 (2): 289–302. https://doi.org/10.1037/cou0000062.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "path.html",
    "href": "path.html",
    "title": "9  Mediation and Path Analysis",
    "section": "",
    "text": "9.1 Mediation analysis\nA single mediation analysis is based on the estimation of the four pathways, w, a, b, and c shown in Figure 9.1. In Figure 9.1 A, the “w” path represents the total X→Y effect. In Figure 9.1 B, the “a” path represents the X→M effect, the “b” path represents the M→Y effect, and the “c” path represents the direct X→Y effect. In traditional mediation analysis, the paths coefficients are estimated using linear regression equations.\nMediation analysis is based on the assumption of temporal precedence of the independent variable X, mediator, and outcome, which means that changes in the X are assumed to precede changes in the mediator, and that changes in the mediator are assumed to precede changes in the outcome.\nIt is important to note that, like any regression-based analysis, mediation analysis cannot establish causal associations unless it is grounded in an experimental design. Drawing causal inferences requires rigorous methodological controls, including random assignment, temporal precedence, and the elimination of alternative explanations.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation and Path Analysis</span>"
    ]
  },
  {
    "objectID": "path.html#mediation-analysis",
    "href": "path.html#mediation-analysis",
    "title": "9  Mediation and Path Analysis",
    "section": "",
    "text": "Figure 9.1: Path diagram of a single mediator model.\n\n\n\n\n\n\nDirect and indirect effects\nMediation analysis decomposes the total X→Y effect (w) into a direct effect (c) and an indirect effect through a mediator variable, which is the product of a and b (axb).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation and Path Analysis</span>"
    ]
  },
  {
    "objectID": "path.html#example",
    "href": "path.html#example",
    "title": "9  Mediation and Path Analysis",
    "section": "9.2 Example",
    "text": "9.2 Example\nAssume that previous research has demonstrated that higher grades are associated with increased happiness: X (grades) → Y (happiness) (Figure 9.2 A). In our theory, we also hypothesize that good grades enhance self-esteem, which in turn increases happiness: X (grades) → M (self-esteem) → Y (happiness) (Figure 9.1 B).\n\n\n\n\n\n\nFigure 9.2: Path diagram of grades, self-esteem, and happiness model.\n\n\n\n \nImporting data\n\n\n\n\n\n\n\n\nFigure 9.3: Table with raw data.\n\n\n\n\nOpen the dataset named “happiness” from the file tab in the menu (Figure 9.3).\n\n9.2.1 Baron & Kenny method\nThe following shows the basic steps for mediation analysis suggested by Baron & Kenny (1986) (Baron and Kenny 1986). A mediation analysis is comprised of three sets of regression: (1) X → Y, (2) X → M, and (3) X + M → Y. This 3-step method used to describe a mediation effect. Steps 1 and 2 use basic linear regression while steps 3 use multiple regression.\n\nStep 1: Estimate the association between X on Y (grades on happiness). The total effect “w” must be significantly different from 0. If there is no association between X and Y, there is nothing to mediate.\n\n\n\n\nTotal effect of X on Y.\n\n\n\\[Y = intercept \\ + \\text{w} \\cdot X + e\\]\nwhere \\(e\\) is the residual error of the model (i.e. ).\n \n\n\\[happiness = 2.86 \\ + 0.40 \\cdot grades\\] Therefore, the total effect w = 0.40 is statistical significant (p&lt;0.001).\n(NOTE: Even if we don’t find a significant association between X and Y, we could move forward to the next step if we have a good theoretical background about their association.)\n \n\nStep 2: Estimate the association between X on M (grades on self-esteem). Path “a” must be significantly different from 0; The independent variable and the mediator must be associated. If X and M have no association, M is just a third variable that may or may not be associated with Y. A mediation makes sense only if X affects M.\n\n\n\n\n\n\n\nFigure 9.4: The effect of X on M.\n\n\n\n\\[M = intercept \\ + \\text{a} \\cdot X + e\\]\nwhere \\(e\\) is the residual error of the model.\n \n\n\\[selfesteem = 1.50 \\ + 0.56 \\cdot grades\\] Therefore, the effect of X on M (a = 0.56) is statistical significant (p&lt;0.001).\n \n\nStep 3: Estimate the effects of both X and M on Y. Path “b” must be significantly different from 0; mediator and outcome must be associated. Additionally, the path “c” should be non-significant and nearly 0. The effect of X on Y will disappear (or at least weaken) when M is included in the regression. The effect of X on Y goes through M.\n\n\n\n\n\n\n\nFigure 9.5: The effects of both X and M on Y.\n\n\n\n\\[Y = intercept \\ + c \\cdot X + \\text{b} \\cdot M + e\\]\nwhere \\(e\\) is the residual error of the model.\n \n\n\\[happiness = 1.90 \\ + 0.04 \\cdot grades + 0.64 \\cdot selfesteem\\]\nTherefore, the effect of M (self-esteem) on Y (happiness), controlling for X (grades), is statistically significant (b = 0.64, p &lt; 0.001), whereas the effect of X (grades) on Y (happiness), controlling for M (self-esteem), is weakened and not statistically significant (c = 0.04, p = 0.719).\n \nTotal, direct and indirect effects\n\nThe total effect (w = 0.40) is just the coefficient (w) we would find by fitting a simple regression model (e.g., \\(Y = intercept \\ + \\text{w} \\cdot X\\)).\nThe indirect effect is the effect of X on Y, through the mediator M. It’s obtained by multiplying \\(a \\times b = 0.56 \\times 0.64 = 0.36\\).\nThe direct effect (c = 0.04) is the partial effect of of X on Y after controlling for M.\n\n\n\n\n\n\n\nFigure 9.6: Direct and inderect effects.\n\n\n\nIn practice, a simple mediation model decompose the total effect of X on Y, in a direct and indirect effect. Therefore:\n\\[w = c + (a \\times b) = 0.04 + (0.56 \\times 0.64) = 0.04 + 0.36 = 0.40\\]\n\n\n9.2.2 Mediation Using Jamovi\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(medmod) -.-&gt; C(Mediation)\n\n\n\n\n\n\nas shown below in Figure 9.7.\n\n\n\n\n\n\nFigure 9.7: In the menu at the top, choose Analyses -&gt; medmod -&gt; Mediation.\n\n\n\n \nThe Mediation dialog box opens. From the left-hand pane drag the variable happiness into the Dependent Variable field, the variable selfesteem into the Mediator field, and the grades variable into the Predictor field as shown below (Figure 9.8).\nAdditionally, check Labels, Test Statistics, Confidence interval, Percent mediation, Path Estimates, and Estimate plot.\n\n\n\n\n\n\nFigure 9.8: Mediation box choices.\n\n\n\nFirst, Figure 9.9 presents the path estimates (regression coefficients):\n\na=0.56 (p &lt;0.001)\nb=0.64 (&lt;0.001)\nc = 0.04 (p = 0.714).\n\n\n\n\n\n\n\nFigure 9.9: Path estimates.\n\n\n\n \nSecond, Figure 9.10 presents the mediation estimates:\n\nThe indirect effect (\\(a \\times b = 0.36\\); p &lt;0.001).\nThe direct effect (c = 0.04; p = 0.714)\nThe total effect (w = c + axb = 0.40; p&lt;0.001)\n\n\n\n\n\n\n\nFigure 9.10: Mediation estimates.\n\n\n\n \nWe can also represent the mediation estimates in a plot:\n\n\n\n\n\n\nFigure 9.11: Mediation estimates plot.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation and Path Analysis</span>"
    ]
  },
  {
    "objectID": "path.html#conditional-mediation-model",
    "href": "path.html#conditional-mediation-model",
    "title": "9  Mediation and Path Analysis",
    "section": "9.3 Conditional mediation model",
    "text": "9.3 Conditional mediation model\n\nMediation analysis is intended to understand the mechanisms through which impacts. It is characterized by direct and indirect effects.\nModeration analysis consists in understanding the conditions which alter the association between X and Y. It is characterized by conditional effect.\nConditional process analysis is used to understand the conditions that affect the mechanisms by which a variable transmits its effect on another. It is characterized by conditional direct and indirect effect.\n\nIt is also called “moderated mediation”. Due to the complexity of human and social processes, conditional mediation models may generally be more appropriate than mediation and moderation models only.\nOnce we are familiar with mediation and moderation models, the intuition behind conditional process models is straightforward. When one of the paths of a mediation model is moderated, the corresponding direct or indirect effect becomes a conditional effect \\(\\theta\\).\n\n\n\n\n\n\nFigure 9.12: The conditional mediation model diagram.\n\n\n\n\n9.3.1 Importing data\n\n\n\n\n\n\n\n\nFigure 9.13: Table with raw data.\n\n\n\n\nOpen the dataset named “glbwarm” from the file tab in the menu (Figure 9.13).\nThe dataset contains the following variables:\n\ngovact: the extent to which the participant supports various policies or actions by the U.S. government to mitigate the threat of global climate change (e.g., how much the participant supports increasing government investment for developing alternative energy like biofuels, wind, or solar).\nnegemot: how frequently the participant reported feeling concerned, worried, and alarmed when thinking about climate change.\nposemot: how frequently reported feeling “hopeful,” “encouraged,” and “optimistic” about global climate change.\nsex: 0 = female, 1 = male.\n\n\n\n9.3.2 Regression equations for the model\nOur model is specified by two regression equations, one for M and one for Y.\n\nRegression equation for M:\n\n\\[M = intercept \\ + a_1 \\cdot X + a_2 \\cdot Z + a_3 \\cdot XZ\\]\nwhich is equivalent to\n\\[M = intercept \\ + (a_1 + a_3Z) \\cdot X + a_2 \\cdot Z\\]\nwhere \\(θ_{X\\rightarrow M}=a_1 + a_3Z\\) is the conditional effect of X on M.\n \n\n\n\n\n\n\nFigure 9.14: Linear regression dialog box for M.\n\n\n\n \n\n\n\n\n\n\nFigure 9.15: Model coefficients for Y.\n\n\n\nFor females (Z=0): \\(θ_{X\\rightarrow M}=0.117\\).\nFor males (Z=1): \\(θ_{X\\rightarrow M}=0.117 + 0.010 = 0.127\\).\n \n\nRegression equation for Y\n\n\\[Y = intercept \\ + c_1 \\cdot X + c_2 \\cdot Z + c_3 \\cdot XZ + b \\cdot M\\]\nwhich is equivalent to\n\\[Y = intercept \\ + (c_1 + c_3Z) \\cdot X + c_2 \\cdot Z + b \\cdot M\\]\nwhere \\(θ_{X\\rightarrow Y}=c_1 + c_3Z\\) is the conditional direct effect of X on Y.\n \n\n\n\n\n\n\nFigure 9.16: Linear regression dialog box for Y.\n\n\n\n \n\n\n\n\n\n\nFigure 9.17: Model coefficients for Y.\n\n\n\nTherefore, the conditional direct effects of X on Y are:\nFor females (Z=0): \\(θ_{X\\rightarrow Y} = 0.373\\).\nFor males (Z=1): \\(θ_{X\\rightarrow Y} = 0.373 + 0.265 = 0.638\\).\n \n\n\n9.3.3 The conditional indirect effects\nThe conditional indirect effect of X on Y through M is the product of the conditional effect of X on M and the effect \\(b\\) of M on Y:\n\nFor females (Z=0): \\(θ_{X\\rightarrow M} \\times b = 0.117 \\times (-0.03) = -0.0035\\).\nFor males (Z=1): \\(θ_{X\\rightarrow M} \\times b = 0.127 \\times (-0.03) = -0.0038\\).\n\n \n\n\n9.3.4 Total effects\n\n\n\n\n\n\nFigure 9.18: Path diagram with model estimates for females (Z=0).\n\n\n\nTherefore, the total effect is the sum of conditional direct and indirect effects: 0.373 + (- 0.0035) = 0.367.\n\n\n\n\n\n\nFigure 9.19: Path diagram with model estimates for males (Z=1).\n\n\n\nTherefore, the total effect is the sum of conditional direct and indirect effects: 0.638 + (- 0.0038) = 0.634.\n \n\n\n9.3.5 Conditional mediation using Jamovi\nThis analysis can be achieved in Jamovi as follows:\nOn the top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(medmod) -.-&gt; C(GLM Mediation Analysis)\n\n\n\n\n\n\nas shown below in Figure 9.7.\n\n\n\n\n\n\nFigure 9.20: In the menu at the top, choose Analyses -&gt; medmod -&gt; GLM Mediation Analysis.\n\n\n\n \n\n\n\n\n\n\nFigure 9.21: GLM Mediation model dialog box.\n\n\n\n \n\n\n\n\n\n\nFigure 9.22: Model building choices.\n\n\n\n \n\n\n\n\n\n\nFigure 9.23: Conditional mediation model estimates.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation and Path Analysis</span>"
    ]
  },
  {
    "objectID": "path.html#path-analysis",
    "href": "path.html#path-analysis",
    "title": "9  Mediation and Path Analysis",
    "section": "9.4 Path analysis",
    "text": "9.4 Path analysis\n\n9.4.1 Basic concepts\nPath analysis can be used to test more complex theories of observed variables. In this example, we look at the theory of planned behavior (TPB). This theory is a psychological theory that links beliefs to behavior. In its simplified form, the TPB proposes that an individual’s intention to perform a specific behavior influences the individual’s decision to enact that behavior, and attitude toward the behavior, perception of norms pertaining to that behavior, and perception of control over performing that behavior influence the individual’s intention to perform the behavior.\nWe can specify the Theory of Planned Behavior as a path diagram by drawing the observed variables and the directional associations (paths) between the variables as implied by the theory, where rectangles represent the variables and directional arrows represent the directional relations between variables, which is depicted in the path diagram below:\n\n\n\n\n\n\nFigure 9.24: Model diagram.\n\n\n\n\nExogenous variables: Independent variables that are influenced by factors outside the model and, in turn, influence endogenous variables. In path diagrams, arrows originate from exogenous variables but do not point to them.\nEndogenous variables: Dependent variables that are explained by exogenous variables in the model. Arrows point toward them and these represent causal paths. Note that an endogenous variable may also be specified as the predictor of another endogenous variable, as is the case in our example path diagram.\nPath coefficients are regression coefficients (typically denoted as \\(\\beta_1-\\beta_4\\), or sometimes as \\(p_1-p_4\\)) that represent direct effects of one variable on another.\nVariances are typically represented as curved double-sided arrows, where both arrows point to the same variable. Covariances are also represented as double-sided arrows in which the arrows connect two distinct variables.\n(Residual) error terms (which are sometimes called disturbances) are added to endogenous variables.\n\nThe equations of this model are:\n\\[intention = intercept +  \\beta_1 attitude + \\beta_2 norms + \\beta_3 control + e\\]\nand\n\\[behavior = intercept + \\beta_4 intention + e\\]\n\n\n9.4.2 Importing data\n\n\n\n\n\n\n\n\nFigure 9.25: Table with raw data.\n\n\n\n\nOpen the dataset named “PlannedBehavior” from the file tab in the menu (Figure 9.25).\n\n\n9.4.3 Path Analysis using Jamovi\nThis analysis can be achieved in Jamovi as follows:\nOn the top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(SEM) -.-&gt; C(Path Analysis)\n\n\n\n\n\n\nas shown below in Figure 9.7.\n\n\n\n\n\n\nFigure 9.26: In the menu at the top, choose Analyses -&gt; SEM -&gt; Path Analysis.\n\n\n\n \nThe Path Analysis dialog box opens. From the left-hand pane drag the variables behavior and intention into the Endogenous Variable field, and the variables attitude, norms into the Mediator field, and the grades variable into the Predictor field as shown below (Figure 9.27).\n\n\n\n\n\n\nFigure 9.27: Path analysis dialog box.\n\n\n\n \nNext we specify the variables of each endogenous variable (Figure 9.28). First we select on the right panel the endogenous model that needs to be set, then select the variable(s) and fill the Models for Endogenous Vars field clicking the arrow.\n\n\n\n\n\n\nFigure 9.28: Endogenous Model determination.\n\n\n\n \nWithin the “Parameter Options” menu, also select the Indirect Effects (Figure 9.29).\n\n\n\n\n\n\nFigure 9.29: Parameters Options. Check Inderect Effects.\n\n\n\n \nThe direct effects (path coefficients) are obtained from regression analysis.\nThe table in Figure 9.30 summarizes hypotheses testing results of the study.\n\n\n\n\n\n\nFigure 9.30: Parameter Estimates of the model.\n\n\n\nThe path coefficient (i.e., regression coefficient b) between attitude and intention is statistically significant and positive (b = 0.352, p &lt; 0.001). The path coefficient between norms and intention is statistically significant and positive (b = 0.153, p = 0.010). The path coefficient between control and intention is statistically significant and positive (b = 0.275, p &lt; 0.001). Finally, the path coefficient between intention and behavior is statistically significant and positive (b = 0.453, p &lt; 0.001).\n \nThe intercepts of the equations of the model are following:\n\n\n\n\n\n\nFigure 9.31: The intercepts of the equation model.\n\n\n\nAccording the outputs of Figure 9.30 and Figure 9.31, the equations can be expressed as follows:\n\\[intention = 0.586 + 0.352 \\cdot attitude + 0.153 \\cdot norms + 0.275 \\cdot control\\]\nand\n\\[behavior = 1.743 + 0.453 \\cdot intention\\]\n \nUnder the “R-Squared” table, we see the unadjusted R2 value for the outcome variable intention, which is equal to 0.369; that is, collectively, attitude, norms, and control explain 36.9% of the variance in intention. Additionally, intention explains 19.8% of the variance in behavior (Figure 9.32).\n\n\n\n\n\n\nFigure 9.32: R-Squared values of the model.\n\n\n\n \nMoreover, the indirect effects are reported in the following table:\n\n\n\n\n\n\nFigure 9.33: Indirect effects.\n\n\n\nFor example, the estimate for the indirect effect of the path attitude=&gt;intention=&gt;behavior is calculated as 0.35*0.45 = 0.16.\n \nUsing path analysis, we can also explicitly model the variance of the exogenous variables (e.g., attitude-attitude variance=0.93), the covariances (correlations) between the exogenous variables (e.g., norms-attitude covariance= 0.20), and the residual errors of the endogenous variables in the model (e.g., intention res. error = 0.53).\n\n\n\n\n\n\nFigure 9.34: Variances and Covariances estimates.\n\n\n\n \nWe can also present the model with a path diagram. All options regard aesthetics of the diagram are shown in Figure 9.35.\n\n\n\n\n\n\nFigure 9.35: Path Diagram choices. Check Residuals for variances (residual errors).\n\n\n\n \n\n\n\n\n\n\nFigure 9.36: Path diagram of the model with observed variables.\n\n\n\n\n\n\n\nBaron, Reuben M., and David A. Kenny. 1986. “The Moderatormediator Variable Distinction in Social Psychological Research: Conceptual, Strategic, and Statistical Considerations.” Journal of Personality and Social Psychology 51 (6): 1173–82. https://doi.org/10.1037/0022-3514.51.6.1173.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation and Path Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html",
    "href": "cfa.html",
    "title": "10  Confirmatory Factor Analysis",
    "section": "",
    "text": "10.1 Introduction\nExploratory factor analysis (EFA) can be used to identify common factors and factor structure among a set of observed variables / indicators (Figure 10.1). Confirmatory factor analysis (CFA) can be used to study how well a hypothesized factor model fits a new sample from the same population or a sample from a different population. The CFA model is the same as the EFA model with the exception that restrictions can be placed on factor loadings, variances, covariances, and residual variances resulting in a more parsimonious model (Figure 10.2).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#introduction",
    "href": "cfa.html#introduction",
    "title": "10  Confirmatory Factor Analysis",
    "section": "",
    "text": "Figure 10.1: In an Exploratory Factor Analysis (EFA) model, all possible associations between latent variables (factors) and observed variables (items) are estimated. That is, each item is allowed to load on every factor, enabling the analysis to uncover the underlying structure without imposing prior constraints.\n\n\n\n\n\n\n\n\n\nFigure 10.2: In a Confirmatory Factor Analysis (CFA) model, we explicitly constrain many of the associations (factor loadings) between latent variables (factors) and observed variables (items) to be zero.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#first-order-cfa-model",
    "href": "cfa.html#first-order-cfa-model",
    "title": "10  Confirmatory Factor Analysis",
    "section": "10.2 First-order CFA model",
    "text": "10.2 First-order CFA model\nEXAMPLE DATA\nOur data analysis is based on the paper published by Keum et al’s Gendered Racial Microaggressions Scale for Asian American Women. This article reported support for a total scale score (22 items) and four subscales. Items were rated on a 6-point Likert scale ranging from 0 (not at all stressful) to 5 (extremely stressful).\n\n\n\n\n\n\n\n\nFigure 10.3: Table with raw data.\n\n\n\n\nBelow, we outline the four subscales, including the number of items in each, their abbreviations, and a sample item representing each factor:\n\nAscribed Submissiveness (9 items)\n\nOthers expect me to be submissive. (AS1)\nOthers have been surprised when I disagree with them. (AS2)\nOthers take my silence as a sign of compliance. (AS3)\nOthers have been surprised when I do things independent of my family. (AS4)\nOthers have implied that AAW seem content for being a subordinate. (AS5)\nOthers treat me as if I will always comply with their requests. (AS6)\nOthers expect me to sacrifice my own needs to take care of others (e.g., family, partner) because I am an AAW. (AS7)\nOthers have hinted that AAW are not assertive enough to be leaders. (AS8)\nOthers have hinted that AAW seem to have no desire for leadership. (AS9)\n\nAsian Fetishism (4 items)\n\nOthers express sexual interest in me because of my Asian appearance. (AF1)\nOthers take sexual interest in AAW to fulfill their fantasy. (AF2)\nOthers take romantic interest in AAW just because they never had sex with an AAW before. (AF3)\nOthers have treated me as if I am always open to sexual advances. (AF4)\n\nMedia Invalidation (5 items)\n\nI see non-Asian women being casted to play female Asian characters.(MI1)\nI rarely see AAW playing the lead role in the media. (MI2)\nI rarely see AAW in the media. (MI3)\nI see AAW playing the same type of characters (e.g., Kung Fu woman, sidekick, mistress, tiger mom) in the media. (MI4)\nI see AAW characters being portrayed as emotionally distant (e.g., cold-hearted, lack of empathy) in the media. (MI5)\n\nAssumptions of Universal Appearance (4 items)\n\nOthers have talked about AAW as if they all have the same facial features (e.g., eye shape, skin tone). (AUA1)\nOthers have suggested that all AAW look alike.(AUA2)\nOthers have talked about AAW as if they all have the same body type (e.g., petite, tiny, small-chested). (AUA3)\nOthers have pointed out physical traits in AAW that do not look ‘Asian’.\n\n\n\n\n\n\n\n\nFigure 10.4: A simple path diagram of four first-order CFA model.\n\n\n\nThe equations of the model are:\n\\[AS_1 = intercept1 + l_1 \\cdot AS + e_1\\]\n\\[AS_2 = intercept2 + l_2 \\cdot AS + e_2\\]\n\\[AS_3 = intercept3 + l_3 \\cdot AS + e_3\\] …\n\\[AS_9 = intercept9 + l_9 \\cdot AS + e_9\\]\n\\[AF_1 = intercept10 + l_{10} \\cdot AF + e_{10}\\]\n\\[AF_2 = intercept11 + l_{11} \\cdot AF + e_{11}\\]\netc.\nwhere \\(l_{1}, l_{2}, ...\\) are the loadings.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#example-of-grmsaaw-stress-appraisal",
    "href": "cfa.html#example-of-grmsaaw-stress-appraisal",
    "title": "10  Confirmatory Factor Analysis",
    "section": "10.3 Example of GRMSAAW Stress Appraisal",
    "text": "10.3 Example of GRMSAAW Stress Appraisal\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Factor) -.-&gt; C(Confirmatory Factor Analysis)\n\n\n\n\n\n\nas shown below (Figure 10.5).\n\n\n\n\n\n\nFigure 10.5: Select Confirmatory Factor Analysis from Factor.\n\n\n\nThe Confirmatory Factor Analysis box opens. Select the AS1-AS9 variables from the left-hand pane, transfer them into the “Factors” box and give then the label “AS” (Figure 10.6):\n\n\n\n\n\n\nFigure 10.6: Select AS1-AS9 for the fisrt factor named AS.\n\n\n\nNext, add a new Factor in the “Factors” box and label it “AF”. Select the AF1-AF4 variables and transfer them into the “Factors” box under the “Conscientiousness” label (Figure 10.7):\n\n\n\n\n\n\nFigure 10.7: Select AF1-AF4 for the second factor named AF.\n\n\n\nSimilarly, add a new factor to the “Factors” box and label it “MI”. Then, select the MI1–MI5 variables and move them into the “Factors” box under the “MI” label. Next, add another new factor labeled “AUA”, and transfer the AUA1–AUA4 variables into the “Factors” box under the “AUA” label.\nBy default, Jamovi standardizes the latent variables so that their variances are equal to 1 (Factor Variances = 1), while keeping the observed indicator variables on their original measurement scales. In this case, the factor loadings (estimates) represent the change in the unstandardized observed variable associated with a one standard deviation increase in the standardized latent variable.\nWe have also the option to set the first item of each factor as a reference by constraining its loading to 1 (Scale factor = scale first indicator). Let’s apply this constraint (Figure 10.8).\n\n\n\n\n\n\nFigure 10.8: Select Options, Estimates, Model fit measures and Plots provided for CFA.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#results",
    "href": "cfa.html#results",
    "title": "10  Confirmatory Factor Analysis",
    "section": "10.4 Results",
    "text": "10.4 Results\n\n10.4.1 Factor Loadings (regression coefficients) table\n\n\n\n\n\n\nFigure 10.9: Path diagram of four first-order CFA model.\n\n\n\n\nEstimate contains the estimated or fixed parameter value for each model parameter. Note that in the unstandardized solution, the first items for each factor—such as AS1, AF1, MI1, and AUA1—may appear incomplete, showing only a fixed value of 1.000. When a coefficient is fixed for identification purposes, it does not have an associated standard error and, as a result, no significance test is performed.\n\n\nExample\nThe unstandardized loading for AS2 is estimated at 1.132. This indicates that for every one-unit increase in the latent factor AS, the score on indicator AS2 is estimated to increase by 1.132 points on the 0-to-5 stress scale. This indicates that AS2 increases 0.132 points more than the reference indicator AS1.\n\n\nSE is the standard error for each estimated parameter.\n95% Confidence Interval is the confidence intervakl for each estimated parameter.\nZ-value is the Wald statistic (the parameter divided by its SE).\nP(&gt;|z|) is the p value for testing the null hypothesis that the parameter equals zero in the population.\nStand. Estimate both latent and observed variables are standardized; this is considered the “completely standardized solution”. Therefore, the standardized estimate represents the change in the standardized observed variable for a one standard deviation change in the standardized latent variable. They can be directly compared across different indicators and latent variables.\n\n\n\n10.4.2 Factor Variances and Covariances\n\n\n\n\n\n\nFigure 10.10: Variances and covariances between factors.\n\n\n\n \n\n\n\n\n\n\nFigure 10.11: Variances and covariances between factors in path diagram.\n\n\n\n \n\n\n10.4.3 Residuals covariances (error terms)\n\n\n\n\n\n\nFigure 10.12: Error terms of the observed variables.\n\n\n\n \n\n\n\n\n\n\nFigure 10.13: Error terms of the observed variables in path diagram.\n\n\n\n \n\n\n10.4.4 Model Fit in CFA\nThere are many measures of fit in Confirmatory Factor Analysis:\n\n\n\n\n\n\nFigure 10.14: Measures of fit in Confirmatory Factor Analysis.\n\n\n\n\nChi-square test. The chi-square test can be used to assess whether the model fits the data adequately. A non-significant chi-square value (e.g., p ≥ 0.05) indicates that the model fits the data reasonably well. However, the test is highly sensitive to sample size—tending to yield non-significant results in small samples even when fit is poor, and significant results in large samples even when the model fits well.\nThe Comparative Fit Index (CFI): The CFI is an incremental fit index, meaning it evaluates how much the hypothesized model improves upon a baseline (or null) model that assumes no associations among variables. CFI values range from 0 to 1, with higher values indicating better fit. (Rule of thumb: CFI values above 0.90 are generally considered indicative of acceptable model fit, while values above 0.95 suggest a good model fit).\nTucker-Lewis Index (TLI): The TLI penalizes model complexity more heavily than the CFI. TLI values can sometimes exceed 1.0, making the index somewhat unstable. Given the close association between TLI and CFI, it is generally recommended to report only one of the two.\nRMSEA (Root Mean Square Error of Approximation): The RMSEA is an absolute fit index interpreted as a badness-of-fit measure, with 0.00 indicating a perfect fit. It tends to favor models with more degrees of freedom and larger sample sizes. A unique feature of RMSEA is that it is accompanied by a 90% confidence interval. Although there is ongoing debate about acceptable RMSEA values, a common consensus is that \\(RMSEA \\geq 0.10\\) indicates poor fit, while \\(RMSEA \\leq 0.05\\) suggests a good fit. When interpreting the RMSEA, it’s important to examine the upper bound of the confidence interval to ensure it does not approach problematic levels.\nSRMR (Standardized Root Mean Square Residual): The SRMR is another absolute fit index and, like RMSEA, is a badness-of-fit statistic—values closer to 0.00 indicate better fit. The SRMR is a standardized version of the Root Mean Square Residual (RMR), which measures the mean absolute covariance residual. Standardization facilitates interpretation across different models. Poor model fit is typically flagged when \\(SRMR \\geq 0.10\\).\n\nAccording to Hu and Bentler (1999), an acceptable fit is achieved when \\(CFI \\geq 0.95\\) and \\(SRMR \\leq 0.08\\)—a guideline known as the combination rule. This recommendation, however, remains a topic of debate.\nThe conventional cutoffs for the aforementioned model fit indices – like any rule of thumb – should be applied with caution. Additionally, these indices do not always align with one another, which is why researchers often examine multiple fit indices to make an informed judgment about whether a model adequately fits the data.\nUsing these criteria, we can evaluate how well our hypothesized factor model fits the sample data.\n\n\n\n\n\n\nFigure 10.15: Model Fit statistical test and measures.\n\n\n\n \nIn summary\n\n\n\n\n\n\n\n\nCriteria\nOur Results\nCriteria met?\n\n\n\n\nStandardized Estimates significant, strong\nAS: 0.50 to 0.65; AF: 0.42 to 0.62; MI: 0.38 to 0.58; AUA: 0.54 to 0.63\nYes\n\n\nNon-significant chi-square\n\\(\\chi ^{2}(203) = 232.453, p = 0.076\\)\nYes\n\n\n\\(CFI\\geq 0.95\\)\nCFI = 0.976\nYes\n\n\n\\(RMSEA\\leq 0.05\\) (but definitely &lt; 0.10)\nRMSEA = 0.022, 90%CI(0.000, 0.034)\nYes\n\n\n\\(SRMR\\leq 0.08\\) (but definitely &lt; 0.10)\nSRMR = 0.045\nYes\n\n\nCombination rule: \\(CFI \\geq 0.95\\) and \\(SRMR \\leq 0.08\\)\nCFI = 0.976, SRMR = 0.045\nYes",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#path-diafram-of-the-first-rder-correlated-four-factors-cfa-model",
    "href": "cfa.html#path-diafram-of-the-first-rder-correlated-four-factors-cfa-model",
    "title": "10  Confirmatory Factor Analysis",
    "section": "10.5 Path diafram of the first-rder correlated four-factors CFA model",
    "text": "10.5 Path diafram of the first-rder correlated four-factors CFA model\nFor each factor, one item (typically the first listed on the left) should be specified as the reference indicator and is represented with a dashed line. In the unstandardized solution, its loading is fixed to 1.0 to establish the scale of the latent variable (Figure 10.16).\n\n\n\n\n\n\nFigure 10.16: Path diafram of the first-rder correlated four-factors CFA model (unstandardized).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#report-the-results",
    "href": "cfa.html#report-the-results",
    "title": "10  Confirmatory Factor Analysis",
    "section": "10.6 Report the results",
    "text": "10.6 Report the results\n\nWe evaluated a first-order, correlated factors model where each of the 22 items loaded onto one of four factors and the factors were free to correlate. Standardized estimates ranged between 0.50 to 0.65 on the AS factor, 0.42 to 0.62 on the AF factor, 0.38 to 0.58 on MI factor, and 0.54 to 0.63 on AUA factor. The Chi-square index was not statistically significant (\\(\\chi ^{2}(203)=232.5, p = 0.076\\)) indicating reasonable fit. The CFI value of 0.976 exceeded the recommendation of 0.95. The RMSEA = 0.022 (90%CI[.000, 0.034]) was satisfactory. The SRMR value of 0.045 remained below the warning value of 0.10.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "sem.html",
    "href": "sem.html",
    "title": "11  Structural Equation Modelling",
    "section": "",
    "text": "11.1 Measurement and Structural Models\nThe general SEM model can be decomposed into two two submodels: a measurement model, and a structural model (Figure 11.1).\nThe measurement model\nThe measurement model defines associations between the observed and unobserved variables. In other words, it provides the link between scores on a measuring instrument (observed indicator variables, \\(x_1,...,x_6\\)) and the underlying structures they are designed to measure (unobserved latent variables \\(\\xi_1\\), \\(\\eta_1\\)). The measurement model, then, represents the CFA model described earlier in Chapter 10 in that it specifies the pattern by which each measure loads on a particular factor.\nThe structural model\nThe structural model defines associations among the unobserved variables (latent variables, \\(\\xi_1\\) and \\(\\eta_1\\)). Accordingly, it specifies the manner by which particular latent variables directly or indirectly influence changes in the values of certain other latent variables in the model. In Figure 11.1 the latent variable \\(\\xi_1\\) is exogenous, while the latent variable \\(\\eta_1\\) is endogenous.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#measurement-and-structural-models",
    "href": "sem.html#measurement-and-structural-models",
    "title": "11  Structural Equation Modelling",
    "section": "",
    "text": "Figure 11.1: The measurement model and structural model.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#effects-in-sem",
    "href": "sem.html#effects-in-sem",
    "title": "11  Structural Equation Modelling",
    "section": "11.2 Effects in SEM",
    "text": "11.2 Effects in SEM\nIn SEM two types of effects are estimates: direct and indirect effects (Figure 11.2).\n\n\n\n\n\n\nFigure 11.2: Hypothesized Structural Equation Model (SEM).\n\n\n\nDirect effects (p1), indicated by a straight arrow, represent the association between one latent variable to another and this is indicated using single-directional arrows (e.g., the green arrow that connects directly \\(\\xi_2\\) and \\(\\eta_2\\)). The arrows are used in SEM to indicate directionality and do not imply causality.\nIndirect effects (\\(p2*p3\\)), on the other hand, reflect the association between an independent latent variable (exogenous variable) (e.g. \\(\\xi_2\\)) and a dependent latent variable (endogenous variable) (e.g. \\(\\eta_2\\)) that is mediated by one or more latent variables (e.g. \\(\\eta_1\\)). This path is illustrated by the red arrows in Figure 11.2.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#parameters-in-the-sem",
    "href": "sem.html#parameters-in-the-sem",
    "title": "11  Structural Equation Modelling",
    "section": "11.3 Parameters in the SEM",
    "text": "11.3 Parameters in the SEM\nThere are three types of parameters to be specified:\n\nDirectional effects: These are regression coefficients (e.g., \\(l_1-l_12\\) in Figure 11.2) that represent the associations between observed indicators and latent variables (referred to as factor loadings), as well as the associations between latent variables and other latent variables (referred to as path coefficients; e.g., \\(p_1-p_4\\) in Figure 11.2).\nVariances: Variances in a structural equation model account for unexplained variability in both observed and latent variables. For observed indicators, they represent measurement error—the variance not accounted for by the latent factor the indicator is intended to measure (e.g., \\(e_1-e_{12}\\) in Figure 11.2). For exogenous latent variables, they are represented with the green double-headed arrows in Figure 11.2 (these are often fixed to 1 for scaling but can sometimes be estimated). For endogenous latent variables, they reflect the variance in an endogenous (dependent) latent variable that is not explained by the exogenous (independent) latent variables predicting it in the model (e.g., \\(resid_1, resid_2\\) in Figure 11.2).\nCovariances: These parameters represent non-directional associations among independent (exogenous) latent variables and these exist when a researcher hypothesizes that the factors are correlated (\\(\\phi_1\\) shown as the curved double-headed orange arrow connected (\\(\\xi_1\\) and \\(\\xi_2\\) in Figure 11.2).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#steps-in-structural-equation-modeling-sem",
    "href": "sem.html#steps-in-structural-equation-modeling-sem",
    "title": "11  Structural Equation Modelling",
    "section": "11.4 Steps in Structural Equation Modeling (SEM)",
    "text": "11.4 Steps in Structural Equation Modeling (SEM)\nThe main steps of SEM are following (Figure 11.2) (Stoffels et al. 2023):\n\nModel specification: Define the hypothesized associations between variables based on theory. Establish a satisfactory measurement model for key concepts using latent variables. Fit regression paths between concepts (structural model).\nModel identification: Model identification refers to determining whether there is sufficient information in the observed data to estimate the model’s parameters uniquely. A model is overidentified when there are more known data points (usually variances and covariances) than free parameters—this is ideal because it allows for both parameter estimation and model fit testing. A just-identified model has an equal number of knowns and free parameters; while it can be estimated, its fit to the data cannot be tested. An underidentified model has fewer knowns than parameters, meaning it lacks enough information to estimate all parameters, making it impossible to fit the model reliably.\nModel estimation: It refers to the process of using statistical techniques to calculate the values of model parameters, such as factor loadings, path coefficients, and error or residual variances. Common estimation methods include Maximum Likelihood (ML), Generalized Least Squares (GLS), and Bayesian estimation, with ML being the most widely used.\nAssess goodness of fit: Assessing goodness of fit in SEM involves evaluating how well the proposed model reproduces the observed data. Key measures include the Chi-square test, and approximate fit indices like the Root Mean Square Error of Approximation (RMSEA), Comparative Fit Index (CFI), and Tucker-Lewis Index (TLI).\nModel respecification: Model respecification in SEM refers to the process of modifying a model to improve its fit to the data after initial estimation. If the original model does not fit well, researchers may adjust it by adding or removing paths, correlating error terms, or reassigning indicators—guided by both theory and statistical diagnostics like modification indices.\n\n\n\n\n\n\n\nFigure 11.3: Steps and key decisions involved in performing Structural Equation Modeling (SEM) (Source: Stoffels et al. 2023).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#example-data-and-the-model",
    "href": "sem.html#example-data-and-the-model",
    "title": "11  Structural Equation Modelling",
    "section": "11.5 EXAMPLE Data and the model",
    "text": "11.5 EXAMPLE Data and the model\nThe theoretical framework for our example is grounded in understanding how various student background factors influence academic achievement. The observed variables are: motivation (motiv), harmony (harm), stability (stabi), negative parental psychology (ppsych), socioeconomic status (ses), verbal IQ (verbal), reading (read), arithmetic (arith), and spelling (spell).\n\n\n\n\n\n\n\n\nFigure 11.4: Table with raw data.\n\n\n\n\nIn this example, nine observed variables are clustered into hypothetical latent constructs based on prior knowledge or theory. The three hypothesized latent constructs are adjustment, risk, and achievement. Adjustment is defined by the observed variables motivation, harmony, and stability. Similarly, risk is defined by negative parental psychology, socioeconomic status, and verbal IQ. It also correlates with the Adjustment latent variable. Finally, achievement is composed of reading, arithmetic, and spelling (Figure 11.5).\n\n\n\n\n\n\nFigure 11.5: Structural Equation Model (SEM) for how various student background factors influence academic achievement.\n\n\n\nParameters of the model in Figure 11.5:\n\nFixed: 9 error term regression paths (fixed to 1), 3 factor loadings (fixed to 1), 1 residual regression path (fixed to 1).\nFree: 9 error variances (\\(e_1,..,e_9\\)), 6 factor loadings (\\(l_2, l_3, l_4, l_5, l_6, l_8, l_9\\)), 2 path coefficients (\\(p1\\) and \\(p_2\\)), 1 residual variance, 2 variances of the exogenous variables (green double-headed arrows), 1 covariance (orange double-headed arrow).\n\nTherefore, we have 13 fixed parameters and 21 free parameters.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#sem-in-jamovi",
    "href": "sem.html#sem-in-jamovi",
    "title": "11  Structural Equation Modelling",
    "section": "11.6 SEM in Jamovi",
    "text": "11.6 SEM in Jamovi\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(SEM) -.-&gt; C(Structural Equation Modelling)\n\n\n\n\n\n\nas shown below (Figure 11.6).\n\n\n\n\n\n\nFigure 11.6: select SEM (interactive) from SEM icon in the menu.\n\n\n\nOnce the Structural Equation Modeling window appears, type “Achievement” into the Latent Endogenous Variables box. Next, select the observed variables read (ref.), arith, and spell from the left-hand pane and move them under the “Achievement” label in the Latent Endogenous Variables box (Figure 11.7).\n\n\n\n\n\n\nFigure 11.7: Select read, arith, and spell for the endogenous variable named Achievement.\n\n\n\nSimilarly, type “Adjustment” into the Latent Exogenous Variables box. Next, select the observed variables motiv (ref.), harm, and stabi from the left-hand pane and move them under the “Adjustment” label in the Latent Exogenous Variables box (Figure 11.7).\nNext, add a new exogenous variable in the Latent Exogenous Variables box and label it “Risk”. Select the verbal (ref.), ppsych, and ses observed variables and from the left-hand pane and move them under the “Risk” label in the Latent Exogenous Variables box (Figure 11.7).\nWe also need to define the exogenous factors “Adjustment” and “Risk” as predictors of the endogenous variable “Achievement”. To do this, select the desired variables and use the arrow button to transfer them into the Endogenous Variables field in the model as shown in Figure 11.8.\n\n\n\n\n\n\nFigure 11.8: Endogenous Model determination.\n\n\n\nWe can also present the model with a path diagram by selecting “path diagram” and “show residuals” (Figure 11.10).\n\n\n\n\n\n\nFigure 11.9: Select Path Diagram and check show residuals.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "sem.html#output-of-jamovi-sem-analysis",
    "href": "sem.html#output-of-jamovi-sem-analysis",
    "title": "11  Structural Equation Modelling",
    "section": "11.7 Output of Jamovi SEM analysis",
    "text": "11.7 Output of Jamovi SEM analysis\nPath coefficients\nThe path coefficients of the structural model are shown in the following table:\n\n\n\n\n\n\nFigure 11.10: Direct path coefficients.\n\n\n\nFactor Loadings\nThe factor Loadings of the measurement model are shown in the following table:\n\n\n\n\n\n\nFigure 11.11: Factor Loadings of the measurement model.\n\n\n\nVariances and Covariances\nVariances (i.e., measurement errors, variances of the exogenous latent variables, variances of endogenous variables, and covariances between latent variables) are presented in the table Figure 11.12\n\n\n\n\n\n\nFigure 11.12: Variances and Covariances of the model.\n\n\n\nFinally, we can presnt our results of the model with a path diagram as follows:\n\n\n\n\n\n\nFigure 11.13: Path diagram of the model.\n\n\n\n\n\n\n\nStoffels, Malou, Dario M. Torre, Paul Sturgis, Andries S. Koster, Marnix P. D. Westein, and Rashmi A. Kusurkar. 2023. “Steps and Decisions Involved When Conducting Structural Equation Modeling (SEM) Analysis.” Medical Teacher 45 (12): 1343–45. https://doi.org/10.1080/0142159x.2023.2263233.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Structural Equation Modelling</span>"
    ]
  },
  {
    "objectID": "ma1.html",
    "href": "ma1.html",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "",
    "text": "12.1 Meeting the review family\nAs more primary studies are conducted in research, the body of relevant research literature continues to grow. This expansion is a welcome development for psychologists working across various fields—such as clinical, educational, school, industrial-organizational, health, and sports psychology—who aim to ground their practice in evidence-based findings. However, the growing volume of research also presents new challenges in gathering, analyzing, and synthesizing the vast amount of available information.\nTo manage this complexity, researchers are increasingly turning to research reviews, which help organize, evaluate, and interpret existing studies. These reviews make the growing body of knowledge more accessible and applicable to both practice and future research. Forty-eight review types have been identiﬁed and categorized into seven families (Sutton et al. 2019):\nBut there are much more:",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#meeting-the-review-family",
    "href": "ma1.html#meeting-the-review-family",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "",
    "text": "Traditional literature review\nSystematic review\nRapid review\nQualitative review\nMixed-methods review\nPurpose-specific review (Health Technology Assessment-HTA)\nReview of reviews\n\n\n\nScoping review\nLiving review\nEconomic evaluation review\nMeasurement properties review",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#evidence-based-pyramid-in-research",
    "href": "ma1.html#evidence-based-pyramid-in-research",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.2 Evidence based pyramid in research",
    "text": "12.2 Evidence based pyramid in research\nThe levels of evidence, or hierarchy of evidence, provide a framework for ranking medical studies according to the quality and reliability of their design. This hierarchy is often represented as a pyramid, which reflects both the quality and quantity of evidence available. In this model, higher levels represent more rigor and reliable evidence. Each level builds upon the data and research found in the tiers below (Figure 12.1).\nEvidence based pyramids are typically divided into two or three sections. The top section includes secondary evidence such as systematic reviews, meta-analyses, and critical appraisals. The middle section contains primary evidence, including randomized controlled trials (RCTs), cohort studies, case-control studies, case series, and case reports. Some models also include a bottom tier that represents background information and expert opinion (Source: openmd).\n\n\n\n\n\n\nFigure 12.1: Evidence based pyramid (Based on Source: https://openmd.com/guide/levels-of-evidence).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#systematic-review",
    "href": "ma1.html#systematic-review",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.3 Systematic review",
    "text": "12.3 Systematic review\nAmong all types of reviews (Figure 12.2), the systematic review is considered one of the most rigorous and trusted forms of research synthesis. Therefore, conducting reliable, well-organized systematic reviews is essential for effectively synthesizing the findings of primary studies .\n\n\n\n\n\n\nFigure 12.2: Evidence pyramid.\n\n\n\n\nDefinition of systematic review\nSystematic review (SR) is a review of clearly formulated question that uses explicit, pre-planned scientific methods to identify, select, appraise, and synthesize results from similar but separate primary studies. (NOTE: Meta-analysis (MA), the statistical analysis of a large collection of results from individual studies is an optional component of a systematic review).\n\nFor example, let’s consider the Cochrane systematic review titled “Psychological therapies for anxiety and depression in children and adolescents with long-term physical conditions” (Thabrew et al. 2018).\nNext, we outline the fundamental steps involved in conducting a systematic review.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#establish-a-team-and-develop-a-focused-research-question",
    "href": "ma1.html#establish-a-team-and-develop-a-focused-research-question",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.4 Establish a team and develop a focused research question",
    "text": "12.4 Establish a team and develop a focused research question\nThe first step in conducting a systematic review is typically initiated by independent researchers, universities, institutes, or organizations such as the Cochrane Collaboration, the Joanna Briggs Institute (JBI), and the Centre for Reviews and Dissemination at the University of York. Policy-focused groups, including professional societies, government agencies, and healthcare payers, may also initiate such reviews. These entities undertake systematic reviews to address well-defined research questions or explore specific hypotheses, aiming to generate high-quality evidence that can guide practice, inform policy, and shape future research directions.\nInitially, a preliminary search of the existing literature is conducted to identify knowledge gaps within the field. The existence of previous systematic reviews on similar topics does not preclude the need for a new review—provided the new review addresses unresolved issues, incorporates updated evidence, or offers a novel analytical perspective that adds meaningful value.\nEstablish a research team\nThe research core team must clearly specify and agree on the reasons for the study as these are the driving force for any systematic reviews. All the team members must be fully aware and convinced of the reasons behind the proposed review and why the study is important.\nConduct of a systematic review is a complex procedure involving collaboration of content experts, librarians, methodologists, and statisticians. A well-organized and coordinated team is essential for conducting a successful systematic review. Many steps—such as the literature search, screening process, and quality assessment—require independent verification by multiple reviewers.\nCareful selection of colleagues and experts for the team is essential, evaluating both their expertise in the field and their professional integrity. The complexity of the research question and the anticipated number of primary studies will also influence the size of the team.\nFinally, no team can function effectively without a leader. The team leader is responsible for coordinating the project, ensuring adherence to the study protocol, keeping all members informed, and facilitating active participation throughout all phases of the review.\nDevelop a focused research question\nThe formulation of research question determines all the subsequent steps of the review: what studies should be included, where and how to search for studies, how to critically appraise those studies, and so on. The review question is usually based on the “PICO” mnemonic, which stands for:\n\nPopulation\nIntervention\nComparison(s)\nOutcome(s)\n\n\nExample\nPopulation: Children and adolescents aged up to 18 years with depression or anxiety or both with “long-term conditions”\nIintervention: Individual or group-based psychological or psychologically-oriented therapy excluding e-health therapies.\nComparator: Controls (treatment-as-usual, waiting list, attention placebo, psychological placebo, or non-psychological treatment).\nOutcome: Changes in severity of anxiety and depression symptoms measured separately using validated scales.\n\nIt is important to note that a systematic review with a broad scope provides a comprehensive summary of the available evidence base, nevertheless it is resource-intensive and usually comes with substantial heterogeneity that hinders interpretation of the findings. In contrast, a systematic review with a narrow focus is more manageable, but the available evidence may be limited, and the generalizability of the findings may be reduced.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#develop-your-research-plan-and-pre-register-the-project",
    "href": "ma1.html#develop-your-research-plan-and-pre-register-the-project",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.5 Develop your research plan and (pre) register the project",
    "text": "12.5 Develop your research plan and (pre) register the project\nA pre-study plan (or protocol) outlines objectives, methods, and criteria for a systematic review. In other words, it provides a structured framework to guide the review process through its various stages.\nTo increase the openness and transparency of a systematic review and streamlines the review process, researchers can preregister or register their projects using a registry. Preregistration and registration differ primarily in terms of timing. Preregistration occurs when researchers document essential information about a research project before they begin collecting data or analyzing primary sources. In contrast, registration refers to documenting the research project after the research process has already begun.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#specify-the-inclusion-and-exclusion-criteria",
    "href": "ma1.html#specify-the-inclusion-and-exclusion-criteria",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.6 Specify the inclusion and exclusion criteria",
    "text": "12.6 Specify the inclusion and exclusion criteria\nThe PICO framework is commonly used to specify the inclusion and exclusion criteria (eligibility criteria) for reviews of interventions. A critical step in setting these criteria is the evaluation of the type(s) of study design that may best answer the research question. Another important step is the clear definition of the outcomes. Specifically, an outcome can include five elements(Figure 12.3) (Saldanha et al. 2014):\n\nThe domain or outcome title (e.g., anxiety).\nThe specific measurement or technique/instrument used to make the measurement (e.g., Hamilton Anxiety Rating Scale).\nThe specific metric or format of the outcome data from each participant that will be used for analysis (e.g., value at a time-point, change from baseline).\nThe method of aggregation or how data from each group will be summarized (e.g., mean, median, proportion).\nThe time-points that will be used for analysis (e.g., 3 months, 6 months) .\n\n\n\n\n\n\n\nFigure 12.3: Each outcome has five elements (Source: Saldanha et al. 2014).\n\n\n\n\nExample of eligibility criteria in PICO format\n\nTypes of studies: We included all randomised controlled trials (RCTs) and cluster randomised trials. Cross-over trials were also included, though we only used data from the first phase in order to avoid carryover effects.\nTypes of participants: We included trials performed on children and adolescents aged up to 18 years (or at least 80% of the sample within this age range). We included studies performed on participants with any single or mixed long-term physical condition(s) of more than three months duration, who also had depression/subthreshold depression or anxiety, or both. We included studies conducted in hospital and community settings.\nTypes of interventions: Experimental interventions included any individual or group-based psychological or psychologically-oriented therapy excluding e-health therapies designed with the primary aim of treating clinical or subthreshold levels of anxiety or depression and tested in children and adolescents with long-term conditions (behaviour therapies such as relaxation training; cognitive behaviour therapies such as CBT; psychodynamic therapies such as psychoanalytic therapy; humanistic therapies such as person-centred psychotherapy; integrative therapies; and systemic therapies such as structural family therapy). Comparator interventions included any of the following: Attention placebo (AP); psychological placebo (PP); non-psychological therapies; Treatment-as-usual (TAU).\nTypes of outcome measures: Primary outcomes including treatment efficacy (hanges in severity of anxiety and depression symptoms measured), and treatment acceptability (measured via validated scales). Secondary outcomes including changes in caseness (remission/response), suicide-related behavior, i.e. number of: a) deaths by suicide, b) suicide attempts and c) episodes of self harm.\n\n\nNOTE: Researchers should consider the risk of inclusion bias. For example, review investigators may be aware of the results from various clinical trials when setting inclusion criteria, and may unintentionally include only those trials that support the hypothesis of the systematic review.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#search-information-sources",
    "href": "ma1.html#search-information-sources",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.7 Search information sources",
    "text": "12.7 Search information sources\nIt is recommended to search at least two major bibliographic databases, along with other sources of published and unpublished studies—including backward and forward citation tracking, reviews, consultation with field experts, and grey and non-English literature. Be sure to specify the date each source was last searched.\nNOTE: Researchers must be cautious of ascertainment bias, which occurs when certain studies are more likely to be identified (e.g., published in open-access journals or high-impact international journals) and included in a systematic review — not because they are necessarily better or more relevant, but simply because they are easier to find.\n\n12.7.1 Search in multiple electronic databases, platforms and engines\nBefore initiating the search, the team must develop a well-defined search strategy, identify relevant electronic databases, platforms and appropriate search engines, and, if necessary, create access accounts for those databases.\n\nSearch algorithm\n\nStart with simple search strategy.\nRun search, and retrieve reports.\nAnalyze controlled vocabulary terms and keywords of studies fitting the eligibility criteria, and revise strategy.\nRe-run search with revised strategy.\nRepeat steps 2 through 4 if necessary.\nRun optimal search strategy.\nRetrieve reports identified with optimal search strategy.\nRun the search strategy in multiple databases.\n\n\nMajor bibliographic databases for RCTs and observational studies:\n\nMEDLINE/PubMED\nEMBASE\nCochrane Central Register of Controlled Trials (CENTRAL)\n\nNational and regional databases (often local language):\n\nLILACS\nCNKI (China National Knowledge Infrastructure)\nKorean Medical Database (KMBASE)\n\nSubject-specific databases\n\nCINAHL (Cumulative Index to Nursing and Allied Health Literature)\nPsycINFO\nOTseeker (Occupational Therapy Systematic Evaluation of Evidence)\n\nCitation databases (platforms)\n\nWeb of Science\nWeb of Science\nScopus\n\nSearch Engines\n\nGoogle Scholar\n\nGray literature databases\n\nOpengrey\nNational Guidelines Clearing House\n\n\n\n12.7.2 Build a high-quality and effective search strategy\nWhen searching for academic papers, selecting the right search terms is crucial for finding relevant studies. These terms are typically derived from key concepts related to the topic of interest. There are two main types of search terms that should be used:\n\nControlled vocabulary terms: These are standardized subject terms used by databases to tag articles consistently, regardless of the terminology used by the authors. They help retrieve articles even if they use different words to describe the same concept. For example, MeSH (Medical Subject Headings) – used in PubMed/MEDLINE; Emtree – used in EMBASE; APA Thesaurus of Psychological Index Terms – used in PsycINFO.\nKeywords: These are natural language terms—the words and phrases that researchers might use in titles, abstracts, or full texts.\n\nFor systematic review searches, researchers should use both controlled vocabulary and keywords. Using only keywords may result in missing articles that use different terminology, while relying solely on controlled vocabulary could exclude articles that have not yet been indexed or were indexed using outdated terms. Boolean operators (OR, AND, NOT) are crucial, as they allow researchers to combine search terms and help narrow or expand the search results, making them more relevant to the research (Figure 12.4).\n\n\n\n\n\n\nFigure 12.4: Boolean operators.\n\n\n\nA comprehensive search for eligible studies is one of the most critical steps in a systematic review. Involvement of an information specialist or an experienced librarian is essential for developing a robust and effective search strategy. Note that each database has its own way of writing a search strategy.\n\nExample\nThe Cochrane Group’s Information Specialist initially searched the Cochrane Common Mental Disorders Controlled Trials Register (CCMD-CTR) (all years to 6 May 2016), using the following terms.\nCondition = (anxiety or depressi* or mood or mutism or neuroses or neurotic or “obsessive compulsive” or panic or phobi or psychoneuroses or “stress disorder*” or “psychological stress” or “school refusal”) and Comorbidity = not empty and Age Group = (child or adolescent)\n\nThis search included a more sensitive set of terms to find additional untagged/uncoded reports of RCTs. For example, regarding the age group:\n\nExample\n[Age Group] 1. (child* or boy* or girl* or infant* or juvenil* or minors or paediatric* or pediatric* or school* or preschool* or pre-school* or kindergarten or nursery or adolesc* or preadolesc* or pre-adolesc* or pubert* or pubescen* or prepube* or pre-pube* or high-school or teen* or (young next (adult* or people or patient* or men* or women* or mother* or male or female or survivor* or oCender* or minorit)) or youth or student* or undergrad* or college or campus or classroom):ti,ab\n\n\n\n12.7.3 Search citations using both backward and forward citation tracking methods\nCitation searching in the context of systematic reviews is a method used to identify relevant literature that may not be captured through standard database searches. It involves tracking how research articles are connected through citations. There are two main types of citation searching: backward citation searching (also known as reference list checking) and forward citation searching.\n\nBackward Citation Search: A search to find all the references cited within a single article. This search looks backwards in time to trace the prior research and sources that informed the development of the article.\nForward Citation Search: A search to find all subsequent articles that have cited a specific article. This search looks forward in time to explore how the article has influenced later research and contributed to the broader scholarly conversation.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#screen-and-select-studies",
    "href": "ma1.html#screen-and-select-studies",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.8 Screen and select studies",
    "text": "12.8 Screen and select studies\nThe search process most often yields a large number of potentially pertinent citations that need to be checked against the pre-specified eligibility criteria. Study selection is a staged process, which needs to be explicit and objective in order to minimize errors and biases.\nAt least two reviewers should first screen records retrieved at title and abstract level working independently (meaning that each reviewer is blinded to the decisions of the other). The initially selected reports will then qualify for full-text screening in a similar manner to reach a final decision about studies that will be included in the systematic review. Disagreements at any stage between assessors need to be resolved either with consensus or through arbitration with a senior reviewer.\nAutomation tools are available to facilitate both the de-duplication of records (i.e., removing duplicate records retrieved from multiple databases) and the study selection process. Software such as Rayyan, Covidence, EPPI-Reviewer, CADIMA, DistillerSR are specifically designed to support systematic reviews. Additionally, reference management tools like EndNote, Mendeley or Zotero can also be used to organize and manage citations, including handling duplicates.\nThe entire process should be documented using a well-designed flow diagram, known as the PRISMA flow chart, which outlines the number of records or studies reviewed at each stage and provides detailed reasons for exclusion (Figure 12.5) (Iddagoda and Flicker 2023).\n\n\n\n\n\n\nFigure 12.5: PRISMA flow chart.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#collect-data-form-included-studies",
    "href": "ma1.html#collect-data-form-included-studies",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.9 Collect data form included studies",
    "text": "12.9 Collect data form included studies\nHaving completed the study selection process, the reviewers should proceed with data extraction, during which they obtain all necessary information and outcome data from each eligible study. The data items to be extracted are agreed upon by the review team, and electronic data extraction forms are typically pilot tested on a small sample of eligible studies. This process is again conducted in duplicate to ensure accuracy and data integrity. At this stage unreported information or missing data might be sought through communication with authors of original reports.\nDuring data extraction, reviewers should ensure the use of clear abbreviations, consistent unit conversions, standardized definitions, and concise presentation of information.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#assess-the-methodological-quality-and-risk-of-bias-of-the-included-studies",
    "href": "ma1.html#assess-the-methodological-quality-and-risk-of-bias-of-the-included-studies",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.10 Assess the methodological quality and risk of bias of the included studies",
    "text": "12.10 Assess the methodological quality and risk of bias of the included studies\nA systematic review is only as good as the studies upon which is built. Evidence and results should be interpreted in light of the quality of the included studies. The quality of the research encompasses how a study has been conducted (methodological quality) and how it has been described (reporting quality and reproducibility). Poor methodological and reporting quality of primary studies included in the review may introduce bias and spurious conclusions (Muka et al. 2019; Mantsiou et al. 2023).\nTherefore, assessment of the methodological quality and risk of bias in the included studies by two independent reviewers is an essential component of a systematic review. For randomized controlled trials Cochrane released the RoB 2 tool (revised tool for Risk of Bias in randomized trials). Risk of bias is assessed at the outcome level for the following domains: randomization process, deviations from the intended interventions, missing outcome data, measurement of the outcome and selection of the reported result.\nAfter completing all seven bias domains, an overall judgment is made regarding the risk of bias of the study for the outcome under assessment: “low risk of bias”, “some concerns”, or “high risk of bias”. The overall risk-of-bias judgment is derived from the domain-level judgments using a predefined algorithm (Figure 12.6).\n\n\n\n\n\n\nFigure 12.6: Traffic light plot for ROB 2 tool.\n\n\n\n \n\n\n\n\n\n\nFigure 12.7: Summary barplot for ROB 2 tool.\n\n\n\nFor observational studies evaluation of methodological quality is based on the ROBINS-I tool V2 (Risk Of Bias in Non-randomized Studies - of Interventions Version 2). Risk of bias is assessed at the outcome level for the following domains: confounding, selection of participants into the study, classification of interventions, deviations from intended interventions, missing data, bias arising from measurement of the outcome, selection of the reported result.\nAfter completing all seven bias domains, an overall judgment is made regarding the risk of bias: “low risk of bias,” “moderate risk of bias,” “serious risk of bias,” or “critical risk of bias.” The overall risk-of-bias judgment is derived from the domain-level judgments using a predefined algorithm (Figure 12.8).\n\n\n\n\n\n\nFigure 12.8: Traffic light plot for ROBINS-I tool.\n\n\n\n \n\n\n\n\n\n\nFigure 12.9: Summary barplot for ROBINS-I tool.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#synthesize-the-results",
    "href": "ma1.html#synthesize-the-results",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.11 Synthesize the results",
    "text": "12.11 Synthesize the results\nOne of the most important steps in conducting a systematic review is synthesizing the results from the included primary studies. Authors should present the findings using narrative descriptions and summary tables, grouping the results according to key characteristics such as intervention, population, outcomes, or study design—this is referred to as qualitative synthesis.\nWhen the data are suitable for statistical aggregation, authors may also perform a meta-analysis (quantitative synthesis). In this process, a summary statistic is calculated for each included study—typically a (standardized) mean difference for continuous outcomes, or a risk ratio (RR) or odds ratio (OR) for dichotomous outcomes. An overall effect estimate is then computed as a weighted average of the individual study effects.\n\nMeta-analysis is an optional component of a systematic review, meaning that not every systematic review includes a meta-analysis. However, every systematic review does include a qualitative synthesis.\n\nIt is important to note that every study is unique, and those included in a systematic review will inevitably differ to some extent. Reviewers should assess heterogeneity, which may arise from factors such as participant characteristics, disease severity, concomitant treatments, or methodological quality. Depending on the presence and extent of heterogeneity, two basic meta-analytic models are available: the fixed-effect model and the random-effects model.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#assess-reporting-bias",
    "href": "ma1.html#assess-reporting-bias",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.12 Assess reporting bias",
    "text": "12.12 Assess reporting bias\nReviewers should assess the risk of bias in the result of a synthesis (such as meta-analysis) due to missing studies or missing results within studies. Missing studies/results may introduce bias when the decision to publish a study/result is influenced by the observed p-value or magnitude or direction of the effect (Page et al. 2021).\nFor example, studies with statistically non-significant results may not have been submitted for publication (publication bias), or particular results that were statistically non-significant may have been omitted from study reports (selective outcome reporting bias).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#grade-quality-of-evidence-grade-approach",
    "href": "ma1.html#grade-quality-of-evidence-grade-approach",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.13 Grade Quality of Evidence (GRADE approach)",
    "text": "12.13 Grade Quality of Evidence (GRADE approach)\nThe most common approach to rating the certainty of the evidence is the GRADE (Grading of Recommendations Assessment, Development and Evaluation) framework. GRADE has four levels of evidence ranging from very low quality, which suggests that we are very uncertain about the true estimate, to high quality, which suggests that further research is very unlikely to change our confidence in the estimate of effect (Balshem et al. 2011).\nRandomized controlled trials provide high quality evidence which may be downgraded for several reasons including high risk of bias, imprecision, inconsistency, indirectness, or concerns about publication bias. Conversely, evidence that includes observational data starts at low quality due to the possibility of residual confounding (i.e., confounding that persists after Adjustment for the putatively measured confounders) (Figure 12.10).\n\n\n\n\n\n\nFigure 12.10: A summary of GRADE’s approach to rating quality of evidence (Source: Balshem et al. 2011).\n\n\n\nThe evaluation should be performed independently by two reviewers, while any disagreement should be discussed with a third, independent reviewer.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#update-report-and-submit-for-publication",
    "href": "ma1.html#update-report-and-submit-for-publication",
    "title": "12  Systematic Review and Meta-analysis (1)",
    "section": "12.14 Update, report, and submit for publication",
    "text": "12.14 Update, report, and submit for publication\nWhen ready to submit the study for publication, if the interval since beginning the search of bibliographic databases is greater than 6–12 months the search should be updated to identify recently published articles (Muka et al. 2019).\nReporting guidelines exist to help ensure that systematic reviews with or without meta-analysis are reported with transparency, reproducibility, and comparability. The most commonly used guideline is PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses), which assists authors in clearly reporting why the review was conducted, what methods were used, and what the review found.\nFinally, additional experts with content expertise may be invited to review and comment on the manuscript (and the published work should acknowledge their assistance). It is still possible to improve the quality of the publication further by appraising the interpretation of the results one last time.\n\n\n\n\nBalshem, Howard, Mark Helfand, Holger J. Schünemann, Andrew D. Oxman, Regina Kunz, Jan Brozek, Gunn E. Vist, Yngve Falck-Ytter, Joerg Meerpohl, and Susan Norris. 2011. “GRADE Guidelines: 3. Rating the Quality of Evidence.” Journal of Clinical Epidemiology 64 (4): 401–6. https://doi.org/10.1016/j.jclinepi.2010.07.015.\n\n\nIddagoda, Mayura Thilanka, and Leon Flicker. 2023. “Clinical Systematic Reviews  a Brief Overview.” BMC Medical Research Methodology 23 (1). https://doi.org/10.1186/s12874-023-02047-8.\n\n\nMantsiou, Chrysanthi, Aris Liakos, Maria Mainou, Nikolaos Papanas, Apostolos Tsapas, and Eleni Bekiari. 2023. “A Simple Guide to Systematic Reviews and Meta-Analyses.” The International Journal of Lower Extremity Wounds, May. https://doi.org/10.1177/15347346231169842.\n\n\nMuka, Taulant, Marija Glisic, Jelena Milic, Sanne Verhoog, Julia Bohlius, Wichor Bramer, Rajiv Chowdhury, and Oscar H. Franco. 2019. “A 24-Step Guide on How to Design, Conduct, and Successfully Publish a Systematic Review and Meta-Analysis in Medical Research.” European Journal of Epidemiology 35 (1): 49–60. https://doi.org/10.1007/s10654-019-00576-5.\n\n\nPage, Matthew J, David Moher, Patrick M Bossuyt, Isabelle Boutron, Tammy C Hoffmann, Cynthia D Mulrow, Larissa Shamseer, et al. 2021. “PRISMA 2020 Explanation and Elaboration: Updated Guidance and Exemplars for Reporting Systematic Reviews.” BMJ, March, n160. https://doi.org/10.1136/bmj.n160.\n\n\nSaldanha, Ian J., Kay Dickersin, Xue Wang, and Tianjing Li. 2014. “Outcomes in Cochrane Systematic Reviews Addressing Four Common Eye Conditions: An Evaluation of Completeness and Comparability.” Edited by Kypros Kypri. PLoS ONE 9 (10): e109400. https://doi.org/10.1371/journal.pone.0109400.\n\n\nSutton, Anthea, Mark Clowes, Louise Preston, and Andrew Booth. 2019. “Meeting the Review Family: Exploring Review Types and Associated Information Retrieval Requirements.” Health Information & Libraries Journal 36 (3): 202–22. https://doi.org/10.1111/hir.12276.\n\n\nThabrew, Hiran, Karolina Stasiak, Sarah E Hetrick, Liesje Donkin, Jessica H Huss, April Highlander, Stephen Wong, and Sally N Merry. 2018. “Psychological Therapies for Anxiety and Depression in Children and Adolescents with Long-Term Physical Conditions.” Cochrane Database of Systematic Reviews 2019 (1). https://doi.org/10.1002/14651858.cd012488.pub2.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma2.html",
    "href": "ma2.html",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "",
    "text": "13.1 Introduction\nAlthough the term meta-analysis was first introduced by Smith and Glass in 1976 (Smith and Glass 1977), the first use of meta-analysis in the sense of combining quantitative studies is attributed to Karl Pearson (“Report on Certain Enteric Fever Inoculation Statistics” 1904), who analyzed data from five studies on the correlations between immunity and inoculation, as well as mortality and inoculation. In the late 1970s and early 1980s, following the work of Smith and Glass, meta-analysis gained widespread popularity, and the statistical methods necessary for its application were further refined and developed.\nIn a meta-analysis, a set of independent studies is included. Each study is summarized by an estimate of effect or association (the “study result”)—such as a mean difference, percentage, risk ratio, or correlation coefficient. The primary goal of a meta-analysis is to estimate an overall, or combined, effect size.\nIf all the studies included in the analysis were equally precise, we could simply calculate the average of their effect sizes. However, when some studies are more precise than others, it’s important to give more weight to those that provide more reliable information. This is exactly what a meta-analysis does. Instead of computing a simple average, it calculates a weighted average, assigning greater weight to more precise studies and less to those with higher uncertainty (Figure 13.1).\nThe key question, then, is how weights are assigned to individual studies. The answer depends on how we define the “combined effect”. There are two primary models used in meta-analysis, the fixed-effect model (also known as common effect model) and the random-effects model. Each model has different assumptions regarding the included studies, leading to different definitions of the combined effect and different mechanisms for assigning weights.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#introduction",
    "href": "ma2.html#introduction",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "",
    "text": "Meta-analysis is an optional component of a systematic review. It is the statistical analysis which combines the results of several independent studies considered by the analyst to be “combinable”. This definition highlights that the reviewer has to make the decision whether the studies are similar enough to be combined in a meta-analysis.\n\n\n\n\n\n\n\n\n\n\nFigure 13.1: The framework of meta-analysis for evidence integration.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#fixed-effect-model",
    "href": "ma2.html#fixed-effect-model",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "13.2 Fixed-effect model",
    "text": "13.2 Fixed-effect model\nThe framework of fixed effect model\nIn a fixed-effect (FE) model we assume that all \\(k\\) studies considered in the meta-analysis share a common effect size, \\(\\theta_1 = \\theta_2= ...=\\theta_k = \\theta\\) (hence, the term fixed). Each observed effect, \\(Y_i\\), is considered to be distributed around \\(\\theta\\), with a variance \\(V_{Y_i}\\) informed entirely by the within-study variance (sampling error).\n\n\n\n\n\n\nFigure 13.2: Fixed-effect model – distribution of sampling error.\n\n\n\nThe observed effect \\(Y_i\\) for any study (squares) is given by the common effect size, \\(\\theta\\), plus the sampling error in that study, \\(e_i\\). That is,\n\\[Y_i = \\theta + e_i\\]\nwhere \\(e_i \\sim N(0, V_{Y_i})\\).\nWhile the error in any given study is random, we can estimate the sampling distribution of the errors. In Figure 13.2 we have placed a normal curve about the true effect size for each study, with the width of the curve being based on the variance in that study. For example, in Study 1 the sample size is small, the variance large, and the observed effect is likely to fall anywhere within a relatively wide range. By contrast, in Study 2 the sample size is relatively large, the variance is small, and the observed effect is likely to fall in a relatively narrow range. (The width of the normal curve is based on the square root of the variance, or standard error).\nThe weight assigned to each study in a fixed-effect meta-analysis is the inverse of the variance \\(V_{Y_i}\\):\n\\[W_i = \\frac{1}{V_{Y_i}}\\]\n \nSummary effect and confidence interval\nThe summary effect, \\(\\theta_F\\), in a fixed-effect model represents the estimate of a common true effect shared by all included studies. The associated confidence interval (CI) reflects the uncertainty around this estimate. The width of the normal distribution curve for each study is determined by its variance—studies with smaller variances (typically due to larger sample sizes) yield narrower curves, indicating more precise estimates.\nThe summary effect and its confidence interval are displayed at the bottom of Figure 13.2.\n\\[\\theta_F = \\frac{\\sum_{i=1}^k W_i Y_i}{\\sum_{i=1}^k W_i}\\]\nThe variance of \\(\\theta_F\\) is given by\n\\[V_{\\theta_F} = \\frac{1}{\\sum_{i=1}^k W_i}\\]\nand the estimated standard error of the summary effect is the square root of the variance,\n\\[SE_{\\theta_F} = \\sqrt{V_{\\theta_F}}\\]\n \nThen, 95% lower and upper limits for the summary effect are estimated as\n\\[LL_{\\theta_F} = \\theta_F - 1.96 \\times SE_{\\theta_F}\\]\nand\n\\[UL_{\\theta_F} = \\theta_F + 1.96 \\times SE_{\\theta_F}\\]",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#random-effects-model",
    "href": "ma2.html#random-effects-model",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "13.3 Random effects model",
    "text": "13.3 Random effects model\nThe framework of fixed effect model\nWhen we decide to incorporate a group of studies in a meta-analysis, we assume that the studies have enough in common that it makes sense to synthesize their results. Nevertheless, there is generally no reason to believe that the true effect size is exactly the same in every study.\nInstead of assuming all \\(\\theta_i\\) are equal (as in a fixed-effect model), the random-effects model assumes:\n\\[\\theta_i \\sim N(\\mu, \\tau^2)\\]\nThat is, the true effect sizes (represented by orange circles in Figure 13.3) are distributed around a mean, \\(\\mu\\), and can be considered a random sample from a normal distribution with variance \\(\\tau^2\\)—hence, the term random. In Figure 13.3 this distribution is illustrated by the orange normal curve at the bottom of the graph.\n\n\n\n\n\n\nFigure 13.3: Random-effects model – between-study and within-study variance.\n\n\n\nFigure 13.3 also highlights that the distance between the overall mean and the observed effect in any given study consists of two distinct parts: true variation in effect sizes (\\(u_i\\)) and sampling error (\\(e_i\\)).\nTherefore, the observed effect \\(Y_i\\) for any study is given by the grand mean (\\(\\mu\\)), the deviation of the study’s true effect from the grand mean (\\(u_i\\)), and the deviation of the study’s observed effect from the study’s true effect (\\(e_i\\)). That is,\n\\[Y_i = \\theta_i + e_i = \\mu + u_i + e_i\\]\nwhere \\(e_i \\sim N(0, V_{Y_i})\\) and \\(u_i \\sim N(0, \\tau^2)\\).\nTo compute a study’s variance under the random-effects model, we need to know both the within-study variance and \\(\\tau^2\\):\n\\[V^*_{Y_i} = V_{Y_i} + \\tau^2\\]\nIt is important to note that the same value of \\(\\tau^2\\) applies to all studies in the meta-analysis.\nUnder the random-effects model the weight assigned to each study is:\n\\[W^*_i = \\frac{1}{V^*_{Y_i}} = \\frac{1}{V_{Y_i} + \\tau^2}\\] Study weights are more balanced under the random-effects model than under the fixed-effect model. Large studies are assigned less relative weight and small studies are assigned more relative weight as compared with the fixed-effect model.\n(NOTE: To highlight the parallel between the formulas of random effects model and those in the fixed effect model we use the same notations but add an asterisk * to represent the random-effects version.)\n \nSummary effect and confidence interval\nThe summary effect in random effect meta-analysis provides an estimation of the average treatment effect, and the CI reflects the uncertainty around this estimate, including the component of heterogeneity.\n\\[\\theta_R = \\frac{\\sum_{i=1}^k W^*_i Y_i}{\\sum_{i=1}^k W^*_i}\\]\nThe variance of \\(\\theta_R\\) is given by\n\\[V_{\\theta_R} = \\frac{1}{\\sum_{i=1}^k W^*_i}\\]\nand the estimated standard error of the summary effect is the square root of the variance,\n\\[SE_{\\theta_R} = \\sqrt{V_{\\theta_R}}\\]\n \nThen, 95% lower and upper limits for the summary effect are estimated as\n\\[LL_{\\theta_R} = \\theta_R - 1.96 \\times SE_{\\theta_R}\\]\nand\n\\[UL_{\\theta_R} = \\theta_R + 1.96 \\times SE_{\\theta_R}\\]\nIn the presence of heterogeneity, the relative weights assigned under a random-effects model are more balanced than those in a fixed-effect model. This is because standard random-effects methods add a common component of variance (\\(\\tau^2\\)) to each study’s weight to account for between-study variability in treatment effects. As a result, this dual source of variability—within-study and between-study—leads to larger overall variance, wider standard errors, and broader confidence intervals for the summary effect estimate.\nMultiple estimators have been proposed for \\(\\tau^2\\) such as the Der Simonian and Laird, the restricted maximum-likelihood and maximum likelihood, the Paul-Mantel, Hedges, and Hunter-Schmidt estimator.\nNOTE: Hartung and Knapp introduced a new meta-analysis method based on a refined variance estimator in the random effects model. It has been argued that the Hartung–Knapp method is preferred over the DerSimonian–Laird method.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#forest-plot",
    "href": "ma2.html#forest-plot",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "13.4 Forest plot",
    "text": "13.4 Forest plot\nThe main output of a meta-analysis is a graph called a forest plot. This plot depicts results from each primary study as well as the summary effect estimate.\nEach study is identified by the first author and date of publication and is presented in a single row at the left side of the plot. Results from individual studies are shown as a square which represents the estimate of the effect size and a horizontal line which corresponds to the confidence interval. The size of the square is proportional to the weight of the study, which indicates its relative impact on the calculations of the summary effect (Figure 13.4).\nThere is also a vertical reference line at the null hypothesis (0.0 for mean difference results and 1.0 for ratio results), which denotes no effect between intervention and comparison groups.\nThe overall effect estimate is presented graphically as a diamond, with the endpoints representing the limits of the 95% confidence interval (CI). This confidence interval indicates how precisely we have estimated the effect size, based on the standard error of the mean.\nIn contrast, the 95% prediction interval reflects the expected range of effect sizes in future studies, considering the standard deviation of the effect sizes observed across studies. Unlike the confidence interval, which reflects the precision of the overall estimate, the prediction interval is an absolute measure that accounts for the heterogeneity between studies (Borenstein 2023).\n\n\n\n\n\n\nFigure 13.4: A typical forest plot.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#heterogeneity",
    "href": "ma2.html#heterogeneity",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "13.5 Heterogeneity",
    "text": "13.5 Heterogeneity\n\n13.5.1 Types of Heterogeneity\nThere are three types of heterogeneity: clinical, methodological, and statistical.\n\nClinical heterogeneity: Variability in participants (e.g., inclusion criteria, geographical location), interventions (e.g., dose, nature of control interventions) and outcomes (e.g., follow-up duration, cut-off points).\nMethodological heterogeneity: Variability in the study design, the quality of conduct, and approach to analysis. For example, when the sequence of assigning participants to treatment groups is not concealed, randomized clinical trials tend to estimate larger treatment effects.\nStatistical heterogeneity: Variability in effect sizes, resulting from clinical and/or methodological diversity. Statistical heterogeneity is present if the observed effects are more different from each other than would be expected due to random sampling.\n\n\n\n13.5.2 Assessing heterogeneity in meta-analysis\nAssessment of the consistency of effects across studies is an essential part of meta-analysis. Unless we know how consistent the results of studies are, we cannot determine the generalisability of the findings of the meta-analysis.\nCochran’s Q statistic\nThe statistical test usually applied in meta-analysis for detecting true heterogeneity among studies is the Q test, proposed by Cochran. Under the null hypothesis of no heterogeneity (\\(H_o\\): the true effects are the same in all the primary studies included in meta-analysis; or \\(H_o\\): \\(\\tau^2 = 0\\)), the Q statistic follows a chi-square distribution with k-1 degrees of freedom, where k is the number of studies.\nThe statistical power of Cochran’s Q test is often low, particularly in meta-analyses that include a small number of studies. Consequently, true heterogeneity may go undetected when conventional significance thresholds, such as 0.05, are applied. To mitigate this limitation, a more lenient threshold of 0.10 has been proposed; however, this increases the risk of a Type I error. As such, the Q test should be interpreted with caution, especially when the analysis includes fewer than 20 studies. Furthermore, it is not recommended to determine the choice between a fixed-effect and a random-effects model solely based on the Q test results, as it does not provide sufficient evidence to guide model selection.\n\nStatistical heterogeneity may not always be observed, even in the presence of clinical and/or methodological heterogeneity. Therefore, the absence of statistical heterogeneity should not be interpreted as evidence of no heterogeneity.\n\n \n\\(\\tau^2\\) measure\n\\(\\tau^2\\) describes the underlying between-study variability. Its square root, \\(\\tau\\), is measured in the same units as the outcome. Its estimate does not systematically increase with either the number of studies or the sample size.\n \n\\(I^2\\) index\nAnother statistic used to assess heterogeneity is \\(I^2\\), which represents the part of total variation that is due to between-studies variance. \\(I^2\\) is a percentage and its values lie between 0% and 100%. For example, an \\(I^2\\) value of 0% indicates that all variability in effect size estimates is due to sampling error within studies, whereas an \\(I^2\\) value of 50% indicates that half of the total variability among effect sizes is caused by true heterogeneity between studies. Importantly, \\(I^2\\) is a relative measure and can be directly compared between meta-analyses with different numbers of studies and various types of outcome data.\n\\(I^2\\) values of approximately 25%, 50%, and 75% have been proposed to indicate low, moderate, and high heterogeneity, respectively (Higgins 2003). However, it should be interpreted with caution when the number of included studies is small (e.g., fewer than 20). Moreover, when the study sizes become very large, the sampling error tends to 0 and \\(I^2\\) tends to 1 and such heterogeneity may not be clinically relevant.\nThe majority of meta-analyses use the \\(I^2\\) index to quantify heterogeneity. While this practice is common it is nevertheless incorrect. I-squared does not tell us how much the effect size varies (except when I-squared is zero percent). The statistic that does convey this information is the prediction interval (Borenstein 2023).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#small-study-effects-in-meta-analysis",
    "href": "ma2.html#small-study-effects-in-meta-analysis",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "13.6 Small-study effects in meta-Analysis",
    "text": "13.6 Small-study effects in meta-Analysis\n“Small-study effects” is a generic term for the phenomenon that smaller studies sometimes show different, often larger, treatment effects than large ones.\nPotential sources of asymmetry in funnel plots\n\nOne possible, and probably the most well-known, reason is publication bias. This occurs when the likelihood of a study being published—particularly a small study—increases if it shows a stronger, statistically significant, and favorable effect. Conversely, small studies with null or negative findings are less likely to be published, especially since such studies are often perceived as less robust or less interesting.\n\nNOTE: Publication bias affects all review methods (not a problem exclusive to MAs!)\n\nThere are a number of other possible reasons for small-study effects. One is selective reporting of the most favourable outcomes, known as outcome reporting bias.\nAnother possible cause of small-study effects is clinical heterogeneity between patients in large and small studies; e.g., patients in smaller studies may have been selected so that a favourable outcome of the experimental treatment may be expected.\n\n \nTools to assess small-study effects\nA funnel plot is a graphical tool commonly used in meta-analysis to assess small-study effects. It is a simple scatterplot that presents the treatment effects estimated from individual studies on the x-axis and a measure of precision, usually the standard error of the effect estimate, on the y-axis. At the top of the graph, studies with greater precision (smaller standard errors) are located, while those with less precision (larger standard errors) are found lower on the plot. A vertical solid line indicates the estimate based on the model. A pseudo confidence interval region is drawn around this value with bounds equal to ±1.96 SE, where SE is the standard error value from the y‐axis (assuming level = 95)(Figure 13.5).\nIf no excessive between-study heterogeneity exists, smaller studies (with larger standard errors) would scatter more than larger studies. That is, the funnel plot would show the form of a triangle (inverted funnel) symmetric with respect to the average treatment effect, with broad variability for small imprecise studies (at the bottom of the plot) and small dispersion for large, precise studies (at the top) (Figure 13.5).\n\n\n\n\n\n\nFigure 13.5: Symmetrical funnel plot.\n\n\n\nIn an asymmetrical funnel plot, one side may exhibit a higher density of studies than the other, or there may be a noticeable absence of studies on one side, both of which suggest potential bias (Figure 13.6).\n\n\n\n\n\n\nFigure 13.6: Asymmetrical funnel plot.\n\n\n\nReviewers might attempt to assess small-study effects by inspecting the funnel plot for asymmetry, either visually or formally, using methods such as Egger’s test or the Begg and Mazumdar rank correlation. For these statistical tests, a p-value &lt; 0.05 indicates asymmetry in the funnel plot. In general, these tests are relatively imprecise, and it is not advisable to test for asymmetry in the funnel plot when fewer than ten studies are available (Figure 13.5).\nFunnel-plot asymmetry thus raises the possibility of bias, but it is not proof of bias (Sterne, Gavaghan, and Egger 2000). It is important to note, however, that asymmetry (unless produced by chance alone) will always lead us to question the interpretation of the overall estimate of effect when studies are combined in a meta-analysis. It is suggested that the funnel plot should be seen as a generic means of examining “small-study effects” (the tendency for the smaller studies in a meta-analysis to show larger treatment effects) rather than as a tool to diagnose specific types of bias.\nThe Test of Excess Significance (TES) is a statistical method used to detect and quantify publication bias or selective reporting in the literature. Specifically, it examines whether the number of statistically significant findings in a set of studies exceeds what would be expected by chance. P-values less than 0.05 indicate that there are more significant results than expected, which may suggest publication bias or selective reporting.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#meta-analysis-using-jamovi",
    "href": "ma2.html#meta-analysis-using-jamovi",
    "title": "13  Systematic Review and Meta-analysis (2)",
    "section": "13.7 Meta-analysis using Jamovi",
    "text": "13.7 Meta-analysis using Jamovi\nThe aim of this meta-analysis is to investigate whether psychological therapies are more effective than any comparator in improving quality of life immediately post-intervention. Seven studies examined this outcome, and the following data were extracted for each group:\n\n\n\n\n\n\n\n\nFigure 13.7: Table with raw data.\n\n\n\n\n\nstudy: name and year of the study\nMean1: mean of the psychological therapy group\nSD1: standard deviation of the psychological therapy group\nTotal1: number of participants of the psychological therapy group\nMean2: mean of the comparator group\nSD2: standard deviation of the comparator group\nTotal2: number of participants of the comparator group\n\nStandardized mean differences (SMDs) will be used to summarize the data from each group, as the studies employed different scales to assess the outcome.\nOpen the dataset named “meta” from the file tab in the menu (Figure 13.8).\n\n\n\n\n\n\nFigure 13.8: The meta dataset.\n\n\n\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Meta Analysis) -.-&gt; C(Mean Differences)\n\n\n\n\n\n\nas shown below (Figure 13.9).\n\n\n\n\n\n\nFigure 13.9: In the menu at the top, choose Analyses -&gt; Meta Analysis -&gt; Mean Differences.\n\n\n\nThe The Mean Differences box opens (Figure 13.10). From the left-hand pane drag the variables into the right-hand fields, as shown below:\n\n\n\n\n\n\nFigure 13.10: The Mean Differences box options. Drag and drop the variables into the right-hand field.\n\n\n\nFrom the Model Options we select “Restricted Maximum-Likelihood” for estimating the \\(\\tau^2\\), and “Standardized Mean Difference” as the measure of effect size.\n\n\n\n\n\n\nFigure 13.11: Model options of meta-analysis.\n\n\n\n \nNext, from the Plot section tick the box “Prediction Interval”, “Model fitting weights”, and in the X-Axis Title type “SMD”.\n\n\n\n\n\n\nFigure 13.12: The Plots check options.\n\n\n\n \n\n\n\n\n\n\nFigure 13.13: Random-Effects model. Overall effect.\n\n\n\nA total of k=7 studies were included in the analysis. The observed standardized mean differences (SMD) ranged from 0.064 to 5.20, with all estimates being positive. The estimated average SMD based on the random-effects model was 1.28 (95% CI: 0.05 to 2.52). Therefore, the average outcome differed significantly from zero (z = 2.04, p = 0.04).\n \n\n\n\n\n\n\nFigure 13.14: Heterogeneity Statistics results.\n\n\n\nAccording to the Q-test, the true effects do not appear to be the same across all primary studies (Q(6) = 60.3, p &lt; 0.001). The proportion of total variance attributable to between-study differences is substantial, with an I² value of 96.9%; however, the small number of studies limits the reliability of this estimate. Most importantly, the 95% prediction interval for the true effect, ranging from –2.12 to 4.69, reflects considerable heterogeneity across studies.\n \nFigure 13.15 presents the forest plot comparing psychological therapy with any comparator for the outcome Quality of life (short-term).\n\n\n\n\n\n\nFigure 13.15: Forest plot.\n\n\n\nThe psychological therapies were more effective than any comparator in improving quality of life immediately post-intervention (SMD = 1.28, CI 0.05 to 2.52).\nObserve that the forest plot clearly demonstrates that the Monghanloo (2015) study (n = 34) exhibits a large standardized mean difference (SMD) of approximately 5.20, with a confidence interval ranging from 3.8 to 6.6. This finding is markedly different from the other studies (it may be a potential outlier in the context of this model), which show effect sizes closer to zero or slightly positive.\n(Note: The authors of the systematic review considered a SMD effect size of 0.2 to be small, 0.5 medium, and greater than 0.8 large).\nSmall-study effects and publication bias\nWe check Show Test of Excess Significance output from the Publication Bias (Figure 13.16).\n\n\n\n\n\n\nFigure 13.16: Tests for publication bias.\n\n\n\n \n\n\n\n\n\n\nFigure 13.17: Test of Excess Significance (TES).\n\n\n\n \n\n\n\n\n\n\nFigure 13.18: Funnel plot.\n\n\n\n \n\n\n\n\n\n\nFigure 13.19: Results of the tests for publication bias.\n\n\n\n \nThe visual asymmetry of the funnel plot, particularly the absence of smaller studies showing non-positive effects, raises concerns about a small-study effect (Figure 13.18). Egger’s test also suggests the presence of funnel plot asymmetry (z = 4.4, p &lt; 0.001). However, the Begg and Mazumdar rank correlation test was not statistically significant (Kendall’s tau = 0.62, p = 0.069) and the Test of Excess Significance indicated no evidence of excess significance bias (i.e., no suspiciously high number of significant findings). Given the small number of studies (n = 7), the results from both the statistical tests and the funnel plot are not very clear and should be interpreted with caution.\n(NOTE: Research has found that funnel plots using the standardized mean difference (SMD) in combination with the standard error (SE) are unsuitable for assessing publication bias and can lead to false-positive results (Zwetsloot et al. 2017))\n\n\n\n\nBorenstein, Michael. 2023. “How to Understand and Report Heterogeneity in a Meta-Analysis: The Difference Between I-Squared and Prediction Intervals.” Integrative Medicine Research 12 (4): 101014. https://doi.org/10.1016/j.imr.2023.101014.\n\n\nHiggins, J. P T. 2003. “Measuring Inconsistency in Meta-Analyses.” BMJ 327 (7414): 557–60. https://doi.org/10.1136/bmj.327.7414.557.\n\n\n“Report on Certain Enteric Fever Inoculation Statistics.” 1904. BMJ 2 (2288): 1243–46. https://doi.org/10.1136/bmj.2.2288.1243.\n\n\nSmith, Mary L., and Gene V. Glass. 1977. “Meta-Analysis of Psychotherapy Outcome Studies.” American Psychologist 32 (9): 752–60. https://doi.org/10.1037/0003-066x.32.9.752.\n\n\nSterne, Jonathan A. C, David Gavaghan, and Matthias Egger. 2000. “Publication and Related Bias in Meta-Analysis.” Journal of Clinical Epidemiology 53 (11): 1119–29. https://doi.org/10.1016/s0895-4356(00)00242-0.\n\n\nZwetsloot, Peter-Paul, Mira Van Der Naald, Emily S Sena, David W Howells, Joanna IntHout, Joris AH De Groot, Steven AJ Chamuleau, Malcolm R MacLeod, and Kimberley E Wever. 2017. “Standardized Mean Differences Cause Funnel Plot Distortion in Publication Bias Assessments.” eLife 6 (September). https://doi.org/10.7554/elife.24260.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "14  Presentations",
    "section": "",
    "text": "Lecture 1: Introduction\n\n\n\n\npsy-introduction\n\n\n     \n\nLecture 2: Between-subjects: One-way ANOVA\n\n\n\n\npsy-anova1\n\n\n     \n\nLecture 3: Within-subjects: Repeated ANOVA\n\n\n\n\npsy-anova2\n\n\n     \n\nLecture 4: Within-subjects: Two-way ANOVA\n\n\n\n\npsy-anova3\n\n\n     \n\nLecture: Linear Regression (Simple Models)\n\n\n\n\npsy-linear1\n\n\n     \n\nLecture: Linear Regression (Multi-variable models)\n\n\n\n\npsy-linear2\n\n\n     \n\nLecture: Principal Component Analysis\n\n\n\n\npsy-pca\n\n\n     \n\nLecture: Systematic Reviews\n\n\n\n\npsy-SR_meta1\n\n\n     \n\nLecture: Meta-analysis\n\n\n\n\npsy-SR_meta2",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Presentations</span>"
    ]
  },
  {
    "objectID": "sources.html",
    "href": "sources.html",
    "title": "15  Sources & Aknowledgements",
    "section": "",
    "text": "Chapter 8 Principal Components Analysis\nPrincipal components analysis\nIntroduction to Mediation Analysis\nChapter 55 Investigating Processes Using Path Analysis\nStructural Equation Modeling (SEM)",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Sources & Aknowledgements</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Balshem, Howard, Mark Helfand, Holger J. Schünemann, Andrew D. Oxman,\nRegina Kunz, Jan Brozek, Gunn E. Vist, Yngve Falck-Ytter, Joerg\nMeerpohl, and Susan Norris. 2011. “GRADE Guidelines: 3. Rating the\nQuality of Evidence.” Journal of Clinical Epidemiology\n64 (4): 401–6. https://doi.org/10.1016/j.jclinepi.2010.07.015.\n\n\nBaron, Reuben M., and David A. Kenny. 1986. “The\nModeratormediator Variable Distinction in Social\nPsychological Research: Conceptual, Strategic, and Statistical\nConsiderations.” Journal of Personality and Social\nPsychology 51 (6): 1173–82. https://doi.org/10.1037/0022-3514.51.6.1173.\n\n\nBorenstein, Michael. 2023. “How to Understand and Report\nHeterogeneity in a Meta-Analysis: The Difference Between I-Squared and\nPrediction Intervals.” Integrative Medicine Research 12\n(4): 101014. https://doi.org/10.1016/j.imr.2023.101014.\n\n\nHiggins, J. P T. 2003. “Measuring Inconsistency in\nMeta-Analyses.” BMJ 327 (7414): 557–60. https://doi.org/10.1136/bmj.327.7414.557.\n\n\nIddagoda, Mayura Thilanka, and Leon Flicker. 2023. “Clinical\nSystematic Reviews  a Brief Overview.” BMC\nMedical Research Methodology 23 (1). https://doi.org/10.1186/s12874-023-02047-8.\n\n\nLewis, Jioni A., and Helen A. Neville. 2015. “Construction and\nInitial Validation of the Gendered Racial Microaggressions Scale for\nBlack Women.” Journal of Counseling Psychology 62 (2):\n289–302. https://doi.org/10.1037/cou0000062.\n\n\nMantsiou, Chrysanthi, Aris Liakos, Maria Mainou, Nikolaos Papanas,\nApostolos Tsapas, and Eleni Bekiari. 2023. “A Simple Guide to\nSystematic Reviews and Meta-Analyses.” The International\nJournal of Lower Extremity Wounds, May. https://doi.org/10.1177/15347346231169842.\n\n\nMuka, Taulant, Marija Glisic, Jelena Milic, Sanne Verhoog, Julia\nBohlius, Wichor Bramer, Rajiv Chowdhury, and Oscar H. Franco. 2019.\n“A 24-Step Guide on How to Design, Conduct, and Successfully\nPublish a Systematic Review and Meta-Analysis in Medical\nResearch.” European Journal of Epidemiology 35 (1):\n49–60. https://doi.org/10.1007/s10654-019-00576-5.\n\n\nPage, Matthew J, David Moher, Patrick M Bossuyt, Isabelle Boutron, Tammy\nC Hoffmann, Cynthia D Mulrow, Larissa Shamseer, et al. 2021.\n“PRISMA 2020 Explanation and Elaboration: Updated Guidance and\nExemplars for Reporting Systematic Reviews.” BMJ, March,\nn160. https://doi.org/10.1136/bmj.n160.\n\n\n“Report on Certain Enteric Fever Inoculation Statistics.”\n1904. BMJ 2 (2288): 1243–46. https://doi.org/10.1136/bmj.2.2288.1243.\n\n\nSaldanha, Ian J., Kay Dickersin, Xue Wang, and Tianjing Li. 2014.\n“Outcomes in Cochrane Systematic Reviews Addressing Four Common\nEye Conditions: An Evaluation of Completeness and Comparability.”\nEdited by Kypros Kypri. PLoS ONE 9 (10): e109400. https://doi.org/10.1371/journal.pone.0109400.\n\n\nSmith, Mary L., and Gene V. Glass. 1977. “Meta-Analysis of\nPsychotherapy Outcome Studies.” American Psychologist 32\n(9): 752–60. https://doi.org/10.1037/0003-066x.32.9.752.\n\n\nSterne, Jonathan A. C, David Gavaghan, and Matthias Egger. 2000.\n“Publication and Related Bias in Meta-Analysis.”\nJournal of Clinical Epidemiology 53 (11): 1119–29. https://doi.org/10.1016/s0895-4356(00)00242-0.\n\n\nStoffels, Malou, Dario M. Torre, Paul Sturgis, Andries S. Koster, Marnix\nP. D. Westein, and Rashmi A. Kusurkar. 2023. “Steps and Decisions\nInvolved When Conducting Structural Equation Modeling (SEM)\nAnalysis.” Medical Teacher 45 (12): 1343–45. https://doi.org/10.1080/0142159x.2023.2263233.\n\n\nSutton, Anthea, Mark Clowes, Louise Preston, and Andrew Booth. 2019.\n“Meeting the Review Family: Exploring Review Types and Associated\nInformation Retrieval Requirements.” Health Information &\nLibraries Journal 36 (3): 202–22. https://doi.org/10.1111/hir.12276.\n\n\nThabrew, Hiran, Karolina Stasiak, Sarah E Hetrick, Liesje Donkin,\nJessica H Huss, April Highlander, Stephen Wong, and Sally N Merry. 2018.\n“Psychological Therapies for Anxiety and Depression in Children\nand Adolescents with Long-Term Physical Conditions.” Cochrane\nDatabase of Systematic Reviews 2019 (1). https://doi.org/10.1002/14651858.cd012488.pub2.\n\n\nZwetsloot, Peter-Paul, Mira Van Der Naald, Emily S Sena, David W\nHowells, Joanna IntHout, Joris AH De Groot, Steven AJ Chamuleau, Malcolm\nR MacLeod, and Kimberley E Wever. 2017. “Standardized Mean\nDifferences Cause Funnel Plot Distortion in Publication Bias\nAssessments.” eLife 6 (September). https://doi.org/10.7554/elife.24260.",
    "crumbs": [
      "References"
    ]
  }
]