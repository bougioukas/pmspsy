[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Statistical Methods for Analyzing Empirical Data",
    "section": "",
    "text": "Welcome!\nThis course introduces postgraduate students to advanced statistical methods used in the quantitative social, educational, and behavioral sciences. Students will learn:\n\nData management.\nAnalysis of Variance (ANOVA) Designs.\nMultiple Linear Regression. Interaction between variables.\nPrincipal Components Analysis and Factor Analysis.\nMediation and Path Analysis.\nBasic Structural Equation Modeling (SEM).\nPrinciples of Evidence Synthesis (Systematic reviews and Meta-analysis).\n\n \nThe students will also learn about the principles of data visualization and statistical software JAMOVI.\n     \nSources for reading\n\nAnalysis of Variance Designs: A Conceptual and Computational Approach with SPSS and SAS\nLearning Statistics with Jamovi",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "",
    "text": "1.1 Why Jamovi?\nJamovi is a new fee open “3rd generation” statistical software that is built on top of the programming language R (Figure 1.1). Designed from the ground up to be easy to use, Jamovi is a compelling alternative to costly statistical products such as SPSS and SAS.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#why-jamovi",
    "href": "introduction.html#why-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "",
    "text": "Figure 1.1: Jamovi is free and open statistical software\n\n\n\n\n\n\n\n\n\nSome other advantages are:\n\n\n\n\nUser-friendly point-and-click interface.\nDisplays informative tables and clear visuals.\nSupports add-on modules for advanced statistical analysis.\nAllows integration with R.\nProvides access to a user guide and community resources on the Jamovi website.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#downloading-and-installing-jamovi",
    "href": "introduction.html#downloading-and-installing-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.2 Downloading and installing Jamovi",
    "text": "1.2 Downloading and installing Jamovi\nJamovi is available for Windows (64-bit), macOS, Linux and ChromeOS. Installation on desktop is quite straight-forward. Just go to the Jamovi download page https://www.jamovi.org/download.html, and download the latest version (current release) for your operating system.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#navigating-jamovi",
    "href": "introduction.html#navigating-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.3 Navigating Jamovi",
    "text": "1.3 Navigating Jamovi\nWhen jamovi first opens, we will see a screen something like in Figure 1.2.\n\n\n\n\n\n\n\n\nFigure 1.2: Jamovi starts up!.\n\n\n\n\n\nTo the left is the spreadsheet view, and to the right is where the results of statistical tests appear. Down the middle is a bar separating these two regions, and this can be dragged to the left or the right to change their sizes.\n \nLet’s take a quick look at the Jamovi Main Menu, referred to hereafter as the Menu, as shown in Figure 1.3. This Menu is displayed at the very top of the Jamovi screen:\n\n\n\n\n\n\n\n\nFigure 1.3: The menu bar provides access to all functions of the program.\n\n\n\n\n\nThere are six tabs in the Menu (from left to right): 1. File (a layer with three horizontal levels \\(\\equiv\\)), 2. Variables, 3. Data, 4. Analyses, 5. Edit, and 6. Settings (the three dots \\(\\vdots\\) at the top right of the window) tabs. A toolbar appears whenever we click on a Menu tab (Table 1.1).\n \n\n\n\nTable 1.1: Menu and toolbars of Jamovi\n\n\n\n\n\n\n\n\n\nMenu tab\nToolbar\n\n\n\n\n\nFile tab (\\(\\equiv\\))\nThe file tab  allows us to open/import existing files, save and export our files.\n\n\n\n\n\nVariables tab\nThis allows us to view and search our variables in a list view.\n\n\nThis view allows us to easily navigate our variables and do the following:\n\nSearch for a variable by scrolling through the list or search for one by name.\nEdit the variable names and descriptions by double-clicking in the relevant field.\nEdit our variable details by double-clicking on the data symbol (the screen will appear for us to add all the necessary information).\nCreate a new variable by clicking on the in the bottom right corner. |\n\n\n\n\nData tab\nHere we will see our raw data which are organised like Excel in rows and columns. We can also manipulate our data and add new variables when necessary.\n\n\nSpecifically, this tab allows us to do the following:\n\nRename and add details to existing variables. Click on the Setup button, or double-click on the variable we want to manage.\nCompute and transform variables\nAdd and/or Delete variables (columns)\nAdd Filters\nAdd and/or Delete Rows\n\n\n\n\nAnalyses tab\nIt includes the available statistical analyses that can be performed by Jamovi.\n\n\nWe will spend most of our time in the Analyses Tab. The following six modules are pre-installed:\n\nExploration\nT-Tests\nANOVA\nRegression\nFrequencies\nFactor\n\nFor example, if we want to perform regression analysis, we simply click the ’’Regression” button.\nAll other modules need to be installed using the Modules button (Plus button) in our top-right  |\n\n\n\nEdit tab\nIt includes a toolbar similar to a word processor.\n\n\nWe can add extra information to our results using the buttons that are very similar to what we would find in Word (though there are fewer options).\n\n\n\nSettings tab\n(the three dots \\({\\vdots}\\) at the top right of the window)\n\nIt includes the application settings that can be manged by the users according to their preferences.\n\n\nWe can apply our preferences for a number of settings such as:\n\nHow many decimal numbers we want.\nIf we want to learn R, we can also display the R syntax.\nOur graph color scheme.\nOur default missing value.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#types-of-variables-in-jamovi",
    "href": "introduction.html#types-of-variables-in-jamovi",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.4 Types of Variables in Jamovi",
    "text": "1.4 Types of Variables in Jamovi\nData variables can be one of four measure types:\n\n Nominal: This type is for nominal categorical variables.\n Ordinal: This type is for ordinal categorical variables.\n Continuous : this type is for variables with numeric values which are considered to be of Interval or Ratio scales.\n ID: This will usally be our first column. This can be text or numbers, but it should be unique to each row.\n\n \nAdditionally, data variables can be one of three data types:\n\nInteger: These are full numbers e.g. 1, 2, 3, … 100, etc. - Integers can be used for all three measure types . When used for Nominal/Ordinal data numbers will represent labels e.g. male=1; female=2.\nDecimal: These are numbers with decimal points. e.g. 1.3, 5.6, 7.8, etc. - This will usually only be used for continuous data.\nText: This can be used for ordinal and nominal data.\n\nThe measure types are designated by the symbol in the header of the variable’s column. Note that some combinations of data-type and measure-type don’t make sense, and Jamovi won’t let us choose these.\n\n\n\nTable 1.2: Types of data and measures\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasure\n\n\n\n\n\nData\nNominal\nOrdinal\nContinuous\n\n\nInteger\n\\({\\checkmark}\\)\n\\({\\checkmark}\\)\n\\({\\checkmark}\\)\n\n\nDecimal\n\n\n\\({\\checkmark}\\)\n\n\nText\n\\({\\checkmark}\\)\n\\({\\checkmark}\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#importing-data",
    "href": "introduction.html#importing-data",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.5 Importing data",
    "text": "1.5 Importing data\n\n1.5.1 The dataset\nIt is possible to simply begin typing values into the Jamovi spreadsheet as we would with any other spreadsheet software. Alternatively, existing datasets in a range of formats (OMV, Excel, CSV, SPSS, R data, Stata, SAS) can be opened in Jamovi. We will use the following dataset as an example (Figure 1.4).\n\n\n\n\n\n\n\n\nFigure 1.4: Table with raw data.\n\n\n\n\n(NOTE: You can find other formats of the data (OMV, Excel) at the link: https://osf.io/gvctz/).\n   \nThe meta-data (data about the data) for this dataset are as following:\n\nsex: sex (1 = male, 2 = female).\nage: age in years.\ntime_spend: hours spent on social media.\n\\(q_1 ... q_{10}\\): Ten questions (items) of Rosenberg Self-Esteem Scale (RSES). The 10 items are answered on a four point scale ranging from strongly agree to strongly disagree coded as follows: Strongly Agree = 3, Agree = 2, Disagree = 1, and Strongly Disagree = 0.\n\n\nPositively worded Items 1, 2, 4, 6, and 7.\nNegatively worded Items 3, 5, 8, 9, and 10 (codes should be reversed).\n\n\n\n\n\n\n\nFigure 1.5: Codes should be reversed for the negatively worded Items.\n\n\n\nThe scale ranges from 0-30 (we add the scores for all items), with 30 indicating the highest total score possible.\nMore information for the RSES: Rosenberg Self-Esteem Scale.\n\n\n1.5.2 Opening the file\nTo open this csv file, click on the File tab  at the top left hand corner (just left of the Variables tab) (Figure 1.6).\n\n\n\n\n\n\nFigure 1.6: Click on the File tab\n\n\n\nThis will open the menu shown in Figure 1.7. Select ‘Open’ and then ‘This PC’. Choose the downloaded file from the files listed on ‘Browse’ which are stored on our computer folders:\n\n\n\n\n\n\n\n\nFigure 1.7: Open an existing file stored on our computer into Jamovi.\n\n\n\n\n\n \nThe flowchart of the process is:\n\n\n\n\n\nflowchart LR\n  A(File tab) -.-&gt; B(Open) -.-&gt; C(This PC) -.-&gt; D(Browse) -.-&gt; E(Open \\n 'the downloaded file')\n\n\n\n\n\n\n \nWe should see data now in the Spreadsheet view (Figure 1.8).\n\n\n\n\n\n\n\n\nFigure 1.8: Our dataset.\n\n\n\n\n\nAs we can see this is a data set with 258 observations and 13 variables. JAMOVI has classified all the variables as nominal ; however, only the sex variable is actually nominal.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#adding-labels-to-codes",
    "href": "introduction.html#adding-labels-to-codes",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.6 Adding labels to codes",
    "text": "1.6 Adding labels to codes\n\nsex variable\n\nThe first variable, named sex, is a categorical variable coded as 1 for males and 2 for females. Notice that it is correctly identified as a nominal  variable in Jamovi.\nWe can assign labels to numerically coded values of categorical variables, such as sex, by accessing the data variable settings. One way to achieve this is by double-clicking on the variable name sex, which opens the additional menu of variable settings at the top of the Jamovi screen (Figure 1.9).\n\n\n\n\n\n\nFigure 1.9: An additional menu appears at the top of the Jamovi screen after double-clicking on the variable name sex.\n\n\n\n \nIn this menu, we will find the Levels setup. Here, we can specify the labels that should appear for each category level. Click on the number “1” in the Levels box to edit its label, changing it from “1” to “male”. Similarly, click on the number “2” and change it to “female” (Figure 1.10).\n\n\n\n\n\n\nFigure 1.10: Adding labels to numerically coded Values.\n\n\n\nNotice how the numbers “1” and “2” have moved to the lower right under the text we’re typing, allowing us to still see which label corresponds to each numerical code. Press Enter or click anywhere outside the labels box to save these labels.\nWe close the variable settings by pressing the arrow in the top-right corner .",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#changing-the-measure-type",
    "href": "introduction.html#changing-the-measure-type",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.7 Changing the measure type",
    "text": "1.7 Changing the measure type\nNext, we will change the measure type of age and time_spent variables from nominal to continuous.\n\nage variable\n\nDouble-click on the variable name age to open the data variable settings, as shown in Figure 1.11:\n\n\n\n\n\n\nFigure 1.11: Data variable menu settings for the age variable.\n\n\n\n \nFrom the drop-down list of “Measure type” we select the continuous type , as shown in Figure 1.12.\n\n\n\n\n\n\nFigure 1.12: Change the measure type of age from nominal to continuous. .\n\n\n\n \n\ntime_spent variable\n\nInstead of closing the data variable menu using the arrow in the top-right corner, we can click on the  to proceed to the next variable setting, time_spent. As before, we select the continuous type for this variable from the “Measure type” drop-down list, as shown in Figure 1.13.\n\n\n\n\n\n\nFigure 1.13: Change the measure type of time_spent from nominal to continuous.\n\n\n\nWe close the variable settings by pressing the arrow in the top-right corner .\n \n\nq1 to q10 variables\n\nFinally, we will change the measure type of q1 to q10 variables from nominal to ordinal. In the Variables tab, we select the checkboxes for the q1 through q10 variables, as shown in Figure 1.14.\n\n\n\n\n\n\nFigure 1.14: Change the measure type of time_spent from nominal to continuous.\n\n\n\n \nAfter that, we click on the Edit button  to open the data variable settings, as shown in Figure 1.15.\n\n\n\n\n\n\nFigure 1.15: Change the measure type of time_spent from nominal to continuous.\n\n\n\n \nFrom the drop-down list of “Measure type” we select the ordinal type , as shown in Figure 1.16.\n\n\n\n\n\n\nFigure 1.16: Change the measure type of q1 to q10 from nominal to ordinal.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#filtering-rows",
    "href": "introduction.html#filtering-rows",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.8 Filtering rows",
    "text": "1.8 Filtering rows\nNext, we select the Filters button  from the Data tab. This opens the “Row FILTERS” view at the top of the Jamovi screen where we can add a filter called “Filter 1” (Figure 1.17). Let’s say that we want to study only the adults from the participants in this survey.\n\nSimple condition\n\nIn order to access functions, press the  icon in the filter settings and from “VARIABLES” double-click on age (or we just type the variable name but if the variable has a space, we must use ticks '' around the variable name). Then type the condition age &gt;= 18 in the formula box and press ENTER from the keyboard (Figure 1.17).\n\n\n\n\n\n\nFigure 1.17: Adding a filter.\n\n\n\n \n\n\n\n\n\n\nRelational (or comparison) operators in Jamovi\n\n\n\n\n\n\nsymbol\nread as\n\n\n\n\n&lt;\nless than\n\n\n&gt;\ngreater than\n\n\n==\nequal to\n\n\n&lt;=\nless than or equal to\n\n\n&gt;=\ngreater than or equal to\n\n\n!=\nnot equal to\n\n\n\n\n\n \nNotice that a column named Filter 1 has been added to the Spreadsheet view. Cells that meet the condition age &gt;= 18 are checked with a green tick , while the rest have a red x symbol . Lines with an X are grayed out indicating that these observations are now outside of the current dataset.\nThere is also a switch where we can activate  or inactivate  the filter (note that an inactivate filter will remain visible and can be toggled to active at any time).\nIt is also possible to hide all filter columns by clicking on the eye symbol  of the filters. In this case, all filters and the filtered data will remain active but will be invisible.\nFinally, if we want to delete the filter permanently, we can click on the  of the filter .\n \n\nMultiple conditions\n\nBut we can do more complicated filters than this! Let’s say that we’re interested in the adult females. In fact we can specify this in three ways:\na) by using the and operator in “Filter 1” which means that both conditions (adults and females) in the expression must be true at the same time. Therefore, we type the expression age &gt;= 18 and sex == 'female' (Figure 1.18):\n\n\n\n\n\n\nFigure 1.18: Combining conditions with “and” operator in one expression.\n\n\n\nNote that in the above expression we can also use double quotes around the \"female\" (i.e., age &gt;= 18 and sex == \"female\") or even the coded value (i.e., age &gt;= 18 and sex == 2).\nb) by adding the second condition (i.e. sex == \"female\") as another expression to “Filter 1” (by clicking the small + beside the first expression) (Figure 1.19):\n\n\n\n\n\n\nFigure 1.19: Multiple expressions in the same filter.\n\n\n\nThis additional expression comes to be represented with its own column F1(2) (Figure 1.19), and by looking at the ticks and crosses, we can see which expression is responsible for excluding each row.\nc) adding a new “Filter 2” (by selecting the large + to the left of the filters dialog box) (Figure 1.20). In this case, we can activate or inactivate the filters separately.\n\n\n\n\n\n\nFigure 1.20: Multiple expressions using multiple filters.\n\n\n\nWe close the filter settings by pressing the arrow in the top-right corner .\n\n\n\n\n\n\nImportant\n\n\n\nFilters in Jamovi exclude the rows for which the expression is not true. When filters are active, all results will be based on the filtered data. If we want to see unfiltered results we will either need to delete the filter or toggle it to inactive.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#transforming-a-variable",
    "href": "introduction.html#transforming-a-variable",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.9 Transforming a variable",
    "text": "1.9 Transforming a variable\n\n1.9.1 Transform a quantitative variable into a qualitative variable\nSometimes it can be useful to convert a quantitative variable into a qualitative variable with levels. For example, the time_spent can be categorized as follows:\n\nless than or equal to 3  “0-3”\n4 to 7  “4-7”\n8 to 11  “8-11”\ngreater than 11  “&gt;11”\n\nSelect time_spent variable and click the Transform button  from the toolbar of the Data tab. This opens the “TRANSFORMED VARIABLE” view, where we can set the name of the transformed variable such as time_spent2 and create the transformation. To do this, select the source variable, the time_spent in this case, in the Source Variable field and create a new transformation using transform field (Figure 1.21), which is initially set to ‘none’.\n\n\n\n\n\n\nFigure 1.21: Setting up a new transformation of a variable.\n\n\n\n \nThis opens the “TRANSFORM” view where Jamovi gives each transformation a name (e.g., Transform 1; if we want we can change it). This allows us to use it again later on other variables if we wish. We can also add a description (Figure 1.22).\n\n\n\n\n\n\nFigure 1.22: Box for adding conditions to the transformation.\n\n\n\nNow we need to add conditions. Jamovi uses simple if ... else statements and executes each statement starting from the top. So let’s start!\nFirst, select + Add recode condition. Second, we need to fill the boxes with the information as follows (Figure 1.23):\n\nThe $source is the variable we want to transform (here time_spent)- don’t change this.\nSelect the appropriate comparison operator (here &lt;= )\nIn the next box, we will put the time_spent value we want as the cut off point (e.g., 3).\nAfter the use, add our new label (here '0-3'). If we are using text we must enclose it in '...'\n\n\n\n\n\n\n\nFigure 1.23: Adding the first condition (0-3).\n\n\n\n \nWe can add as many conditions as we want by selecting + Add recode condition. This will add a new if $source line into the box (Figure 1.24). Remember they will be executed in order.\n\n\n\n\n\n\nFigure 1.24: Adding the second condition (4-7).\n\n\n\n \n\n\n\n\n\n\nFigure 1.25: Adding the third condition (8-11).\n\n\n\n \nFinally, after the else use box just add the label for the data that does not meet the above conditions (here '&gt;11'), as shown in Figure 1.26.\n\n\n\n\n\n\nFigure 1.26: Adding the final label for the data that does not meet the above conditions (&gt;11).\n\n\n\n \n\n\n1.9.2 Reverse scoring of items\nTo compute the total score for all items of the RSES, we first need to reverse the scores of the negatively worded questions (3, 5, 8, 9, and 10). To do this, we can follow these simple steps.\nIn the Variables tab, we select the checkboxes for the q3, q5, q8, q9, and q10 variables, as shown in Figure 1.27.\n\n\n\n\n\n\nFigure 1.27: Select the variables to be reversed.\n\n\n\n \nAfter that, we click on the Transform button ) from the toolbar of the Variables tab to open the Transform variable settings. Then, we Create New Transform, as shown in Figure 1.28.\n\n\n\n\n\n\nFigure 1.28: Open the Transform variable settings.\n\n\n\n \nIn the Transform view, we enter _R as a suffix for the variable names and specify 3-$source in the condition box, as shown in Figure 1.29.\n\n\n\n\n\n\nFigure 1.29: Transform variable settings.\n\n\n\n\n\n\n\n\n\nFigure 1.30: Data with the reversed variables.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "introduction.html#compute-a-new-variable",
    "href": "introduction.html#compute-a-new-variable",
    "title": "1  Introduction to Jamovi and data preparation",
    "section": "1.10 Compute a new variable",
    "text": "1.10 Compute a new variable\nFinally, we compute each participant’s total score (ranging from 0 to 30) based on their responses to the 10 questions of the Rosenberg Self-Esteem Scale.\nAdding computed variables to a Jamovi spreadsheet is straightforward. Click on the Compute button ) from the toolbar of the Data tab. An empty column has been created at the end of our dataset (Figure 1.31). The black dot symbol in the right of the column header indicates that this is a computed variable.\n\n\n\n\n\n\nFigure 1.31: Compute a new variable.\n\n\n\nTo set up the computed variable, either double-click the column header, or click the Setup button ) in the Data tab. This opens the “COMPUTED VARIABLE” view, where we can name the computed variable score. Next, we select the SUM function from the available options for use in the Formula box. Finally, we add the q-variables in the formula separated by comma (note that we must use the reversed variables in the sum) and we press ENTER (Figure 1.32).\n\n\n\n\n\n\nFigure 1.32: Computation of the total score.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Jamovi and data preparation</span>"
    ]
  },
  {
    "objectID": "anova1.html",
    "href": "anova1.html",
    "title": "2  ANOVA Designs (1)",
    "section": "",
    "text": "2.1 One-way between-subjects Analysis of Variance (One-way ANOVA)\nThe one-way between-subjects analysis of variance (one-way ANOVA) is used to compare more than two independent (unrelated or unpaired) samples. We may think of it as an extension of Student’s t-test.\nAlthough, ANOVA can detect whether there are mean differences between groups, it does not identify which groups are different from the others. At first, we might consider to compare all groups in pairs with t-tests. However, this approach can lead to incorrect conclusions due to the multiple comparisons problem. Each additional t-test increases the likelihood of making at least one Type I error (false positive) across the set (often called a family) of comparisons.\nThis is why, after an ANOVA test concludes that at least one difference exists between groups (omnibus analysis), we should perform statistical tests that account for the number of comparisons (post hoc tests). Some of the most commonly used post hoc tests include the Tukey test, Bonferroni correction, and Holm test.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ANOVA Designs (1)</span>"
    ]
  },
  {
    "objectID": "anova1.html#one-way-between-subjects-analysis-of-variance-one-way-anova",
    "href": "anova1.html#one-way-between-subjects-analysis-of-variance-one-way-anova",
    "title": "2  ANOVA Designs (1)",
    "section": "",
    "text": "2.1.1 Importing data\nThe SAT is used by a wide range of colleges and universities as part of the application process for college admission. Assume we are interested in the effect of preparation time on SAT performance.\nIn this example, we have five student groups, each containing seven cases. The groups contain students who have studied for either zero, two, four, six, or eight months prior to taking the SAT.\n\n\n\n\n\n\n\n\nFigure 2.1: Table with raw data.\n\n\n\n\nOpen the dataset named “sat” from the file tab in the menu (Figure 2.2).\n\n\n\n\n\n\nFigure 2.2: The sat dataset.\n\n\n\n \nWe prepare the data as follows (Figure 2.3):\n\n\n\n\n\n\nFigure 2.3: The modified dataset.\n\n\n\n\n\n2.1.2 Research question\nA quaziexperimental study explored the effect of preparation time on SAT performance, with students having studied for different duration (zero, two, four, six, or eight months). The question of interest is whether the mean SAT score differs across these preparation times.\n\n\n2.1.3 Hypothesis testing for the one-way ANOVA test\n\n\n\n\n\n\nNull hypothesis and alternative hypothesis\n\n\n\n\n\\(H_0\\): all group means are equal (the means of SAT in the five conditions are equal: \\(\\mu_{1} = \\mu_{2} = \\mu_{3} = \\mu_{4} = \\mu_{5}\\))\n\\(H_1\\): at least one group mean differs from the others (there is at least one group with mean SAT score different from the others)\n\n\n\n\n\n2.1.4 Assumptions\n\nThe dependent variable, satscore, should be approximately normally distributed for all groups. To increase the number of observations used in assessing normality, we often examine the residuals from the ANOVA model for the entire dataset using a normal quantile plot of the standardized residuals (Normal Q-Q plot).\nThe data in groups have similar variance (also named as homogeneity of variance or homoscedasticity).\n\n\n\n2.1.5 Descriptive statistics and plots\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Exploration) -.-&gt; B(Descriptives)\n\n\n\n\n\n\nas shown below in Figure 2.4.\n\n\n\n\n\n\nFigure 2.4: Select exploration and Desctriptives.\n\n\n\nHighlight satscore in the left panel and click it (or drug it) over the the Variables. Then highlight the group and click it over the Split by (Figure 2.5). Additionally, select variables across rows.\n\n\n\n\n\n\nFigure 2.5: Descriptive dialog box.\n\n\n\n \nThe default descriptive statistics are shown in Figure 2.6: the mean, median, standard deviation, minimum and maximum.\n\n\n\n\n\n\nFigure 2.6: Descriptive statistics.\n\n\n\nTo generate boxplots, click the Plots, and check Box plot, Data, and Mean.\n\n\n\n\n\n\nFigure 2.7: Selection of boxplots.\n\n\n\n\n\n\n\n\n\nFigure 2.8: Boxplots.\n\n\n\nThe plot suggests that the mean SAT score (black square) increases as the months progress, suggesting a positive association between time and SAT score improvement.\n\n\n2.1.6 ANOVA (omnibus analysis)\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(ANOVA) -.-&gt; C(ANOVA)\n\n\n\n\n\n\nas shown below in Figure 4.4.\n\n\n\n\n\n\nFigure 2.9: Conducting ANOVA test in Jamovi. In the menu at the top, choose Analyses -&gt; ANOVA  -&gt; ANOVA.\n\n\n\nNOTE: There is also a One-Way ANOVA menu option. This version of the ANOVA analysis does not have all the options we want so we are not going to use this method, so we will run our analysis via “ANOVA” rather than “One-Way ANOVA”.\n \nIn the ANOVA dialog box, highlight satscore in the left panel and click it (or drug it) over the the Dependent Variable. Then highlight the group and click it over the Fixed Factors (Figure 2.10). Additionally, check \\(\\eta^2\\).\n\n\n\n\n\n\nFigure 2.10: ANOVA dialog box.\n\n\n\n \nAssumptions Checks\nClick the Assumptions Checks, and check Homogeneity test, Normality test, and Q-Q plot (Figure 4.9).\n\n\n\n\n\n\nFigure 2.11: Assumption selections for ANOVA.\n\n\n\n\nNormality of distributions\n\n\n\n\n\n\n\nRemember: Hypothesis testing for Shapiro-Wilk test for normality\n\n\n\n\\(H_{0}\\): the data came from a normally distributed population.\n\\(H_{1}\\): the data tested are not normally distributed.\n\nIf p − value &lt; 0.05, reject the null hypothesis, \\(H_{0}\\).\nIf p − value ≥ 0.05, do not reject the null hypothesis, \\(H_{0}\\).\n\n\n\n\n\n\n\n\n\nFigure 2.12: Normality test.\n\n\n\nThe Shapiro-Wilk test of normality suggests normal distributions (p=0.56 &gt; 0.05; \\(H_o\\) is not rejected).\n \n\n\n\n\n\n\nFigure 2.13: Normal Q-Q plot.\n\n\n\nThe data points mostly fall along the diagonal line, indicating that the residuals are approximately normally distributed. Additionally, there are no extreme deviations or systematic patterns, suggesting that normality holds well.\n \n\nEquality of variances\n\n\n\n\n\n\n\nRemember: Hypothesis testing for Levene’s test for equality of variances\n\n\n\n\\(H_{0}\\): the variances of WeightLoss in all groups are equal (\\(σ^2_1=σ^2_2=σ^2_3=σ^2_4=σ^2_5\\))\n\\(H_{1}\\): the variances of satscore differ between groups (\\(σ^2_i\\neq σ^2_j\\), where \\(i,j= 1, 2, 3, 4, 5\\) and \\(i\\neq j\\))\n\nIf p − value &lt; 0.05, reject the null hypothesis, \\(H_{0}\\).\nIf p − value ≥ 0.05, do not reject the null hypothesis, \\(H_{0}\\).\n\n\n\n\n\n\n\n\n\nFigure 2.14: Levene’s test.\n\n\n\nSince p = 0.239 &gt; 0.05, the \\(H_0\\) of the Levene’s test is not rejected and the variances of the five conditions are comparable; in short, it appears that the assumption of homogeneity of variance is not violated.\n \nANOVA table\n\n\n\n\n\n\nFigure 2.15: Summary table of ANOVA.\n\n\n\n \nIn Figure 2.15, the F-statistic is calculated as follows:\n\\[F= \\frac{Mean \\ Square \\ between \\ groups}{Mean \\ Square \\ within \\ groups} = \\frac{Mean \\ Square \\ group}{Mean \\ Square \\ residuals} = \\frac{57624.3}{1325.7} = 43.467\\]\nNote that we compare this value to an F-distribution (F-test). The degrees of freedom in the numerator (df1) and the denominator (df2) are 4 and 30, respectively.\nThe p-value &lt; 0.001 (reject \\(H_0\\) of the ANOVA test). There is at least one condition with mean SAT score which is different from the other means.\nThis table also presents the eta squared (\\(\\eta^2 = 0.85\\)) , which expresses the proportion of variability explained by the group relative to the total variability:\n\\[\\eta^2 = \\frac{Sum \\ of \\ squares \\ group}{Total \\ sum \\ of \\ squares} = \\frac{230497}{230497 + 39771} = \\frac{230497}{270268}=0.85\\]\nA value of 0.85 (85%) means that 85% of the variation in SAT scores can be attributed to the preparation time and would be considered a large effect size. (NOTE: Whether the \\(\\eta^2\\) value is considered “high” or not is relative and depends on the research context).\n \n\n\n2.1.7 Post hoc tests\nClick the Post Hoc Tests, then highlight the group in the left panel and click it (or drug it) over the the right panel. Check Tukey correction.\n\n\n\n\n\n\nFigure 2.16: Post Hoc Tests panels.\n\n\n\n \n\n\n\n\n\n\nFigure 2.17: Post Hoc Tests (Tukey correction).\n\n\n\nFor example, the mean difference between zero months and two months is: 412.857 - 474.286 = -61.429, which is significant (p=0.028).\n \n\nInterpretation\nAn analysis of variance showed that the amount of preparation for the SAT in which students engaged appeared to significantly affect their performances on the test, F(4, 30) = 43.47, p &lt; 0.001, \\(\\eta^2 = 0.85\\). Post-hoc analyses with Tukey’s test, adjusting p-values for multiple comparisons, indicated that each additional two months of study up to six months was associated with significantly higher SAT scores. However, there was no significant difference in scores between the six month and eight month study groups.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ANOVA Designs (1)</span>"
    ]
  },
  {
    "objectID": "anova2.html",
    "href": "anova2.html",
    "title": "3  ANOVA Designs (2)",
    "section": "",
    "text": "3.1 One-way within-subjects Analysis of Variance (repeated one-way ANOVA)\nThe one-way repeated measures analysis of variance (also known as a within-subjects ANOVA) is an extension of the paired t-test designed to assess whether there are significant differences in the means of three or more related groups, such as comparing the difference between three or more time points.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA Designs (2)</span>"
    ]
  },
  {
    "objectID": "anova2.html#one-way-within-subjects-analysis-of-variance-repeated-one-way-anova",
    "href": "anova2.html#one-way-within-subjects-analysis-of-variance-repeated-one-way-anova",
    "title": "3  ANOVA Designs (2)",
    "section": "",
    "text": "3.1.1 Importing data\nIn hypothetical study, it is hoped that a certain drug will alleviate the intensity of symptoms of a certain disease. Symptom intensity was evaluated on a twelve-point scale with higher values indicating more intense symptoms. Two pre-treatment baseline measurements are made, the first a month prior to treatment and the second one week prior to treatment. Post-treatments measures of symptom intensity are made after one week, one month, and one year following administration of the drug. In this simplified example, we have eight patients in the study.\n\n\n\n\n\n\n\n\nFigure 3.1: Table with raw data.\n\n\n\n\nOpen the dataset named “symptoms” from the file tab in the menu (Figure 3.2).\n\n\n\n\n\n\nFigure 3.2: The symptoms dataset.\n\n\n\n \nWe prepare the data as follows (Figure 3.3):\n\n\n\n\n\n\nFigure 3.3: The modified dataset.\n\n\n\n\n\n3.1.2 Research question\nA study investigated the effect of a drug on symptom intensity in a specific disease, assessing eight patients before (two pre-test baseline measures) and after treatment (three post-test measures). The primary question is whether the mean symptom intensity score changed over time.\n\n\n3.1.3 Hypothesis testsing for the one-way repeated ANOVA test\n\n\n\n\n\n\nNull hypothesis and alternative hypothesis\n\n\n\n\n\\(H_0\\): all related group means are equal (the means of symptom intensity score in the five time points are equal: \\(\\mu_{1} = \\mu_{2} = \\mu_{3} = \\mu_{4} = \\mu_{5}\\))\n\\(H_1\\): at least one group mean differs from the others (there is at least one group with mean symptom intensity score different from the others)\n\n\n\n\n\n3.1.4 Assumptions\n\nThe data are normally distributed in all time points.\nThe variances of the differences between all possible pairs of within-subject conditions are equal (sphericity assumption).\n\n\n\n3.1.5 ANOVA (omnibus analysis)\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(ANOVA) -.-&gt; C(Repeated Measures ANOVA)\n\n\n\n\n\n\nas shown below in Figure 3.4.\n\n\n\n\n\n\nFigure 3.4: Conducting ANOVA test in Jamovi. In the menu at the top, choose Analyses -&gt; ANOVA  -&gt; Repeated Measures ANOVA.\n\n\n\n \nIn the repeated ANOVA dialog box, define the levels of the “RM Factor 1” which we will rename as time. Then, highlight the variables from pre1 to post3 in the left panel and click them (or drug them) to the Repeated Measure Cells. Additionally, check \\(\\eta^2\\) and Partial \\(\\eta^2\\) (Figure 3.5).\n\n\n\n\n\n\nFigure 3.5: Repeated ANOVA dialog box.\n\n\n\n \n\n\n3.1.6 Descriptive statistics and plots\n\n\n\n\n\n\nFigure 3.6: The estimated marginal means panels.\n\n\n\n\n\n\n\n\n\nFigure 3.7: Descriptive statistics.\n\n\n\n\n\n\n\n\n\nFigure 3.8: Plot with means.\n\n\n\nThe graph shows a clear reduction in mean symptom intensity after the treatment.\n \nAssumptions Checks\nClick on Assumptions Checks, select Sphericity tests, and Q-Q Plot (Figure 3.9).\n\n\n\n\n\n\nFigure 3.9: Assumption selections for repeated ANOVA.\n\n\n\n\nNormality of distributions\n\n\n\n\n\n\n\nFigure 3.10: Normal Q-Q plot.\n\n\n\n\nSphericity assumption\n\nThis assumption is usually checked with the Mauchly’s sphericity test, where null hypothesis states that the variances of the differences are equal (Figure 3.11).\n\n\n\n\n\n\nFigure 3.11: Assumption selections for repeated ANOVA.\n\n\n\nIn our example, the assumption of sphericity has not been met (p = 0.043). In this case, we have to correct the degrees of freedom in repeated ANOVA analysis.\nThere are two correction options \\(\\epsilon\\) available: Greenhouse-Geisser (GGe), or Huynh-Feldt (HFe) (Figure 3.12). The general recommendation is to use the Greenhouse-Geisser \\(\\epsilon\\) correction when it is less than 0.75; otherwise, we should use the Huynh-Feldt \\(\\epsilon\\) correction.\nAs the GGe value is less than 0.75, we use the Greenhouse-Geisser adjustment of 0.488.\n\n\n\n\n\n\nFigure 3.12: Assumption selections for repeated ANOVA.\n\n\n\nThe corrected degrees of freedom are:\n\\(df_1*GGe=4*0.488=1.95\\)\nand\n\\(df_2*HFe=28*0.488=13.66\\).\n \nRepeated ANOVA table\n\n\n\n\n\n\nFigure 3.13: Summary table of repeated ANOVA.\n\n\n\nAs we can see from Figure 3.13, the within-subjects variable (time) was statistically significant under the Greenhouse-Geisser correction, F(1.95, 13.66) = 18.624, p &lt; 0.001, \\(\\eta^2_p = 0.727\\).\n\n\n3.1.7 Post hoc tests\nClick the Post Hoc Tests, then highlight the time in the left panel and click it (or drug it) over the the right panel. Check Bonferroni correction.\n\n\n\n\n\n\nFigure 3.14: Post Hoc Tests panels.\n\n\n\n \n\n\n\n\n\n\nFigure 3.15: Post Hoc Tests (Bonferroni correction).\n\n\n\n \n\nInterpretation\nBased on Greenhouse-Geisser correction for violation of sphericity, a one-way within-subjects ANOVA revealed a significant difference in the pre-test and post-test means, F(1.95, 13.66) = 18.62, p &lt; 0.001, within-subjects \\(\\eta^2 = 0.73\\). Pairwise comparisons using a Bonferroni correction to maintain an alpha level of 0.05 revealed that intensity of symptoms remained constant from the two pre-test baseline measures, significantly decreased after a week following drug therapy, and further significantly decreased after one month. Symptom intensity did not significantly differ from that level at the end of a year.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA Designs (2)</span>"
    ]
  },
  {
    "objectID": "anova3.html",
    "href": "anova3.html",
    "title": "4  ANOVA Designs (3)",
    "section": "",
    "text": "4.1 Two-way between-subjects Analysis of Variance (Two-way ANOVA)\nA research design is not limited to examining the effects of a single independent variable. In this section, we will explore how to incorporate a second independent variable. A design that includes multiple independent variables is known as a factorial design, where each level of one independent variable is combined with each level of the other.\nAfter obtaining a significant ANOVA result, it is essential to conduct post hoc tests that account for the number of comparisons to ensure accurate statistical interpretation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA Designs (3)</span>"
    ]
  },
  {
    "objectID": "anova3.html#two-way-between-subjects-analysis-of-variance-two-way-anova",
    "href": "anova3.html#two-way-between-subjects-analysis-of-variance-two-way-anova",
    "title": "4  ANOVA Designs (3)",
    "section": "",
    "text": "4.1.1 Importing data\nAssume that researchers are interested in exploring the role of analogical thinking in the problem-solving skills of children and adolescents. The researchers sample 21 students from primary school (6th grade students from “Dimotiko”, ages 11-12) and 21 students from secondary school (3rd grade students from “Gymnasium”, ages 14-15). The students are then randomly assigned to one of three groups, each consisting of 7 students: a control group, experimental group 1 (exposure to similar examples without instructions), and experimental group 2 (exposure to similar examples with instructions). The outcome measured is the number of mistakes made while attempting to solve the problems.\n\n\n\n\n\n\n\n\nFigure 4.1: Table with raw data.\n\n\n\n\nOpen the dataset named “mistakes” from the file tab in the menu (Figure 4.2).\n\n\n\n\n\n\nFigure 4.2: The mistakes dataset.\n\n\n\n \nWe prepare the data as follows (Figure 4.3):\n\n\n\n\n\n\nFigure 4.3: The modified dataset.\n\n\n\n\n\n4.1.2 Research question\nThe question of interest is whether the effect of school age and instructions on the number of mistakes. Specifically, we want to answer the following questions:\n\nDoes the number of mistakes differ based on instructions?\nDoes it differ based on school age?\nDoes the effect of instructions on the number of mistakes depend on school age (moderator)?\n\n\n\n4.1.3 Hypothesis testing for the one-way ANOVA test\n\n\n\n\n\n\nNull and alternative hypotheses\n\n\n\nMain effect: intervention\n\n\\(H_0\\): There is no significant difference in number of mistakes between intervention groups (\\(\\mu_{control} = \\mu_{exper1} = \\mu_{exper2}\\))\n\\(H_1\\): At least one intervention has a significantly different mean number of mistakes.\n\nMain effect: school age\n\n\\(H_0\\): There is no significant difference in number of mistakes between primary and secondary school. (\\(\\mu_{primary} = \\mu_{secondary}\\))\n\\(H_1\\): There is a significant difference in number of mistakes between primary and secondary school (\\(\\mu_{primary} \\neq \\mu_{secondary}\\)).\n\nInteraction effect between intervention and school age\n\n\\(H_0\\): There is no interaction effect between intervention and school age on number of mistakes (i.e., the effect of intervention on number of mistakes does not depend on school age).\n\\(H_1\\): There is a significant interaction effect between intervention and school age on number of mistakes (i.e., the effect of intervention on number of mistakes varies depending on school age).\n\n\n\n\n\n4.1.4 Assumptions\n\nNormality of Residuals: The number of mistakes should be approximately normally distributed within each group (i.e., for each combination of gender and residential community).\nHomogeneity of Variance (Homoscedasticity): The variance of number of mistakes should be approximately equal across all groups. (also named as homogeneity of variance or homoscedasticity).\n\n\n\n4.1.5 ANOVA (omnibus analysis)\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(ANOVA) -.-&gt; C(ANOVA)\n\n\n\n\n\n\nas shown below in Figure 4.4.\n\n\n\n\n\n\nFigure 4.4: Conducting ANOVA test in Jamovi. In the menu at the top, choose Analyses -&gt; ANOVA  -&gt; ANOVA.\n\n\n\n \nIn the ANOVA dialog box, highlight intervention in the left panel and drug it to the the Dependent Variable. Then highlight the gender and school_age and drug them to the Fixed Factors (Figure 4.5). Additionally, check \\(\\eta^2\\).\n\n\n\n\n\n\nFigure 4.5: ANOVA dialog box.\n\n\n\n \n\n\n4.1.6 Descriptive statistics and plots\n\n\n\n\n\n\nFigure 4.6: The estimated marginal means panels.\n\n\n\n\n\n\n\n\n\nFigure 4.7: Descriptive statistics.\n\n\n\n\n\n\n\n\n\nFigure 4.8: Plot with means.\n\n\n\nWe have created an interaction plot that illustrates the simple effects of intervention for primary and secondary school students. The resulting plot shows an interaction because the lines are not parallel. In this example, school age is a moderator.\n \nAssumptions Checks\nClick the Assumptions Checks, and check Homogeneity test, Normality test, and Q-Q plot (Figure 4.9).\n\n\n\n\n\n\nFigure 4.9: Assumption selections for ANOVA.\n\n\n\n\n\n\n\n\n\nFigure 4.10: Normality test.\n\n\n\nThe Shapiro-Wilk test of normality suggests normal distributions (p=0.08 &gt; 0.05; \\(H_o\\) is not rejected).\n \n\n\n\n\n\n\nFigure 4.11: Normal Q-Q plot.\n\n\n\nThe data points mostly fall along the diagonal line, indicating that the residuals are approximately normally distributed.\n \n\nEquality of variances\n\n\n\n\n\n\n\nFigure 4.12: Levene’s test.\n\n\n\nSince p = 0.19 &gt; 0.05, the \\(H_0\\) of the Levene’s test is not rejected and the variances are comparable.\n \nANOVA table\n\n\n\n\n\n\nFigure 4.13: Summary table of ANOVA.\n\n\n\nWe observe that both main effects—intervention (F = 14.2, p &lt;0.001) and school age (F = 48.9, p &lt;0.001), are significant. Additionally, the interaction is also significant (F = 23.1, p &lt;0.001).\nA key principle in interpreting and reporting factorial analysis results is that interactions take precedence over main effects. This is because interactions offer a more detailed and comprehensive understanding of the data.\nTherefore, we can conduct a simple effects analysis (which can be performed in the Linear Models module) and follow up with post hoc tests.\n\n\n\n\n\n\nFigure 4.14: Simple effects (school age as moderator).\n\n\n\nThe number of mistakes in the intervention groups differs significantly only among secondary school students (F = 36.7, p &lt;0.001).\n \n\n\n\n\n\n\nFigure 4.15: Simple effects (intervention as moderator).\n\n\n\nThe number of mistakes between primary school and secondary school students are significant for the experimental groups (F = 12.2, p = 0.001 and F = 82.8, p &lt;0.001).\n\n\n4.1.7 Post hoc tests\nClick the Post Hoc Tests, then highlight the gender x residence in the left panel and click it over the the right panel. Check Tukey correction.\n\n\n\n\n\n\nFigure 4.16: Post Hoc Tests panels.\n\n\n\n \n\n\n\n\n\n\nFigure 4.17: Post Hoc Tests (Bonferroni correction).\n\n\n\n \n\nInterpretation\nSimple effects tests were conducted using the Tukey adjustment to maintain an alpha level of 0.05. Results showed that the effect of instructions on the number of mistakes depends on school age.\nPrimary school students showed a relatively stable number of mistakes across all three groups, with their mistakes remaining high even with experimental interventions.\nSecondary school students demonstrated a significant decrease in mistakes. Specifically, there was a significant reduction in mistakes when comparing the control group to the group exposed to examples (MD = 12.6, p = 0.019). Adding instructions led to an even greater reduction in mistakes (MD = 18.9, p &lt;0.001), indicating that explicit guidance further enhanced their problem-solving skills.\nAdditionally, secondary school students made significantly fewer mistakes than primary school students in both experimental interventions, suggesting that older children may have a stronger ability to apply analogical reasoning in problem-solving after being exposed to similar examples and instructions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA Designs (3)</span>"
    ]
  },
  {
    "objectID": "linear1.html",
    "href": "linear1.html",
    "title": "5  Linear regression (1)",
    "section": "",
    "text": "5.1 Introduction to simple linear regression\nSimple linear regression involves a numeric dependent (or response) variable \\(Y\\) and one independent (or explanatory) variable \\(X\\) that is either numeric or categorical.\nOften it is of interest to quantify the linear association between two numeric variables, \\(X\\) and \\(Y\\), and given the value of one variable for an individual, to predict the value of the other variable. This is not possible from the correlation coefficient as it simply indicates the strength of the association as a single number; in order to describe the association between the values of the two variables, a technique called regression is used. In regression, we assume that a change in the independent variable, \\(X\\), will lead directly to a change in the dependent variable \\(Y\\). However, the term “dependent” does not necessarily imply a cause-and-effect relationship between the two variables.\nWe may recall from secondary/high school algebra that the equation of a line is: \\[y = \\beta_o + \\beta_1 \\cdot x \\tag{5.1}\\]\nThe Equation 5.1 is defined by two coefficients (parameters) \\(\\beta_o\\) and \\(\\beta_1\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#introduction-to-simple-linear-regression",
    "href": "linear1.html#introduction-to-simple-linear-regression",
    "title": "5  Linear regression (1)",
    "section": "",
    "text": "Figure 5.1: The equation of line.\n\n\n\n\n\nThe intercept coefficient \\(\\beta_o\\) is the value of \\(y\\) when \\(x = 0\\) (the point where the fitted line crosses the y-axis; Figure 5.1).\nThe slope coefficient \\(\\beta_1\\) for \\(x\\) is the mean change in \\(y\\) for every one unit increase in \\(x\\) (Figure 5.1).\n\n\n5.1.1 Importing data\n\n\n\n\n\n\n\n\nFigure 5.2: Table with raw data.\n\n\n\n\nOpen the dataset named “BirthWeight” from the file tab in the menu (Figure 5.3).\n\n\n\n\n\n\nFigure 5.3: The BirthWeight dataset.\n\n\n\nData of 550 infants at 1 month age was collected. The following variables were recorded:\n• Body weight of the infant in g (weight)\n• Body height of the infant in cm (height)\n• Head circumference in cm (headc)\n• Gender of the infant (gender: Female, Male)\n• Birth order in their family (parity: Singleton, One sibling, 2 or more siblings)\n• Education of the mother (education: tertiary, year10, year12)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#research-question",
    "href": "linear1.html#research-question",
    "title": "5  Linear regression (1)",
    "section": "5.2 Research question",
    "text": "5.2 Research question\nLet’s say that we want to model the association between height and weight for the sample of 550 infants of 1 month age. In other words, we want to find the parameters of a mathematical equation, such as \\(y = \\beta_o + \\beta_1 \\cdot x\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#hypothesis-testsing",
    "href": "linear1.html#hypothesis-testsing",
    "title": "5  Linear regression (1)",
    "section": "5.3 Hypothesis Testsing",
    "text": "5.3 Hypothesis Testsing\n\n\n\n\n\n\nNull hypothesis and alternative hypothesis\n\n\n\n\n\\(H_{0}:\\) the two variables are not linearly related. There is no effect between height and weight (\\(β_1 = 0\\)).\n\\(H_{1}:\\) the two variables are linearly related. There is an effect between height and weight (\\(β_1 \\neq 0\\)).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#scatter-plot",
    "href": "linear1.html#scatter-plot",
    "title": "5  Linear regression (1)",
    "section": "5.4 Scatter plot",
    "text": "5.4 Scatter plot\nWe start our analysis by creating the scatter plot of the response variable weight and the explanatory variable height. The pattern of the plotted points typically reveals the nature and strength of the association between the two variables.\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Exploration) -.-&gt; C(Scatterplot)\n\n\n\n\n\n\nas shown below in Figure 5.4.\n\n\n\n\n\n\nFigure 5.4: In the menu at the top, choose Analyses &gt; Exploration  &gt; Scatterplot.\n\n\n\nIn the ANOVA dialog box, highlight height in the left panel and drug it to the the X-axis. Then highlight the weight drug it to the Y-axis (Figure 5.5). Additionally, check from the Regression Line “Linear”.\n\n\n\n\n\n\nFigure 5.5: The Scatterplot dialogue box options.\n\n\n\n\n\n\n\n\n\nFigure 5.6: The Scatter plot of height and weight.\n\n\n\nAs we can see in Figure 5.6, the points seem to be scattered around a line. The scatter plot also shows that, in general, infants with high height tend to have high weight (positive association).\nTo select the best fitting straight line of the data set, it is necessary to determine the estimated values \\(b_o\\) and \\(b_1\\) of parameters \\(\\beta_o\\) and \\(\\beta_1\\) in Equation 5.1. The regression equation of the model becomes:\n\\[\\widehat{y} = b_o  + b_1 \\cdot x \\tag{5.2}\\]\nWhy do we put a “hat” on top of the \\(y\\)? It’s a form of notation commonly used in regression to indicate that we have a predicted value, or the value of \\(y\\) on the regression line for a given \\(x\\) value.\n\n5.4.1 Linear regression\nThe process of fitting a linear regression model to the data involves finding a straight line that can be considered as the best representation of the overall association between age and lung capacity.\nTo choose a line, we need to explain what we mean by the “best representation” of the data. A “best-fitting” line refers to the line that minimizes the sum of squared residuals (RSS). Therefore, we refer to the resulting model as the least-squares linear regression model and to the corresponding line as the least-squares regression line.\n\n\n5.4.2 Fit a simple linear regression model\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Regression) -.-&gt; C(Linear Regression)\n\n\n\n\n\n\nas shown below (Figure 6.4).\n\n\n\n\n\n\nFigure 5.7: In the menu at the top, choose Analyses &gt; Regression  &gt; Linear Regression.\n\n\n\nThe Linear Regression dialogue box opens (Figure 5.8). From the left-hand pane drag the variable weight into the Dependent Variable field and the variable height into the Covariates field on the right-hand side, as shown below:\n\n\n\n\n\n\nFigure 5.8: The Linear Regression dialogue box options. Drag and drop the weight into the Dependent Variable field and the height into the Covariates field.\n\n\n\nNext, from the Assumption Checks section tick the box “Q-Q plot of residuals” (Figure 5.9).\n\n\n\n\n\n\nFigure 5.9: Assumption Checks choices.\n\n\n\n\n\n\n\n\n\nFigure 5.10: Normal Q-Q plot of the residuals.\n\n\n\nThe Figure 5.9 shows no significant deviation from normality.\n \nAdditionally, from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 6.16):\n\n\n\n\n\n\nFigure 5.11: Check the Confidence interval box in the Model Coefficients section.\n\n\n\nThe output table with the model coefficients should look like the following (Figure 5.12):\n\n\n\n\n\n\nFigure 5.12: The model coefficients table.\n\n\n\n \nNow, let’s focus on interpreting the regression table in Figure 5.12. In the estimate column are the intercept \\(b_o\\) = -5411.95 \\(\\approx 5412\\) and the slope \\(b_1\\) = 178.3 \\(\\approx 178\\) for height. Thus the equation of the regression line becomes:\n\\[\n\\begin{aligned}\n\\widehat{y} &= b_o + b_1 \\cdot x\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{height}\\\\\n\\widehat{\\text{weight}}&= -5412 + 178\\cdot\\text{height}\n\\end{aligned}\n\\]\n \nThe intercept \\(b_o\\)\nThe intercept \\(b_o =5412\\) is the average weight for those infants with height of 0. In graphical terms, it’s where the line intersects the \\(y\\) axis when \\(x\\) = 0 (Figure 5.13). Note, however, that while the intercept of the regression line has a mathematical interpretation, it has no physical interpretation here, since observing a weight of 0 is impossible.\n\n\n\n\n\n\n\n\nFigure 5.13: Data of infants’ body height-body weight with fitted line crossing the y-axis.\n\n\n\n\n\n \nThe slope \\(b_1\\)\nOf greater interest is the slope of height, \\(b_1 = 178\\), as it summarizes the association between the height and weight variables.\n\n\n\n\n\n\n\n\nFigure 5.14: Scatter plot of infants’ body height-body weight and graphically calculation of the slope.\n\n\n\n\n\nThe graphical calculation of the slope from two points of the fitted line is (Figure 5.14):\n\\[  \nb =\\frac{dy}{dx}=\\frac{5270-4560}{60-56}= \\frac{710}{4} \\approx 178\n\\] Note that, in this example, the coefficient has units g/cm.\nAdditionally, note that the sign is positive, suggesting a positive association between these two variables, meaning infants with higher height also tend to have higher weight. Recall from earlier that the correlation coefficient was \\(r = 0.71\\). They both have the same positive sign, but have a different value. Recall further that the correlation’s interpretation is the “strength of linear association”. The slope’s interpretation is a little different:\n\nFor every 1 cm increase in height, there is on average an associated increase of 178 g of weight.\n\nWe only state that there is an associated increase and not necessarily a causal increase. In other words, just because two variables are strongly associated, it doesn’t necessarily mean that one causes the other. This is summed up in the often quoted phrase, “correlation is not necessarily causation.”\nFurthermore, we say that this associated increase is on average 178 g of weight, because we might have two infants whose height differ by 1 cm, but their difference in weight won’t necessarily be exactly 178. What the slope of 178 is saying is that across all possible infants, the average difference in weight between two infants whose height differ by 1 cm is 178 g.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#the-standard-error-se-of-the-regression-slope",
    "href": "linear1.html#the-standard-error-se-of-the-regression-slope",
    "title": "5  Linear regression (1)",
    "section": "5.5 The Standard error (SE) of the regression slope",
    "text": "5.5 The Standard error (SE) of the regression slope\nThe third column of the regression table in Figure 5.12 corresponds to the standard error of our estimates. We are interested in understanding the standard error of the slope (\\(SE_{b}\\)).\n\nSay we hypothetically collected 1000 samples of pairs of weight and height, computed the 1000 resulting values of the fitted slope \\(b\\), and visualized them in a histogram. This would be a visualization of the sampling distribution of \\(b\\). The standard deviation of the sampling distribution of \\(b\\) has a special name: the standard error of \\(b\\).\n\nThe coefficient for the independent variable ‘height’ is 178.31. The standard error is 7.49, which is a measure of the variability around this estimate for the regression slope.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#test-statistic-and-confidence-intervals-for-the-slope",
    "href": "linear1.html#test-statistic-and-confidence-intervals-for-the-slope",
    "title": "5  Linear regression (1)",
    "section": "5.6 Test statistic and confidence intervals for the slope",
    "text": "5.6 Test statistic and confidence intervals for the slope\nThe 6th column of the regression table in Figure 5.12 corresponds to a t-statistic. The hypothesis testing for the slope is:\n\\[\n\\begin{aligned}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs } H_1&: \\beta_1 \\neq 0.\n\\end{aligned}\n\\]\nThe null hypothesis, \\(H_{0}\\), states that the coefficient of the independent variable (height) is equal to zero, and the alternative hypothesis, \\(H_{1}\\), states that the coefficient of the independent variable is not equal to zero.\nThe t-statistic for the slope is defined by the following equation:\n\\[\\ t = \\frac{\\ b_1}{\\text{SE}_{b_1}} \\tag{5.3}\\]\nIn our example:\n\\[\\ t = \\frac{\\ b_1}{\\text{SE}_{b_1}}=\\frac{\\ 178.31}{\\text{7.49}} = 23.81\\]\nIn practice, we use the p-value (as generated by Jamovi based on the value of the t-statistic Equation 5.3) to guide our decision:\n\nIf p − value &lt; 0.05, reject the null hypothesis, \\(H_{0}\\).\nIf p − value ≥ 0.05, do not reject the null hypothesis, \\(H_{0}\\).\n\nIn our example p &lt;0.001 \\(\\Rightarrow\\) reject \\(H_{0}\\).\nThe \\(95\\%\\) CI of the coefficient \\(b\\) for a significance level α = 0.05, \\(df=n-2\\) degrees of freedom and for a two-tailed t-test is given by:\n\\[ 95\\% \\ \\text{CI}_{b} = b \\pm t_{df; 0.05/2} \\cdot \\text{SE}_{b_1} \\tag{5.4}\\]\nIn our example:\n\\[ 95\\% \\ \\text{CI}_{b_1} = 178.31 \\pm 1.96 \\cdot \\text{7.49}= 178.31 \\pm 14.68 \\Rightarrow 95\\% \\text{CI}_{b_1}= \\ (163.6, 193)\\]  \n\n\n\n\n\n\nInterpretation of linear regression\n\n\n\nIn summary, we can say that the regression coefficient of the height (178) is significantly different from zero (p &lt; 0.001) and indicates that there’s on average an increase of 178 g (\\(95\\%\\)CI: 164 to 193) in weight for every 1 cm increase in height. Note that the \\(95\\%\\)CI does not include the hypothesized null value of zero for the slope.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#observed-predicted-fitted-values-and-residuals",
    "href": "linear1.html#observed-predicted-fitted-values-and-residuals",
    "title": "5  Linear regression (1)",
    "section": "5.7 Observed, predicted (fitted) values and residuals",
    "text": "5.7 Observed, predicted (fitted) values and residuals\nWe define the following three concepts:\n\nObserved values \\(y\\), or the observed value of the dependent variable for a given \\(x\\) value\nPredicted (or fitted) values \\(\\widehat{y}\\), or the value on the regression line for a given \\(x\\) value\nResiduals \\(y - \\widehat{y}\\), or the error (ε) between the observed value and the predicted value for a given \\(x\\) value\n\n\n\n\n\n\n\nFigure 5.15: The equation of line.\n\n\n\nThe residuals are exactly the vertical distance between the observed data point and the associated point on the regression line (predicted value) (Figure 5.15). Positive residuals have associated y values above the fitted line and negative residuals have values below. We want the residuals to be small in magnitude, because large negative residuals are as bad as large positive residuals.\nFigure 5.16 shows these values:\n\n\n\n\n\n\n\n\nID\n\n\nweight\n\n\nheight\n\n\nweight_hat\n\n\nresidual\n\n\n\n\n\n\n1\n\n\n3950\n\n\n55.5\n\n\n4483.486\n\n\n-533.486\n\n\n\n\n2\n\n\n4630\n\n\n57.0\n\n\n4750.930\n\n\n-120.930\n\n\n\n\n3\n\n\n4750\n\n\n56.0\n\n\n4572.634\n\n\n177.366\n\n\n\n\n4\n\n\n3920\n\n\n56.0\n\n\n4572.634\n\n\n-652.634\n\n\n\n\n5\n\n\n4559\n\n\n55.0\n\n\n4394.338\n\n\n164.662\n\n\n\n\n6\n\n\n3639\n\n\n51.5\n\n\n3770.301\n\n\n-131.301\n\n\n\n\n7\n\n\n3550\n\n\n56.0\n\n\n4572.634\n\n\n-1022.634\n\n\n\n\n8\n\n\n4530\n\n\n57.0\n\n\n4750.930\n\n\n-220.930\n\n\n\n\n9\n\n\n4969\n\n\n58.5\n\n\n5018.375\n\n\n-49.375\n\n\n\n\n10\n\n\n3740\n\n\n52.0\n\n\n3859.449\n\n\n-119.449\n\n\n\n\n\n\nFigure 5.16: Regression points (first 10 out of 550 infants).\n\n\n\n\nObserve in the above table that weight_hat contains the predicted (fitted) values \\(\\widehat{y}\\) = \\(\\widehat{\\text{weight}}\\).\nThe residual column is simply \\(e_i = y - \\widehat{y} = weight - weight\\_hat\\).\nLet’s see, for example, the values for the first infant and have a visual representation:\n\nThe observed value \\(y\\) = 3950 is infant’s weight for \\(x\\) = 55.5.\nThe predicted value \\(\\widehat{y}\\) is the value 4483.939 on the regression line for \\(x\\) = 55.5. This value is computed using the intercept and slope in the previous regression in Figure 5.16: \\[\\widehat{y} = b_o + b_1 \\cdot x = -5411.953 + 178.296 \\cdot 55.5 = 4483.48\\]\nThe residual is computed by subtracting the predicted (fitted) value \\(\\widehat{y}\\) from the observed value \\(y\\). The residual can be thought of as a model’s error or “lack of fit” for a particular observation. In the case of this infant, it is \\(y - \\widehat{y}\\) = 3950 - 4483.4 = -533.4 .\n\nA “best-fitting” line refers to the line that minimizes the sum of squared residuals (RSS), also known as sum of squared estimate of errors (SSE) out of all possible lines we can draw through the points. The method of least squares is the most popular method used to calculate the coefficients of the regression line.\n\\[ min(RSS) =min\\sum_{i=1}^{n}(y_i - \\widehat{y}_i)^2  \\tag{5.5}\\]\nIn Figure 5.17, we have found the minimum value of RSS (it turns out to be 97723317) and have drawn a horizontal dashed green line. At the point where this minimum touches the graph, we have read down to the x axis to find the best value of the slope. This is the value 178.\n\n\n\n\n\n\n\n\nFigure 5.17: The sum of the squares of the residuals against the value of the coefficient of the slope which we are trying to estimate.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#quality-of-a-linear-regression-fit",
    "href": "linear1.html#quality-of-a-linear-regression-fit",
    "title": "5  Linear regression (1)",
    "section": "5.8 Quality of a linear regression fit",
    "text": "5.8 Quality of a linear regression fit\nThe quality of a linear regression fit is typically assessed using two related quantities: residual standard error (RSE) and the coefficient of determination R\\(^2\\).\nResidual standard error (RSE)\nRSE represents the average distance that the observed values fall from the regression line. Conveniently, it tells us how wrong the regression model is on average using the units of the response variable. Smaller values are better because it indicates that the observations are closer to the fitted line. In our example:\n\\[\\ RSE = \\sqrt{\\frac{\\ RSS}{n-2}}= \\sqrt{\\frac{\\ 97723317}{550-2}}= 422.3 \\tag{5.6}\\]\n \nCoefficient of determination R\\(^2\\)\nThe quality of our simple linear model is presented in Figure 5.18:\n\n\n\n\n\n\nFigure 5.18: The coefficient of determination \\(R^2\\).\n\n\n\nThe R\\(^2\\) is the fraction of the total variation in \\(y\\) that is explained by the regression.\n\\[\\ R^2 = \\frac{\\ explained \\ \\ variation}{total \\ \\ variation} \\tag{5.7}\\]\nThe R\\(^2\\) value is called the coefficient of determination and indicates the percentage of the variance in the dependent variable that can be explained or accounted for by the independent variable. Hence, it is a measure of the ‘goodness of fit’ of the regression line to the data. It ranges between 0 and 1 (it won’t be negative). An R\\(^2\\) statistic that is close to 1 indicates that a large proportion of the variability in the response has been explained by the regression. A number near 0 indicates that the regression did not explain much of the variability in the response.\nIn our example takes the value 0.509. It indicates that about 50.9% of the variation in infant’s body weight can be explained by the variation of the infant’s body height. In simple linear regression \\(\\sqrt{0.509} = 0.713\\) which equals to the Pearson’s correlation coefficient, r.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#simple-linear-regression-with-a-binary-explanatory-variable",
    "href": "linear1.html#simple-linear-regression-with-a-binary-explanatory-variable",
    "title": "5  Linear regression (1)",
    "section": "5.9 Simple linear regression with a binary explanatory variable",
    "text": "5.9 Simple linear regression with a binary explanatory variable\nUsing the same sample of 550 infants of 1 month age we want to examine how body weight is associated with the gender of the infant. Now we have an explanatory variable x that is binary (Male/Female), as opposed to the numerical explanatory variable model (height) that we used previously.\nIn the Linear Regression dialogue box opens (Figure 5.19) drag the variable gender into the Factors field.\n\n\n\n\n\n\nFigure 5.19: The Linear Regression dialogue box options. Drag and drop the weight into the Dependent Variable field and the height into the Factors field.\n\n\n\nA graphical comparison of the weight between the males and females is presented below using the JJStatsPlot:\n\n\n\n\n\n\nFigure 5.20: Violin plot by gender.\n\n\n\nHow can we handle this variable in a mathematical equation? Well, we will use a trick. All cases in which the respondent is Male will be coded as 1 and all other cases, in which the respondent is Female, will be coded as 0 (reference category). This allows us to enter in the gender values as numerical (note that these numbers are just indicators).\n\\[\n\\text{gender} =\n\\begin{cases}\n1 & \\text{if infant is Male} \\\\\n0 & \\text{otherwise (ref.)}\n\\end{cases}\n\\]\nThe equation of the regression line will have the following form:\n\\[\n\\begin{aligned}\n\\widehat{y} &= b_o + b_1 \\cdot x\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{gender}\n\\end{aligned}\n\\]\nAdditionally, from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 6.16):\n\n\n\nCheck the Confidence interval box in the Model Coefficients section.\n\n\nThe output table with the model coefficients should look like the following (Figure 5.21):\n\n\n\n\n\n\nFigure 5.21: The model coefficients table.\n\n\n\nThe equation of the model becomes:\n\\[\n\\begin{aligned}\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{gender}\\\\\n\\widehat{\\text{weight}} &= 4140 + 452 \\cdot\\text{gender}\n\\end{aligned}\n\\]\n\nThe “intercept” represents the average weight of a female infant, which is 4140 g and serves as the reference category.\nThe “gender” term denotes the average weight difference between male and female infants, which is 452 g.\n\nTherefore, the mean weight of a male infant is (4140 + 452) 4592 g which is significantly higher (on average) about 452 g relative to a female infant (p&lt;0.001). The 95% confidence interval for this estimation (the difference in means) is 358 to 545 g.\nIt is important to note that the above analysis is equivalent to run a two-sample t-test.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear1.html#simple-linear-regression-with-a-categorical-explanatory-variable-2-categories",
    "href": "linear1.html#simple-linear-regression-with-a-categorical-explanatory-variable-2-categories",
    "title": "5  Linear regression (1)",
    "section": "5.10 Simple linear regression with a categorical explanatory variable (> 2 categories)",
    "text": "5.10 Simple linear regression with a categorical explanatory variable (&gt; 2 categories)\nSuppose that infants are categorized into three categories based on parity: singletons, having one sibling, or having 2 or more siblings. We choose as the reference category the singleton infants.\nIn the Linear Regression dialogue box opens (Figure 5.19) drag the variable gender into the Factors field.\n\n\n\n\n\n\nFigure 5.22: The Linear Regression dialogue box options. Drag and drop the weight into the Dependent Variable field and the parity into the Factors field.\n\n\n\nA graphical comparison of the weight between the males and females is presented below using the JJStatsPlot:\n\n\n\n\n\n\nFigure 5.23: Violin plot by gender.\n\n\n\nWe will use the previous trick and we will create 2 dummy variables to assign numerical values to the levels of parity. So each dummy variable will represent one category of the explanatory variable and will be coded with 1 if the case falls in that category and with 0 if not.\n\\[\n\\text{parity1} =\n\\begin{cases}\n1 & \\text{if infant has one sibling} \\\\\n0 & \\text{otherwise (ref.)}\n\\end{cases}\n\\]\n\\[\n\\text{parity2} =\n\\begin{cases}\n1 & \\text{if infant has 2 or more siblings} \\\\\n0 & \\text{otherwise (ref.)}\n\\end{cases}\n\\]\nThe equation of the regression line will have the following form:\n\\[\n\\begin{aligned}\n\\widehat{y} &= b_o + b_1 \\cdot x\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{parity1} + b_2 \\cdot\\text{parity2}\n\\end{aligned}\n\\]\nTherefore, we are including all the categories to the linear regression model except the one which is going to be used as the reference category (here is the Singleton). Actually, we create a multiple regression model which we will examine later analytically.\nWe also select from the Reference Level the “Singleton” category and from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 5.24):\n\n\n\n\n\n\nFigure 5.24: Select the reference level and check the Confidence interval box in the Model Coefficients section.\n\n\n\nThe output table with the model coefficients should look like the following (Figure 5.25):\n\n\n\n\n\n\nFigure 5.25: The model coefficients table.\n\n\n\nThe equation of the model becomes:\n\\[\n\\begin{aligned}\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot\\text{parity1} + b_2 \\cdot\\text{parity2}\\\\\n\\widehat{\\text{weight}} &= 4259 + 130 \\cdot\\text{parity1} + 192 \\cdot\\text{parity2}\n\\end{aligned}\n\\]\n\nThe intercept corresponds to the mean weight 4259 g for a singleton infant which is the reference category.\nThe mean weight of an infant with one sibling is 4389 g which is significantly higher (on average) about 130 g relative to a singleton infant (p=0.037). The 95% confidence interval for this estimation (the difference in means) is 8 to 252 g.\nThe mean weight of an infant with 2 or more siblings is 4451 g which is significantly higher (on average) about 192 g relative to a singleton infant (p=0.002). The 95% confidence interval for this estimation (the difference in means) is 68 to 316 g.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Linear regression (1)</span>"
    ]
  },
  {
    "objectID": "linear2.html",
    "href": "linear2.html",
    "title": "6  Linear regression (2)",
    "section": "",
    "text": "6.1 Multiple linear regression model\nAlthough multivariable regression may appear complex, its concepts, computations, and interpretations are direct extensions of those in simple regression.\nThe general form of a linear regression model is given by:\n\\[\\widehat{y} = b_o  + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_3 + ...+b_p \\cdot x_p \\tag{6.1}\\]\nThe objective is to obtain the coefficients-also known as partial regression slopes- \\(b_o, b_1, b_2, b_3,...,b_p\\).\nIt is important to emphasize that the term “linear” refers to the model’s linearity in the coefficients b, rather than in the explanatory variables x. For example, the following is still considered a general linear model:\n\\[\\widehat{y} = b_o  + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_1 \\cdot x_2 + b_4 \\cdot x_1^2 \\tag{6.2}\\]\nFor example, in Figure 6.1 we present a model consisted of one response variable (weight) and two continuous explanatory variables (height, headc):\n\\[\n\\begin{aligned}\n\\widehat{\\text{y}} &= b_o + b_1 \\cdot x_1 + b_2 \\cdot x_2\\\\\n\\widehat{\\text{weight}} &= b_o + b_1 \\cdot \\text{height} + b_2 \\cdot \\text{headc}\n\\end{aligned}\n\\]\nWe have visualized some of the points as being located above the plane and some as being located below the plane. The deviation of a point from the plane is represented by the dashed red line and is the residual. When the model contains more than two independent variables, it is described geometrically as a hyperplane.\nIt is important to note that the residuals in linear regression are assumed to be independent and identically distributed following the normal distribution with mean equals to zero and constant variance.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#multiple-linear-regression-model",
    "href": "linear2.html#multiple-linear-regression-model",
    "title": "6  Linear regression (2)",
    "section": "",
    "text": "Figure 6.1: For a model consisted of one response variable and two explanatory variables a plane in three-dimensional space may be fitted to the data points.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#basic-criteria-for-model-selection",
    "href": "linear2.html#basic-criteria-for-model-selection",
    "title": "6  Linear regression (2)",
    "section": "6.2 Basic criteria for model selection",
    "text": "6.2 Basic criteria for model selection\nIn simple linear regression, there is only one possible model, as it involves a single explanatory variable. However, in multiple linear regression, where multiple explanatory variables are involved, the challenge becomes identifying the best model. But what does “best” really mean?\nShould we select a model with only a few explanatory variables, or include as many as possible? For instance, if we have 20 potential explanatory variables, should we use all of them—or just a subset? And if we choose to use a subset, how do we decide which variables to include in order to optimize a particular function or goal?\nSurprisingly, these questions do not have straightforward answers—even for experienced researchers and data analysts. Variable selection in regression modeling is a complex task, and there is no universal agreement on the best approach. As we’ll see, choosing the “best” model often depends as much on scientific or practical considerations as on statistical criteria.\nA fundamental principle in model selection is the preference for simplicity. When comparing two models that explain the data equally well, the simpler model is generally favored. This principle, known as Occam’s Razor (or the law of parsimony), is widely embraced across scientific disciplines, including statistics.\n\nParcimonious model: We typically prefer simpler models, provided they account for similar amounts of variance as more complex ones.\n\nThe idea behind a parsimonious model is to avoid overfitting, where a model becomes too complex and starts to capture noise rather than the underlying patterns in the data. A parsimonious model aims to find a balance between complexity and performance, ensuring that the model is neither too simple (underfitting) nor too complex (overfitting).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#strategies-for-model-selection",
    "href": "linear2.html#strategies-for-model-selection",
    "title": "6  Linear regression (2)",
    "section": "6.3 Strategies for model selection",
    "text": "6.3 Strategies for model selection\nNext we present some commonly used strategies for model selection:\n\nSimultaneous Regression\n\nThe first and most straightforward approach to model selection is to include all available explanatory variables and assess model fit based on this complete model. This is known as full entry or simultaneous regression. In this method, the regression model is built by estimating all parameters simultaneously. However, there are cases where full-entry or simultaneous regression may not be the best choice for model-building. In such instances, the researcher may prefer to adopt a more complex algorithm for constructing the regression model.\n\nHierarchical Regression\n\nIn hierarchical regression, unlike in simultaneous regression, where all explanatory variables are entered into the model at once, researchers typically follow a pre-specified order for introducing variables creating multiple models or blocks. The order is usually driven by theory, reflecting the researcher’s prior knowledge. Hierarchical regression is particularly popular among social scientists when testing mediational hypotheses.\n\nAutomated regression methods (Best subset selection)\n\n(NOTE: This approach is not supported by JAMOVI.)\nThese methods combine the explanatory variables in all possible ways. The best subset selection (using backward elimination, forward selection, or both[stepwise selection]) seek to find the best model according to statistical criteria in many steps (stepwise method, the model is re-avaluated in each step). However, as you might imagine, the number of possible models quickly becomes quite large.\nIt is important to note that several statistical criteria can be used to assess the efficiency or fit of a model, with penalties for the number of explanatory variables. These criteria are calculated and compared across a set of competing models, providing an objective basis for selecting the “best” regression model. Examples include adjusted R-squared, Akaike Information Criterion (AIC)—where a smaller AIC indicates a better model—and Bayesian Information Criterion (BIC).\nAt first glance, especially for those new to statistics, automated selection methods may seem like an ideal solution for many multiple regression problems. They can appear to be the “panacea” for model selection—after all, allowing the computer to determine the “correct” model using its complex computational abilities seems like a logical approach.\nHowever, the issue is not as straightforward as it may seem, and several statistical and substantive challenges complicate the application of these methods. While automation offers convenience, it also has significant drawbacks, and not all decisions can or should be left to a computer. In addition to these statistical issues, there are substantive considerations to account for when selecting a model. The final model chosen by automated methods may not always offer the most practical value or utility.\nFrom a statistical perspective, automated selection methods, such as forward and backward regression, can introduce bias into parameter estimates, making the resulting inferential model unreliable. After multiple iterations, the probability of a Type I error becomes higher than the nominal \\(\\alpha\\) (typically 0.05). In addition to these statistical issues, there are substantive considerations to account for when selecting a model. The final model chosen by automated methods may not always offer the most practical value or utility.\n\nMaximizing statistical criteria is not the same as maximizing utility of the model.\n\n\nPurposeful selection process\n\nThe purposeful selection process begins with a univariable analysis of each candidate variable. A general decision rule is then applied to determine which variables to include. For example, any variable with a p-value &lt; 0.20 in the univariable analysis may be selected for the multivariable analysis.\nHowever, since the primary goal of a multivariable model is typically to assess the effect of the study intervention while controlling for potential confounders, variable selection should also take into account existing knowledge and the clinical significance of the variables. If necessary, the initial rule can be adjusted. For example, a potential confounder may be included in the model if it alters the coefficient of the primary exposure variable by 10% in the multivariable model.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#importing-data",
    "href": "linear2.html#importing-data",
    "title": "6  Linear regression (2)",
    "section": "6.4 Importing data",
    "text": "6.4 Importing data\nContinuing from the previous chapter, we will work with the BirthWeight dataset. This time, we aim to explore the association between infant weight and all other measured explanatory variables.\n\n\n\n\n\n\n\n\nFigure 6.2: Table with raw data.\n\n\n\n\nOpen the dataset named “BirthWeight” from the file tab in the menu.\n\n\n\n\n\n\nFigure 6.3: The BirthWeight dataset.\n\n\n\nData of 550 infants at 1 month age was collected. The following variables were recorded (Figure 6.3):\n• Body weight of the infant in g (weight)\n• Body height of the infant in cm (height)\n• Head circumference in cm (headc)\n• Gender of the infant (gender: Female, Male)\n• Birth order in their family (parity: Singleton, One sibling, 2 or more siblings)\n• Education of the mother (education: tertiary, year10, year12)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#simultaneous-regression",
    "href": "linear2.html#simultaneous-regression",
    "title": "6  Linear regression (2)",
    "section": "6.5 Simultaneous Regression",
    "text": "6.5 Simultaneous Regression\nFirst, we will include all available explanatory variables and assess model fit based on this complete model.\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Regression) -.-&gt; C(Linear Regression)\n\n\n\n\n\n\nas shown below (Figure 6.4).\n\n\n\n\n\n\nFigure 6.4: In the menu at the top, choose Analyses &gt; Regression  &gt; Linear Regression.\n\n\n\nThe Linear Regression dialogue box opens (Figure 5.8). From the left-hand pane drag the variable weight into the Dependent Variable field, the variables height and headc into the Covariates field, and the variables gender, parity, and education into the factors field on the right-hand side, as shown below (Figure 6.5):\n\n\n\n\n\n\nFigure 6.5: The Linear Regression dialogue box options. Drag and drop the variables in the fields on the right-hand side.\n\n\n\nWe also set reference groups for the categorical variables from the Reference Level box: “Female” for the gender variable, “Singleton” for the parity variable, and “year10” for the education variable.\n\n\n\n\n\n\nFigure 6.6: Reference Level box. Specify the reference group for the categorical variables.\n\n\n\n\n6.5.1 Assumptions\nSpecific assumptions have to be met for reliable hypothesis testing and confidence intervals in linear regression: independence of the residuals, linearity and homoscedasticity of the data, normality of the residuals, no multicollinearity and outliers. We will describe some statistical tests and diagnostic plots in Jamovi for testing the assumptions underlying linear regression model.\nFrom the Assumption Checks section tick the all the boxes and from the Data Summary the “Cook’s distance” (Figure 6.7):\n\n\n\n\n\n\nFigure 6.7: Assumption Checks choices.\n\n\n\n \nIndependence of residuals\nThe independence of residuals assumption means that for any two observations, the residual terms should be uncorrelated (or independent).\n\n\n\n\n\n\nFigure 6.8: The Durbin-Watson test.\n\n\n\nThe Durbin-Watson test assesses whether the residuals from a regression model are independent—that is, whether there is autocorrelation. Ideally, the Durbin-Watson statistic should be close to 2. Values significantly below 1 or above 3 suggest a violation of the independence assumption. In our case, the Durbin-Watson statistic is 1.83, which is close to 2, indicating no evidence of problematic autocorrelation.\n \nLinearity and homoscedasticity of the data\nTo examine linearity and homoscedasticity we examine the Residuals vs Fitted value Plot.\n\n\n\n\n\n\nFigure 6.9: Residuals vs Fitted values plot.\n\n\n\nWe would expect to see a random scatter of points around zero on the y-axis. In our example, the residuals appear randomly dispersed in a cloud-like pattern, which indicates that the assumption of linearity and homoscedasticity is satisfied.\n\nIf the residuals display a pattern—such as being more spread out at the ends and tighter in the middle (a bow tie shape), or more spread out on one side of the x-axis and tighter on the other (a funnel or fan shape)—this suggests heteroscedasticity. In such cases, the assumption of homoscedasticity is violated.\n\n\n\n\n\n\n\nFigure 6.10: Homoscedasticity Vs heteroscedasticity.\n\n\n\n \n\n\n6.5.2 Normality of the residuals\nThe check normality of the residuals with the Shapiro-Wilk’s test and the normal Q-Q plot of the residuals.\n\n\n\n\n\n\nFigure 6.11: The Durbin-Watson test.\n\n\n\nNote that this test almost always yields significant results for the distribution of residuals for large samples and visual inspection (e.g., Q-Q plots) are preferable.\n\n\n\n\n\n\nFigure 6.12: The Durbin-Watson test.\n\n\n\nThe Figure 6.12 shows no significant deviation from normality.\n \n\n\n6.5.3 No multicollinearity\nThis assumption means there should be no perfect or near-perfect linear relationship between two or more of the explanatory variables (predictors) in our regression model. Multicollinearity is a problem for three reasons:\n\nUntrustworthy \\(b\\): As multicollinearity increases, so do the standard errors of the \\(b\\) coefficients. We want smaller standard errors, so this is problematic.\nLimits the size of R, and therefore the size of \\(R^2\\), and we want to have the largest \\(R^2\\) possible, given our data.\nImportance of explanatory variables (predictors): When two explanatory variables are highly correlated, it is very hard to determine which variable is more important than the other.\n\nTo test for multicollinearity, we examine the VIF and Tolerance values. VIF is actually a transformation of Tolerance (Tolerance = 1/VIF). In general, we want VIF values 5 or lower, which corresponds to Tolerance values greater than (1/5) 0.2.\n\n\n\n\n\n\nFigure 6.13: VIF.\n\n\n\nIn our data, the VIF values satisfy the assumption of no multicollinearity.\n \n\nProposed remedies for multicollinearity\n• Increase the sample size: A larger sample can reduce the standard errors of the coefficient estimates, thereby improving the precision and stability of the model.\n• Model respecification: Remove some of the highly associated explanatory variables or replace them with a linear combination of them (if possible).\n• Regularization (Tolerant) techniques: Some regression techniques may be more sensitive to multicollinearity than others. Recent developments in model selection methods have introduced new methods for balancing model complexity and fit. For example two special linear regression model — Lasso and Ridge regression. Although not necessarily designed to be tolerant of collinearity, they offer approaches that may be less sensitive.\n• Principal Component Regression: This technique transforms the original correlated variables into a smaller set of uncorrelated components and uses them in the regression, effectively addressing multicollinearity.\n• Change the reference category for categorical variables: In cases where multicollinearity arises from dummy variables, selecting a different reference category can sometimes alleviate the problem.\n\n\n\n6.5.4 No outliers that influence the model (influential points)\nThere shouldn’t be any data point in the dataset that is an outlier which would strongly influence our results.\nOutliers are points that fall away from the cloud of points. Outliers that actually influence the parameters of the regression model are called influential points. Therefore, not all outliers are influential in linear regression analysis. Even though data have extreme values, they might not be influential to determine a regression model. That means, the results wouldn’t be much different if we either include or exclude them from analysis.\nCook’s distance is a measure used to identify influential data points in regression analysis. In general, Cook’s distances greater than 1 indicate an outlier that may influence the model.\n\n\n\n\n\n\nFigure 6.14: Cook’s distance.\n\n\n\nOur Cook’s distances are very small, so we do not have a problem with outliers.\n \n\n\n6.5.5 The model fit and coefficients\nFrom the Model Fit section tick the box “Adjusted \\(R^2\\)” in Fit Measures (Figure 6.16):\n\n\n\n\n\n\nFigure 6.15: Adjusted R square.\n\n\n\nAdditionally, from the Model Coefficients section tick the box “Confidence interval” in Estimate (Figure 6.16):\n\n\n\n\n\n\nFigure 6.16: Check the Confidence interval box in the Model Coefficients section.\n\n\n\nAdjusted R-squared: This metric adjusts the R-squared value to account for the number of explanatory variables (predictors) in the model.\n\n\n\n\n\n\nFigure 6.17: The model coefficients table.\n\n\n\nAbout 59% of the variation in infant’s body weight can be explained by the independent variables (such as height, head circumference, gender, etc.) in the model.\n \nThe output table with the model coefficients should look like the following (Figure 6.18):\n\n\n\n\n\n\nFigure 6.18: The model coefficients table.\n\n\n\nThe equation of our model with all variables is:\n\\[\\begin{align}\n\\widehat{Weight} &= -7082 + 131 \\cdot height + 109 \\cdot headc + 196 \\cdot gender \\\\\n&\\quad +\\ 76 \\cdot parity1 + 96 \\cdot parity2 - 35 \\cdot edu1 - 36 \\cdot edu2\n\\end{align}\\]\nAll variables in the model are statistically significant except for the comparison between infants with two or more siblings and singletons (p = 0.06), as well as the mother’s education level (year12-year10, p = 0.47; tertiary-year10 p = 0.33).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#hierarchical-regression",
    "href": "linear2.html#hierarchical-regression",
    "title": "6  Linear regression (2)",
    "section": "6.6 Hierarchical regression",
    "text": "6.6 Hierarchical regression\nFirst, we check Akaike Information Criterion (AIC) from the Model Fit (Figure 6.19).\n\n\n\n\n\n\nFigure 6.19: Akaike Information Criterion (AIC).\n\n\n\nThe AIC is a statistical measure used to evaluate the goodness of fit of a model while penalizing for the number of parameters used. It helps compare different models and choose the one that best balances model fit and complexity. A lower AIC indicates a better model.\n\n6.6.1 Model 1\nWe can specify hierarchical regression using the Model Builder drop-down menu in jamovi (Figure 6.20). Let’s select height and gender variables (predictors) as Block 1 (Model 1).\n\n\n\n\n\n\nFigure 6.20: Model builder: Block 1.\n\n\n\n\n\n\n\n\n\nFigure 6.21: Model fit table.\n\n\n\nAbout 55% of the variation in infant’s body weight can be explained by height and gender in the model 1.\n \nThe output table with the model coefficients should look like the following (Figure 6.22):\n\n\n\n\n\n\nFigure 6.22: Model 1 coefficients table.\n\n\n\nThe equation of model 1 is:\n\\[\\widehat{Weight} = -4814 + 165 \\cdot height + 251 \\cdot gender\\]\nBoth variables in the model are statistically significant (p&lt;0.001).\n\n\n6.6.2 Model 2\nNext, we select Add New Block and include the headc and parity variables in Block 2 (Model 2).\n\n\n\n\n\n\nFigure 6.23: Model builder: Block 2.\n\n\n\n\n\n\n\n\n\nFigure 6.24: Model fit table.\n\n\n\nModel 2 explains approximately 59% of the variation in infant body weight using the variables height, gender, headc, and parity, compared to 55% in Model 1 (\\(\\Delta R_{adj}^2 = 0.04\\) or 4%). Additionally, the AIC of Model 2 (8115) is lower than that of Model 1 (8169), indicating that Model 2 has a better fit.\n \nThe output table with the new model coefficients should look like the following (Figure 6.25):\n\n\n\n\n\n\nFigure 6.25: Model 2 coefficients table.\n\n\n\nThe equation of model 2 is:\n\\[\\begin{align}\n\\widehat{Weight} &= -7072 + 130 \\cdot height + 197 \\cdot gender + 110 \\cdot headc \\\\\n&\\quad +\\ 82 \\cdot parity1 + 105 \\cdot parity2\n\\end{align}\\]\nAll variables in the model are statistically significant (p&lt;0.05).\n\n\n6.6.3 Model 3\nFinally, we select Add New Block and include the education variable in Block 3 (Model 3).\n\n\n\n\n\n\nFigure 6.26: Model builder: Block 3.\n\n\n\n\n\n\n\n\n\nFigure 6.27: Model fit table.\n\n\n\nModel 3 does not explain more variation than Model 2. Additionally, the AIC of Model 3 (8118) is greater than that of Model 2 (8115), indicating that Model 3 provides a worse fit.\n \nThe output table with the new model coefficients should look like the following (Figure 6.25):\n\n\n\n\n\n\nFigure 6.28: Model 3 coefficients table.\n\n\n\nThe equation of model 3 is:\n\\[\\begin{align}\n\\widehat{Weight} &= -7082 + 131 \\cdot height + 109 \\cdot headc + 196 \\cdot gender \\\\\n&\\quad +\\ 76 \\cdot parity1 + 96 \\cdot parity2 - 35 \\cdot edu1 - 36 \\cdot edu2\n\\end{align}\\]\nNOTE: This model is the complete that we have previously explored.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "linear2.html#model-with-an-interaction-term",
    "href": "linear2.html#model-with-an-interaction-term",
    "title": "6  Linear regression (2)",
    "section": "6.7 Model with an interaction term",
    "text": "6.7 Model with an interaction term\nFinally, we remove education from Block 3 and add the interaction term between height and gender.\n\n\n\n\n\n\nFigure 6.29: Model builder: Block 3.\n\n\n\n\n\n\n\n\n\nFigure 6.30: Model fit table.\n\n\n\nThe AIC of Model 3 (8101) is lower than that of Model 2 (8115), indicating that Model 3 with the interaction term has a better fit.\n \nThe output table with the new model coefficients should look like the following (Figure 6.25):\n\n\n\n\n\n\nFigure 6.31: Model 3 coefficients table.\n\n\n\nThe interaction term is statistically significant (Estimate = 57, p &lt; 0.001), suggesting that the effect of height on body weight differs by gender. This indicates effect modification (also known as a moderation effect), where gender alters the strength of the association between height and body weight.\nThe equation of model 3 with the interaction term is:\n\\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc -2921 \\cdot gender \\\\\n&\\quad +\\ 91 \\cdot parity1 + 116 \\cdot parity2 + 57 \\cdot heigh * gender\n\\end{align}\\]\nIn this case, the main effects of height and gender are not interpreted independently, as the interaction term modifies their meanings. Specifically:\n\nFor females (reference; gender = 0):\n\n\\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc -2921 \\cdot 0 \\\\\n&\\quad +\\ 91 \\cdot parity1 + 116 \\cdot parity2 + 57 \\cdot heigh * 0\n\\end{align}\\] \\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc + 91 \\cdot parity1 + 116 \\cdot parity2\n\\end{align}\\]\nThus, the effect of height on body weight is 98 g/cm.\n\nFor males (gender = 1):\n\n\\[\\begin{align}\n\\widehat{Weight} &= -5299 + 98 \\cdot height + 108 \\cdot headc -2921 \\cdot 1 \\\\\n&\\quad +\\ 91 \\cdot parity1 + 116 \\cdot parity2 + 57 \\cdot heigh * 1\n\\end{align}\\] \\[\\begin{align}\n\\widehat{Weight} &= -8220 + (98 + 57) \\cdot height + 108 \\cdot headc + 91 \\cdot parity1 + 116 \\cdot parity2 \\\\\n\\end{align}\\]\nThus, the effect of height is 98 + 57 = 155 g/cm.\nThis implies that height has a stronger influence on weight for males than for females.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Linear regression (2)</span>"
    ]
  },
  {
    "objectID": "pca.html",
    "href": "pca.html",
    "title": "7  Principal Components Analysis",
    "section": "",
    "text": "7.1 Introduction\nPrincipal Component Analysis (PCA) is a statistical technique used to reduce the dimensionality of a dataset while preserving as much of its original variability as possible. It transforms a large set of correlated variables into a smaller set of representative variables, called principal components, which collectively explain most of the variability in the original data.\nSuppose that we have \\(n\\) observations with measurements on a set of \\(p\\) observed variables (features), \\(X_1,X_2, . . . ,X_p\\). This means that each of the \\(n\\) observations lives in p-dimensional space, but not all of these dimensions are equally interesting.\nPCA seeks a small number of dimensions that are as interesting as possible, where the concept of interesting is measured by the amount that the observations vary along each dimension. Each of the dimensions found by PCA is a linear combination of the \\(p\\) observed variables. We now explain the manner in which these dimensions, or principal components, are found.\nThe first principal component of a set of observed variables \\(X_1, X_2, . . . ,X_p\\) is the normalized linear combination of the observed variables:\n\\[PC1: Z_1 = \\phi_{11} X_1 + \\phi_{21} X_2  + ...+ \\phi_{p1} X_p \\] that has the largest variance. By normalized, we mean that \\(\\sum_{j=1}^p \\phi_{j1}^2 = 1\\). We refer to the elements \\(\\phi_{11}, \\phi_{21},..., \\phi_{p1}\\) as the loadings of the first principal component.\nTo obtain the loadings of the first principal component (PC1), we solve an optimization problem that maximizes the variance of the data projected onto a linear combination of the original variables. This can be solved via an eigen decomposition, a standard technique in linear algebra (algebra of matrices).\nAfter the first principal component \\(Z_1\\) of the observed variables has been determined, we can find the second principal component \\(Z_2\\).\n\\[PC2: Z_2 = \\phi_{12} X_1 + \\phi_{22} X_2  + ...+ \\phi_{p2} X_p \\]\nThe second principal component (PC2) explaines the next highest amount of variance. The elements \\(\\phi_{12}, \\phi_{22},..., \\phi_{p2}\\) are referred to as the loadings of the second principal component.\nThe same procedure can be applied to obtain the third principal component (PC3), the fourth component (PC4) and so on for subsequent components.\nEXAMPLE DATA\nOur data analysis is based on the paper published by Lewis and Neville on the Gendered Racial Microaggressions Scale for Black Women. The article presents two separate studies that contributed to the development, refinement, and psychometric evaluation of two parallel versions of the scale: one measuring stress appraisal and the other measuring frequency. For the purposes of our analysis, we focus on the final construction of the stress appraisal version. Items were rated on a 6-point Likert scale ranging from 0 (not at all stressful) to 5 (extremely stressful).\nFigure 7.1: Table with raw data.\nLewis and Neville provided support for both a total scale score, consisting of 25 items, and four subscales. Below, we outline the four subscales, including the number of items in each, their abbreviations, and a sample item representing each subscale:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#introduction",
    "href": "pca.html#introduction",
    "title": "7  Principal Components Analysis",
    "section": "",
    "text": "Assumptions of Beauty and Sexual Objectification (10 items)\n\nUnattractive because of size of butt (Obj1)\nNegative comments about size of facial features (Obj2)\nImitated the way they think Black women speak (Obj3)\nSomeone made me feel unattractive (Obj4)\nNegative comment about skin tone (Obj5)\nSomeone assumed I speak a certain way (Obj6)\nObjectified me based on physical features(Obj7)\nSomeone assumed I have a certain body type (Obj8)\nMade a sexually inappropriate comment (Obj9)\nNegative comments about my hair when natural (Obj10)\n\nSilenced and Marginalized (7 items)\n\nI have felt unheard (Marg1)\nMy comments have been ignored (Marg2)\nSomeone challenged my authority (Marg3)\nI have been disrespected in workplace (Marg4)\nSomeone has tried to “put me in my place” (Marg5)\nFelt excluded from networking opportunities (Marg6)\nAssumed I did not have much to contribute to the conversation (Marg7)\n\nStrong Black Woman Stereotype (5 items)\n\nSomeone assumed I was sassy and straightforward (Str1)\nI have been told that I am too independent (Str2)\nSomeone made me feel exotic as a Black woman (Str3)\nI have been told that I am too assertive (Str4)\nAssumed to be a strong Black woman (Str5)\n\nAngry Black Woman Stereotype (3 items)\n\nSomeone has told me to calm down (Ang1)\nPerceived to be “angry Black woman” (Ang2)\nSomeone accused me of being angry when speaking calm (Ang3)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#the-technical-part-of-pca",
    "href": "pca.html#the-technical-part-of-pca",
    "title": "7  Principal Components Analysis",
    "section": "7.2 The technical part of PCA",
    "text": "7.2 The technical part of PCA\n\n\n\n\n\n\nFigure 7.2: The method of PCA for dimensionality reduction.\n\n\n\nFigure 7.2 illustrates the technical workflow of principal component analysis (PCA), as a method to reduce the number of dimensions of the data. It starts with a large table of data (\\(X_{n \\times p}\\)), standardizes it (\\(X^c_{n \\times p}\\)), and calculates the covariance matrix (\\(C_{p \\times p}\\)) between observed variables (features). Then, it finds the principal directions (eigenvectors) and their importance (eigenvalues). By selecting the most important directions (top k), the original data is projected onto a lower-dimensional space applying the projection matrix \\(W_{p \\times k}\\), resulting in a smaller table that still captures most of the data’s variability. The scatter plots visually show this reduction from a higher to a lower dimension.\n\nR-matrix\n\nFirst, we calculate the R-matrix, which is a correlation matrix—a table of correlation coefficients between variables.\n\n\n      Obj1 Obj2 Obj3 Obj4 Obj5 Obj6 Obj7  Obj8 Obj9 Obj10 Marg1 Marg2 Marg3\nObj1  1.00 0.35 0.25 0.27 0.28 0.25 0.28  0.35 0.15  0.24  0.19  0.25  0.17\nObj2  0.35 1.00 0.31 0.25 0.27 0.23 0.31  0.28 0.26  0.24  0.22  0.21  0.25\nObj3  0.25 0.31 1.00 0.24 0.28 0.28 0.20  0.25 0.21  0.22  0.17  0.23  0.17\nObj4  0.27 0.25 0.24 1.00 0.39 0.23 0.28  0.30 0.26  0.28  0.22  0.18  0.14\nObj5  0.28 0.27 0.28 0.39 1.00 0.15 0.18  0.29 0.25  0.20  0.17  0.20  0.23\nObj6  0.25 0.23 0.28 0.23 0.15 1.00 0.20  0.14 0.21  0.12  0.10  0.14  0.05\nObj7  0.28 0.31 0.20 0.28 0.18 0.20 1.00  0.31 0.19  0.28  0.30  0.21  0.20\nObj8  0.35 0.28 0.25 0.30 0.29 0.14 0.31  1.00 0.19  0.23  0.27  0.14  0.14\nObj9  0.15 0.26 0.21 0.26 0.25 0.21 0.19  0.19 1.00  0.20  0.10  0.12  0.21\nObj10 0.24 0.24 0.22 0.28 0.20 0.12 0.28  0.23 0.20  1.00  0.09  0.12  0.17\nMarg1 0.19 0.22 0.17 0.22 0.17 0.10 0.30  0.27 0.10  0.09  1.00  0.43  0.41\nMarg2 0.25 0.21 0.23 0.18 0.20 0.14 0.21  0.14 0.12  0.12  0.43  1.00  0.35\nMarg3 0.17 0.25 0.17 0.14 0.23 0.05 0.20  0.14 0.21  0.17  0.41  0.35  1.00\nMarg4 0.19 0.18 0.24 0.26 0.20 0.10 0.25  0.24 0.07  0.12  0.38  0.23  0.32\nMarg5 0.17 0.22 0.21 0.27 0.25 0.16 0.23  0.19 0.19  0.11  0.41  0.40  0.25\nMarg6 0.18 0.27 0.16 0.23 0.22 0.26 0.28  0.26 0.15  0.26  0.35  0.27  0.25\nMarg7 0.13 0.19 0.14 0.19 0.06 0.17 0.16  0.14 0.10  0.11  0.31  0.33  0.20\nStr1  0.22 0.18 0.14 0.06 0.23 0.07 0.25  0.17 0.19  0.10  0.19  0.25  0.20\nStr2  0.19 0.18 0.19 0.19 0.12 0.15 0.13  0.06 0.18  0.19  0.12  0.18  0.17\nStr3  0.10 0.09 0.09 0.08 0.11 0.09 0.19  0.05 0.12  0.10  0.13  0.18  0.10\nStr4  0.09 0.14 0.18 0.15 0.12 0.08 0.07  0.13 0.05  0.02  0.08  0.12  0.08\nStr5  0.20 0.15 0.15 0.08 0.19 0.11 0.15  0.04 0.07  0.09  0.10  0.23  0.12\nAng1  0.06 0.07 0.07 0.09 0.12 0.04 0.15  0.07 0.17  0.06  0.16  0.23  0.18\nAng2  0.06 0.15 0.08 0.06 0.09 0.20 0.13 -0.03 0.00  0.14  0.17  0.19  0.19\nAng3  0.21 0.13 0.11 0.14 0.11 0.16 0.23  0.07 0.06  0.08  0.28  0.28  0.11\n      Marg4 Marg5 Marg6 Marg7 Str1 Str2 Str3 Str4 Str5 Ang1  Ang2 Ang3\nObj1   0.19  0.17  0.18  0.13 0.22 0.19 0.10 0.09 0.20 0.06  0.06 0.21\nObj2   0.18  0.22  0.27  0.19 0.18 0.18 0.09 0.14 0.15 0.07  0.15 0.13\nObj3   0.24  0.21  0.16  0.14 0.14 0.19 0.09 0.18 0.15 0.07  0.08 0.11\nObj4   0.26  0.27  0.23  0.19 0.06 0.19 0.08 0.15 0.08 0.09  0.06 0.14\nObj5   0.20  0.25  0.22  0.06 0.23 0.12 0.11 0.12 0.19 0.12  0.09 0.11\nObj6   0.10  0.16  0.26  0.17 0.07 0.15 0.09 0.08 0.11 0.04  0.20 0.16\nObj7   0.25  0.23  0.28  0.16 0.25 0.13 0.19 0.07 0.15 0.15  0.13 0.23\nObj8   0.24  0.19  0.26  0.14 0.17 0.06 0.05 0.13 0.04 0.07 -0.03 0.07\nObj9   0.07  0.19  0.15  0.10 0.19 0.18 0.12 0.05 0.07 0.17  0.00 0.06\nObj10  0.12  0.11  0.26  0.11 0.10 0.19 0.10 0.02 0.09 0.06  0.14 0.08\nMarg1  0.38  0.41  0.35  0.31 0.19 0.12 0.13 0.08 0.10 0.16  0.17 0.28\nMarg2  0.23  0.40  0.27  0.33 0.25 0.18 0.18 0.12 0.23 0.23  0.19 0.28\nMarg3  0.32  0.25  0.25  0.20 0.20 0.17 0.10 0.08 0.12 0.18  0.19 0.11\nMarg4  1.00  0.30  0.26  0.16 0.10 0.21 0.05 0.06 0.03 0.12  0.22 0.17\nMarg5  0.30  1.00  0.29  0.28 0.16 0.13 0.16 0.14 0.18 0.12  0.14 0.21\nMarg6  0.26  0.29  1.00  0.20 0.13 0.18 0.15 0.13 0.08 0.11  0.21 0.12\nMarg7  0.16  0.28  0.20  1.00 0.14 0.05 0.04 0.02 0.12 0.17  0.13 0.09\nStr1   0.10  0.16  0.13  0.14 1.00 0.21 0.30 0.23 0.23 0.18  0.05 0.10\nStr2   0.21  0.13  0.18  0.05 0.21 1.00 0.20 0.20 0.12 0.16  0.12 0.16\nStr3   0.05  0.16  0.15  0.04 0.30 0.20 1.00 0.27 0.18 0.20  0.07 0.15\nStr4   0.06  0.14  0.13  0.02 0.23 0.20 0.27 1.00 0.12 0.15  0.03 0.02\nStr5   0.03  0.18  0.08  0.12 0.23 0.12 0.18 0.12 1.00 0.22  0.15 0.11\nAng1   0.12  0.12  0.11  0.17 0.18 0.16 0.20 0.15 0.22 1.00  0.24 0.23\nAng2   0.22  0.14  0.21  0.13 0.05 0.12 0.07 0.03 0.15 0.24  1.00 0.25\nAng3   0.17  0.21  0.12  0.09 0.10 0.16 0.15 0.02 0.11 0.23  0.25 1.00\n\n\nOur objective is to turn the R-matrix (correlation matrix) into an output which represents the degree to which each observed variable contributes to a component.\nPrincipal components are derived through an eigen-decomposition of the correlation matrix. This process involves re-expressing the matrix in terms of its eigenvectors and eigenvalues. The eigenvectors define the directions (or axes) of the new feature space, while the corresponding eigenvalues indicate the amount of variance explained by each component.\n\n7.2.1 PC1\n\nEigenvector and eigenvalue for PC1\n\nThe first eigenvector (\\(\\alpha_{11}, \\alpha_{21}, ..., \\alpha_{p1}\\)):\n\n\n [1] 0.225 0.239 0.214 0.226 0.220 0.173 0.240 0.207 0.175 0.179 0.251 0.250\n[13] 0.220 0.214 0.242 0.234 0.176 0.185 0.173 0.141 0.123 0.146 0.149 0.140\n[25] 0.166\n\n\nThe corresponding eigenvalue, \\(\\lambda_{1}\\) is:\n\n\n[1] 5.365\n\n\n\nLoadings of PC1\n\nNow, we are ready to calculate the loadings \\(\\phi_{11}, \\phi_{21},..., \\phi_{p1}\\) of the first principal component according to the formula:\n\\[\\phi_{i1} = \\alpha_{i1} \\sqrt{\\lambda_{1}}\\]\nwhere \\(i= 1,...p\\).\n\n\n [1] 0.52 0.55 0.49 0.52 0.51 0.40 0.56 0.48 0.40 0.42 0.58 0.58 0.51 0.50 0.56\n[16] 0.54 0.41 0.43 0.40 0.33 0.29 0.34 0.35 0.33 0.38\n\n\n\n\n7.2.2 PC2\n\nEigenvector and eigenvalue for PC2\n\nThe second eigenvector (\\(\\alpha_{12}, \\alpha_{22}, ..., \\alpha_{p2}\\)):\n\n\n [1] -0.224 -0.212 -0.201 -0.265 -0.221 -0.156 -0.082 -0.308 -0.212 -0.245\n[11]  0.240  0.287  0.173  0.079  0.143 -0.005  0.159  0.093  0.025  0.168\n[21]  0.022  0.151  0.309  0.284  0.237\n\n\nThe corresponding eigenvalue, \\(\\lambda_{2}\\) is:\n\n\n[1] 1.706\n\n\n\nLoadings of PC2\n\nNow, we are ready to calculate the loadings \\(\\phi_{12}, \\phi_{22},..., \\phi_{p2}\\) of the second principal component according to the formula:\n\\[\\phi_{i2} = \\alpha_{i2} \\sqrt{\\lambda_{2}}\\]\nwhere \\(i= 1,...p\\).\n\n\n [1] -0.29 -0.28 -0.26 -0.35 -0.29 -0.20 -0.11 -0.40 -0.28 -0.32  0.31  0.38\n[13]  0.23  0.10  0.19 -0.01  0.21  0.12  0.03  0.22  0.03  0.20  0.40  0.37\n[25]  0.31\n\n\nThe same procedure can be applied to calculate the loadings of the third principal component (PC3), the fourth component (PC4) and so on for subsequent components. Therefore, the loadings are scaled versions of eigenvectors that reflect both direction and strength of association.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#eigenvalues-and-variance",
    "href": "pca.html#eigenvalues-and-variance",
    "title": "7  Principal Components Analysis",
    "section": "7.3 Eigenvalues and variance",
    "text": "7.3 Eigenvalues and variance\nA fundamental aspect of principal component analysis (PCA) is understanding how eigenvalues relate to the variance in the dataset.\nEach of the 25 eigenvectors has an associated eigenvalue, \\(\\lambda_1, \\lambda_2, ... \\lambda_p\\), as shown below:\n\n\n [1] 5.3654707 1.7059541 1.5384132 1.2206643 1.0777632 1.0395105 1.0223027\n [8] 0.9764029 0.9456935 0.9039208 0.8420446 0.8298040 0.7462031 0.7344016\n[15] 0.6934445 0.6803484 0.6360415 0.6105103 0.5829854 0.5460390 0.5059900\n[22] 0.4808372 0.4546453 0.4498703 0.4107389\n\n\nThe sum of the eigenvalues will equal the number of variables in the data set:\n\\[\\lambda_1 + \\lambda_2 + \\lambda_3 + ...+ \\lambda_p = 5.37 + 1.71 + 1.54 +...+ 0.41 = 25\\]\nTo determine the proportion of variance explained by the first principal component (i.e., direction by that component), we use the following formula:\n\\[\\frac{\\lambda_1}{\\lambda_1 + \\lambda_2 + \\lambda_3 + ...+ \\lambda_p} = \\frac{5.37}{25} = 0.215 \\ or \\ 21.5\\%\\]\nSimilarly, the explained variance by the second principal component is:\n\\[\\frac{\\lambda_2}{\\lambda_1 + \\lambda_2 + \\lambda_3 + ...+ \\lambda_p} = \\frac{1.71}{25} = 0.068 \\ or \\ 6.8\\%\\]\nNote that the first component captures the maximum variance, the second captures the next highest variance orthogonal to the first, and so on.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#steps-in-the-process-of-pca",
    "href": "pca.html#steps-in-the-process-of-pca",
    "title": "7  Principal Components Analysis",
    "section": "7.4 Steps in the process of PCA",
    "text": "7.4 Steps in the process of PCA\n\nPrepare the Data: Create a dataframe where any items are scaled in the same direction (e.g., negatively worded items are reverse scored).\nEvaluate Assumptions: Assess the suitability of the data for PCA using diagnostic tests such as the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and Bartlett’s test of sphericity. These tests determine whether the correlation matrix is appropriate for component extraction.\nDetermine the Number of Components: Identify how many components to extract, guided by criteria such as eigenvalues greater than one, scree plot inspection, or parallel analysis. These components often correspond to underlying subscales.\nExtract and Rotate Components: Perform the extraction of components through an iterative process. Explore both orthogonal (uncorrelated) and oblique (correlated) rotation methods to enhance interpretability. Adjust the number of components and rotation type as needed to arrive at a theoretically meaningful and statistically sound solution.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#example-of-grms-stress-appraisal",
    "href": "pca.html#example-of-grms-stress-appraisal",
    "title": "7  Principal Components Analysis",
    "section": "7.5 Example of GRMS Stress Appraisal",
    "text": "7.5 Example of GRMS Stress Appraisal\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Factor) -.-&gt; C(Principal Component Analysis)\n\n\n\n\n\n\nas shown below (Figure 7.3).\n\n\n\n\n\n\nFigure 7.3: Select from Factor the Principal Component Analysis.\n\n\n\nThe Principal Component Analysis box opens (Figure 7.3). From the left-hand pane drag all the variables into the Variables field on the right-hand side, as shown below (Figure 7.4):\n\n\n\n\n\n\nFigure 7.4: Principal Component Analysis box options. Drag and drop the variables in the fields on the right-hand side.\n\n\n\nAll variables in the dataset are on the same scale (Likert scale).\n\n7.5.1 Assumptions\nFrom the Assumption Checks, tick both boxes: Bartlett’s test of sphericity and KMO measure of Sampling Adequacy.\n\n\n\n\n\n\nFigure 7.5: Assumptions for PCA.\n\n\n\n\nBartlett’s test of sphericity\n\nBartlett’s test examines the null hypothesis that the correlation matrix is an identity matrix—meaning all the variables are uncorrelated (i.e., the off-diagonal elements are zero). A significant result (p &lt; 0.05) indicates that the correlation matrix significantly differs from an identity matrix, suggesting that the variables share enough correlation to justify the use of principal component analysis (PCA).\n\n\n\n\n\n\nFigure 7.6: Bartlett’s test.\n\n\n\nOur Bartlett’s test is significant: \\(\\chi^2 = 1217\\) (p&lt;0.001). This means that our sample correlation matrix is statistically significantly different than an identity matrix and, therefore, supports a component analytic approach for investigating the data.\n\nKaiser-Meyer-Olkin (MKO) index of Sampling Adequacy\n\nThe Kaiser-Meyer-Olkin index (KMO) is an index of sampling adequacy that varies between 0 and 1. Kaiser’s 1974 recommendations were:\n\nbare minimum of 0.5\nvalues between 0.5 and 0.7 as mediocre\nvalues between 0.7 and 0.8 as good\nvalues between 0.8 and 0.9 as great\nvalues above 0.9 are superb\n\nIf the KMO is below the recommendations, we should probably collect more data to see if it can achieve a satisfactory value.\n\n\n\n\n\n\nFigure 7.7: Kaiser-Meyer-Olkin measure.\n\n\n\nThe Kaiser–Meyer–Olkin (KMO) measure verified the sampling adequacy for the analysis KMO = 0.85, which is considered “great”. Additionally, all individual KMO values were above 0.74—well above the acceptable threshold of 0.50.\n\n\n7.5.2 Specify the Number of Components\nOur decisions on how many components to keep can be guided by several methods:\n\nCumulative variance explained – Retain enough components to account for a desired proportion of total variance.\nParallel analysis – Compare the observed eigenvalues with those obtained from randomly generated data to determine which components are meaningful.\nKaiser’s criterion – Retain components with eigenvalues greater than 1.\nTheoretical justification – Retain components that align with prior knowledge, conceptual frameworks, or hypotheses relevant to the domain of study (fixed number).\n\nJamovi allows users to choose the number of components based on parallel analysis, eigenvalues, or by manually specifying a fixed number.\n\n\n\n\n\n\nFigure 7.8: Choose a method to define the number of components.\n\n\n\nAdditionally, a scree plot displays the eigenvalues associated with each principal component in descending order. It is used to visually identify the “elbow point”—the point at which the rate of decline in eigenvalues noticeably levels off. This point suggests the optimal number of components to retain, as additional components contribute relatively little to explaining variance.\n\n\n\n\n\n\nFigure 7.9: Scree plot.\n\n\n\n\n\n\n\n\n\nFigure 7.10: Scree plot determining the number of components based on parallel analysis.\n\n\n\n\n\n\n\n\n\nFigure 7.11: Scree plot determining the number of components based on Kaiser’s criterion.\n\n\n\nIn our example, parallel analysis suggests retaining 3 components (Figure 7.10), while Kaiser’s criterion indicates 7 components (Figure 7.11).\nIf we select three principal components based on parallel analysis, we observe that the uniqueness of some variables is relatively high (e.g., Obj6 Uniqueness = 0.8). Uniqueness refers to the proportion of a variable’s variance that is not explained by the retained components. Therefore, if a variable has high uniqueness (close to 1), it indicates that the variable is poorly explained by the selected number of components.\n\n\n\n\n\n\nFigure 7.12: The uniqueness of some variables is relatively high when selecting three principal components.\n\n\n\nIf our scale construction includes a priori or planned subscales, we expect the observed variables to reflect the following conceptual dimensions:\n\nAssumptions of Beauty and Sexual Objectification\nSilenced and Marginalized\nStrong Woman Stereotype\nAngry Woman Stereotype\n\nTherefore, guided by prior knowledge and theoretical considerations, we have decided to retain the first four components for further analysis.\n\n\n\n\n\n\nFigure 7.13: Select four principal components.\n\n\n\n\n\n7.5.3 Component Rotation\nRotation in PCA redistributes the variance between components, making the loadings more distinct and interpretable. In other words, rotation typically causes each observed variable to load highly on precisely one component.\nThere are two main types of rotation, and the choice between them depends on theoretical considerations:\n\nOrthogonal Rotation: Use this if you believe the components are independent or unrelated.\n\nVarimax is the most common orthogonal rotation method.\n\nOblique Rotation: Use this if you believe the components are correlated or related.\n\nOblimin and Promax are common oblique rotation methods.\n\n\nWhich method should we choose?\n\nOrthogonal rotation is often considered “easier” because it minimizes cross-loadings (i.e., it reduces the correlation between components). However, this assumes that the components are truly independent, which may not always be the case.\nCan you think of a measure where the subscales would not be correlated? In many real-world cases, components are likely to be correlated, which might suggest that oblique rotation is the better choice.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#varimax-rotation",
    "href": "pca.html#varimax-rotation",
    "title": "7  Principal Components Analysis",
    "section": "7.6 Varimax rotation",
    "text": "7.6 Varimax rotation\nSelect the Varimax rotation method:\n\n\n\n\n\n\nFigure 7.14: Select the Varimax method of rotation.\n\n\n\nAfter rotation, there are four clear components/scales (NOTE: In the unrotated method, most variables loaded on the first component).\n\n\n\n\n\n\nFigure 7.15: Loadings with orthogonal rotation.\n\n\n\nThere is clear (or at least reasonable) component/scale membership for each variable. This table lists all component loadings that are greater than 0.30. When an observed variable has multiple component loadings listed, we inspect it for “cross-loading.” We observe cross-loadings with the following observed variables: Obj6, Marg6, and Ang1.\nIt is important to note that in PCA with orthogonal rotation (such as Varimax), the factor loadings can be interpreted as correlation coefficients between the original observed variables and the rotated components.\n \nMoreover, under the Additional Output section, select Component summary:\n\n\n\n\n\n\nFigure 7.16: Select component summary.\n\n\n\nFigure 7.17 presents the percentage of variance in the variable set that is captured by the derived components after Varimax rotation.\n\n\n\n\n\n\nFigure 7.17: Variance with orthogonal rotation.\n\n\n\nThe SS Loadings column represents the eigenvalues for each component after Varimax rotation, with Principal Component 1 explaining 13.2%, Principal Component 2 explaining an additional 11.7%, Principal Component 3 explaining an additional 8.2%, and Principal Component 4 explaining an additional 6.2%, resulting a cumulative variance of 39.3%.\nThe path diagram follows:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#oblique-rotation",
    "href": "pca.html#oblique-rotation",
    "title": "7  Principal Components Analysis",
    "section": "7.7 Oblique rotation",
    "text": "7.7 Oblique rotation\n\n\n\n\n\n\nFigure 7.18: Select the Oblimin method of rotation.\n\n\n\nFigure 7.19 shows the loadings of the principal components after rotation.\n\n\n\n\n\n\nFigure 7.19: Loadings with oblique rotation.\n\n\n\nFigure 7.20 presents the percentage of variance in the variable set that is captured by the derived components after Oblimin rotation.\n\n\n\n\n\n\nFigure 7.20: Variance with oblique rotation.\n\n\n\nThe SS Loadings column represents the eigenvalues for each component after Oblimin rotation, with Principal Component 1 explaining 13.3%, Principal Component 2 explaining an additional 11.6%, Principal Component 3 explaining an additional 8.2%, and Principal Component 4 explaining an additional 6.2%, resulting a cumulative variance of 39.3%.\n \nMoreover, under the Additional Output section, select Component correlations:\n\n\n\n\n\n\nFigure 7.21: Select Component correlations.\n\n\n\nThe Inter-Component Correlation Matrix reveals that the four components are positively correlated with each other, with correlations ranging from 0.09 to 0.35 (Figure 7.22).\n\n\n\n\n\n\nFigure 7.22: Inter-Component Correlation Matrix.\n\n\n\nThe path diagram follows:\n\n\n\n\n\n\n\n\n\nNote that this path diagram includes links with numerical values between components, representing the correlation coefficients among them. In contrast, orthogonal rotation assumes the components are uncorrelated, so such links do not appear.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "pca.html#component-scores",
    "href": "pca.html#component-scores",
    "title": "7  Principal Components Analysis",
    "section": "7.8 Component scores",
    "text": "7.8 Component scores\nComponent scores represent each observation’s position on the extracted components. They are calculated as weighted combinations of the original variables, using the component loadings derived from PCA. After rotation, these scores reflect the rotated solution, providing insight into how each case (e.g., participant) scores on the newly defined components.\nTo compute the component scores, click on the Save dropdown menu and select the Component scores option (Figure 7.23).\n\n\n\n\n\n\nFigure 7.23: From the Save dropdown menu select the Component scores.\n\n\n\nNew variables have been created, each containing the component scores for the extracted components (Figure 7.24).\n\n\n\n\n\n\nFigure 7.24: Component scores after Oblimin rotation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Principal Components Analysis</span>"
    ]
  },
  {
    "objectID": "ma1.html",
    "href": "ma1.html",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "",
    "text": "8.1 Meeting the review family\nAs more primary studies are conducted in research, the body of relevant research literature continues to grow. This expansion is a welcome development for psychologists working across various fields—such as clinical, educational, school, industrial-organizational, health, and sports psychology—who aim to ground their practice in evidence-based findings. However, the growing volume of research also presents new challenges in gathering, analyzing, and synthesizing the vast amount of available information.\nTo manage this complexity, researchers are increasingly turning to research reviews, which help organize, evaluate, and interpret existing studies. These reviews make the growing body of knowledge more accessible and applicable to both practice and future research. Forty-eight review types have been identiﬁed and categorized into seven families (Sutton et al. 2019):\nBut there are much more:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#meeting-the-review-family",
    "href": "ma1.html#meeting-the-review-family",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "",
    "text": "Traditional literature review\nSystematic review\nRapid review\nQualitative review\nMixed-methods review\nPurpose-specific review (Health Technology Assessment-HTA)\nReview of reviews\n\n\n\nScoping review\nLiving review\nEconomic evaluation review\nMeasurement properties review",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#evidence-based-pyramid-in-research",
    "href": "ma1.html#evidence-based-pyramid-in-research",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.2 Evidence based pyramid in research",
    "text": "8.2 Evidence based pyramid in research\nThe levels of evidence, or hierarchy of evidence, provide a framework for ranking medical studies according to the quality and reliability of their design. This hierarchy is often represented as a pyramid, which reflects both the quality and quantity of evidence available. In this model, higher levels represent more rigor and reliable evidence. Each level builds upon the data and research found in the tiers below (Figure 8.1).\nEvidence based pyramids are typically divided into two or three sections. The top section includes secondary evidence such as systematic reviews, meta-analyses, and critical appraisals. The middle section contains primary evidence, including randomized controlled trials (RCTs), cohort studies, case-control studies, case series, and case reports. Some models also include a bottom tier that represents background information and expert opinion (Source: openmd).\n\n\n\n\n\n\nFigure 8.1: Evidence based pyramid (Based on Source: https://openmd.com/guide/levels-of-evidence).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#systematic-review",
    "href": "ma1.html#systematic-review",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.3 Systematic review",
    "text": "8.3 Systematic review\nAmong all types of reviews (Figure 8.2), the systematic review is considered one of the most rigorous and trusted forms of research synthesis. Therefore, conducting reliable, well-organized systematic reviews is essential for effectively synthesizing the findings of primary studies .\n\n\n\n\n\n\nFigure 8.2: Evidence pyramid.\n\n\n\n\nDefinition of systematic review\nSystematic review (SR) is a review of clearly formulated question that uses explicit, pre-planned scientific methods to identify, select, appraise, and synthesize results from similar but separate primary studies. (NOTE: Meta-analysis (MA), the statistical analysis of a large collection of results from individual studies is an optional component of a systematic review).\n\nFor example, let’s consider the Cochrane systematic review titled “Psychological therapies for anxiety and depression in children and adolescents with long-term physical conditions” (Thabrew et al. 2018).\nNext, we outline the fundamental steps involved in conducting a systematic review.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#establish-a-team-and-develop-a-focused-research-question",
    "href": "ma1.html#establish-a-team-and-develop-a-focused-research-question",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.4 Establish a team and develop a focused research question",
    "text": "8.4 Establish a team and develop a focused research question\nThe first step in conducting a systematic review is typically initiated by independent researchers, universities, institutes, or organizations such as the Cochrane Collaboration, the Joanna Briggs Institute (JBI), and the Centre for Reviews and Dissemination at the University of York. Policy-focused groups, including professional societies, government agencies, and healthcare payers, may also initiate such reviews. These entities undertake systematic reviews to address well-defined research questions or explore specific hypotheses, aiming to generate high-quality evidence that can guide practice, inform policy, and shape future research directions.\nInitially, a preliminary search of the existing literature is conducted to identify knowledge gaps within the field. The existence of previous systematic reviews on similar topics does not preclude the need for a new review—provided the new review addresses unresolved issues, incorporates updated evidence, or offers a novel analytical perspective that adds meaningful value.\nEstablish a research team\nThe research core team must clearly specify and agree on the reasons for the study as these are the driving force for any systematic reviews. All the team members must be fully aware and convinced of the reasons behind the proposed review and why the study is important.\nConduct of a systematic review is a complex procedure involving collaboration of content experts, librarians, methodologists, and statisticians. A well-organized and coordinated team is essential for conducting a successful systematic review. Many steps—such as the literature search, screening process, and quality assessment—require independent verification by multiple reviewers.\nCareful selection of colleagues and experts for the team is essential, evaluating both their expertise in the field and their professional integrity. The complexity of the research question and the anticipated number of primary studies will also influence the size of the team.\nFinally, no team can function effectively without a leader. The team leader is responsible for coordinating the project, ensuring adherence to the study protocol, keeping all members informed, and facilitating active participation throughout all phases of the review.\nDevelop a focused research question\nThe formulation of research question determines all the subsequent steps of the review: what studies should be included, where and how to search for studies, how to critically appraise those studies, and so on. The review question is usually based on the “PICO” mnemonic, which stands for:\n\nPopulation\nIntervention\nComparison(s)\nOutcome(s)\n\n\nExample\nPopulation: Children and adolescents aged up to 18 years with depression or anxiety or both with “long-term conditions”\nIintervention: Individual or group-based psychological or psychologically-oriented therapy excluding e-health therapies.\nComparator: Controls (treatment-as-usual, waiting list, attention placebo, psychological placebo, or non-psychological treatment).\nOutcome: Changes in severity of anxiety and depression symptoms measured separately using validated scales.\n\nIt is important to note that a systematic review with a broad scope provides a comprehensive summary of the available evidence base, nevertheless it is resource-intensive and usually comes with substantial heterogeneity that hinders interpretation of the findings. In contrast, a systematic review with a narrow focus is more manageable, but the available evidence may be limited, and the generalizability of the findings may be reduced.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#develop-your-research-plan-and-pre-register-the-project",
    "href": "ma1.html#develop-your-research-plan-and-pre-register-the-project",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.5 Develop your research plan and (pre) register the project",
    "text": "8.5 Develop your research plan and (pre) register the project\nA pre-study plan (or protocol) outlines objectives, methods, and criteria for a systematic review. In other words, it provides a structured framework to guide the review process through its various stages.\nTo increase the openness and transparency of a systematic review and streamlines the review process, researchers can preregister or register their projects using a registry. Preregistration and registration differ primarily in terms of timing. Preregistration occurs when researchers document essential information about a research project before they begin collecting data or analyzing primary sources. In contrast, registration refers to documenting the research project after the research process has already begun.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#specify-the-inclusion-and-exclusion-criteria",
    "href": "ma1.html#specify-the-inclusion-and-exclusion-criteria",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.6 Specify the inclusion and exclusion criteria",
    "text": "8.6 Specify the inclusion and exclusion criteria\nThe PICO framework is commonly used to specify the inclusion and exclusion criteria (eligibility criteria) for reviews of interventions. A critical step in setting these criteria is the evaluation of the type(s) of study design that may best answer the research question. Another important step is the clear definition of the outcomes. Specifically, an outcome can include five elements(Figure 8.3) (Saldanha et al. 2014):\n\nThe domain or outcome title (e.g., anxiety).\nThe specific measurement or technique/instrument used to make the measurement (e.g., Hamilton Anxiety Rating Scale).\nThe specific metric or format of the outcome data from each participant that will be used for analysis (e.g., value at a time-point, change from baseline).\nThe method of aggregation or how data from each group will be summarized (e.g., mean, median, proportion).\nThe time-points that will be used for analysis (e.g., 3 months, 6 months) .\n\n\n\n\n\n\n\nFigure 8.3: Each outcome has five elements.\n\n\n\n\nExample of eligibility criteria in PICO format\n\nTypes of studies: We included all randomised controlled trials (RCTs) and cluster randomised trials. Cross-over trials were also included, though we only used data from the first phase in order to avoid carryover effects.\nTypes of participants: We included trials performed on children and adolescents aged up to 18 years (or at least 80% of the sample within this age range). We included studies performed on participants with any single or mixed long-term physical condition(s) of more than three months duration, who also had depression/subthreshold depression or anxiety, or both. We included studies conducted in hospital and community settings.\nTypes of interventions: Experimental interventions included any individual or group-based psychological or psychologically-oriented therapy excluding e-health therapies designed with the primary aim of treating clinical or subthreshold levels of anxiety or depression and tested in children and adolescents with long-term conditions (behaviour therapies such as relaxation training; cognitive behaviour therapies such as CBT; psychodynamic therapies such as psychoanalytic therapy; humanistic therapies such as person-centred psychotherapy; integrative therapies; and systemic therapies such as structural family therapy). Comparator interventions included any of the following: Attention placebo (AP); psychological placebo (PP); non-psychological therapies; Treatment-as-usual (TAU).\nTypes of outcome measures: Primary outcomes including treatment efficacy (hanges in severity of anxiety and depression symptoms measured), and treatment acceptability (measured via validated scales). Secondary outcomes including changes in caseness (remission/response), suicide-related behavior, i.e. number of: a) deaths by suicide, b) suicide attempts and c) episodes of self harm.\n\n\nNOTE: Researchers should consider the risk of inclusion bias. For example, review investigators may be aware of the results from various clinical trials when setting inclusion criteria, and may unintentionally include only those trials that support the hypothesis of the systematic review.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#search-information-sources",
    "href": "ma1.html#search-information-sources",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.7 Search information sources",
    "text": "8.7 Search information sources\nIt is recommended to search at least two major bibliographic databases, along with other sources of published and unpublished studies—including backward and forward citation tracking, reviews, consultation with field experts, and grey and non-English literature. Be sure to specify the date each source was last searched.\nNOTE: Researchers must be cautious of ascertainment bias, which occurs when certain studies are more likely to be identified (e.g., published in open-access journals or high-impact international journals) and included in a systematic review — not because they are necessarily better or more relevant, but simply because they are easier to find.\n\n8.7.1 Search in multiple electronic databases, platforms and engines\nBefore initiating the search, the team must develop a well-defined search strategy, identify relevant electronic databases, platforms and appropriate search engines, and, if necessary, create access accounts for those databases.\n\nSearch algorithm\n\nStart with simple search strategy.\nRun search, and retrieve reports.\nAnalyze controlled vocabulary terms and keywords of studies fitting the eligibility criteria, and revise strategy.\nRe-run search with revised strategy.\nRepeat steps 2 through 4 if necessary.\nRun optimal search strategy.\nRetrieve reports identified with optimal search strategy.\nRun the search strategy in multiple databases.\n\n\nMajor bibliographic databases for RCTs and observational studies:\n\nMEDLINE/PubMED\nEMBASE\nCochrane Central Register of Controlled Trials (CENTRAL)\n\nNational and regional databases (often local language):\n\nLILACS\nCNKI (China National Knowledge Infrastructure)\nKorean Medical Database (KMBASE)\n\nSubject-specific databases\n\nCINAHL (Cumulative Index to Nursing and Allied Health Literature)\nPsycINFO\nOTseeker (Occupational Therapy Systematic Evaluation of Evidence)\n\nCitation databases (platforms)\n\nWeb of Science\nWeb of Science\nScopus\n\nSearch Engines\n\nGoogle Scholar\n\nGray literature databases\n\nOpengrey\nNational Guidelines Clearing House\n\n\n\n8.7.2 Build a high-quality and effective search strategy\nWhen searching for academic papers, selecting the right search terms is crucial for finding relevant studies. These terms are typically derived from key concepts related to the topic of interest. There are two main types of search terms that should be used:\n\nControlled vocabulary terms: These are standardized subject terms used by databases to tag articles consistently, regardless of the terminology used by the authors. They help retrieve articles even if they use different words to describe the same concept. For example, MeSH (Medical Subject Headings) – used in PubMed/MEDLINE; Emtree – used in EMBASE; APA Thesaurus of Psychological Index Terms – used in PsycINFO.\nKeywords: These are natural language terms—the words and phrases that researchers might use in titles, abstracts, or full texts.\n\nFor systematic review searches, researchers should use both controlled vocabulary and keywords. Using only keywords may result in missing articles that use different terminology, while relying solely on controlled vocabulary could exclude articles that have not yet been indexed or were indexed using outdated terms. Boolean operators (OR, AND, NOT) are crucial, as they allow researchers to combine search terms and help narrow or expand the search results, making them more relevant to the research (Figure 8.4).\n\n\n\n\n\n\nFigure 8.4: Boolean operators.\n\n\n\nA comprehensive search for eligible studies is one of the most critical steps in a systematic review. Involvement of an information specialist or an experienced librarian is essential for developing a robust and effective search strategy. Note that each database has its own way of writing a search strategy.\n\nExample\nThe Cochrane Group’s Information Specialist initially searched the Cochrane Common Mental Disorders Controlled Trials Register (CCMD-CTR) (all years to 6 May 2016), using the following terms.\nCondition = (anxiety or depressi* or mood or mutism or neuroses or neurotic or “obsessive compulsive” or panic or phobi or psychoneuroses or “stress disorder*” or “psychological stress” or “school refusal”) and Comorbidity = not empty and Age Group = (child or adolescent)\n\nThis search included a more sensitive set of terms to find additional untagged/uncoded reports of RCTs. For example, regarding the age group:\n\nExample\n[Age Group] 1. (child* or boy* or girl* or infant* or juvenil* or minors or paediatric* or pediatric* or school* or preschool* or pre-school* or kindergarten or nursery or adolesc* or preadolesc* or pre-adolesc* or pubert* or pubescen* or prepube* or pre-pube* or high-school or teen* or (young next (adult* or people or patient* or men* or women* or mother* or male or female or survivor* or oCender* or minorit)) or youth or student* or undergrad* or college or campus or classroom):ti,ab\n\n\n\n8.7.3 Search citations using both backward and forward citation tracking methods\nCitation searching in the context of systematic reviews is a method used to identify relevant literature that may not be captured through standard database searches. It involves tracking how research articles are connected through citations. There are two main types of citation searching: backward citation searching (also known as reference list checking) and forward citation searching.\n\nBackward Citation Search: A search to find all the references cited within a single article. This search looks backwards in time to trace the prior research and sources that informed the development of the article.\nForward Citation Search: A search to find all subsequent articles that have cited a specific article. This search looks forward in time to explore how the article has influenced later research and contributed to the broader scholarly conversation.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#screen-and-select-studies",
    "href": "ma1.html#screen-and-select-studies",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.8 Screen and select studies",
    "text": "8.8 Screen and select studies\nThe search process most often yields a large number of potentially pertinent citations that need to be checked against the pre-specified eligibility criteria. Study selection is a staged process, which needs to be explicit and objective in order to minimize errors and biases.\nAt least two reviewers should first screen records retrieved at title and abstract level working independently (meaning that each reviewer is blinded to the decisions of the other). The initially selected reports will then qualify for full-text screening in a similar manner to reach a final decision about studies that will be included in the systematic review. Disagreements at any stage between assessors need to be resolved either with consensus or through arbitration with a senior reviewer.\nAutomation tools are available to facilitate both the de-duplication of records (i.e., removing duplicate records retrieved from multiple databases) and the study selection process. Software such as Rayyan, Covidence, EPPI-Reviewer, CADIMA, DistillerSR are specifically designed to support systematic reviews. Additionally, reference management tools like EndNote, Mendeley or Zotero can also be used to organize and manage citations, including handling duplicates.\nThe entire process should be documented using a well-designed flow diagram, known as the PRISMA flow chart, which outlines the number of records or studies reviewed at each stage and provides detailed reasons for exclusion (Figure 8.5) (Iddagoda and Flicker 2023).\n\n\n\n\n\n\nFigure 8.5: PRISMA flow chart.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#collect-data-form-included-studies",
    "href": "ma1.html#collect-data-form-included-studies",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.9 Collect data form included studies",
    "text": "8.9 Collect data form included studies\nHaving completed the study selection process, the reviewers should proceed with data extraction, during which they obtain all necessary information and outcome data from each eligible study. The data items to be extracted are agreed upon by the review team, and electronic data extraction forms are typically pilot tested on a small sample of eligible studies. This process is again conducted in duplicate to ensure accuracy and data integrity. At this stage unreported information or missing data might be sought through communication with authors of original reports.\nDuring data extraction, reviewers should ensure the use of clear abbreviations, consistent unit conversions, standardized definitions, and concise presentation of information.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#assess-the-methodological-quality-and-risk-of-bias-of-the-included-studies",
    "href": "ma1.html#assess-the-methodological-quality-and-risk-of-bias-of-the-included-studies",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.10 Assess the methodological quality and risk of bias of the included studies",
    "text": "8.10 Assess the methodological quality and risk of bias of the included studies\nA systematic review is only as good as the studies upon which is built. Evidence and results should be interpreted in light of the quality of the included studies. The quality of the research encompasses how a study has been conducted (methodological quality) and how it has been described (reporting quality and reproducibility). Poor methodological and reporting quality of primary studies included in the review may introduce bias and spurious conclusions (Muka et al. 2019; Mantsiou et al. 2023).\nTherefore, assessment of the methodological quality and risk of bias in the included studies by two independent reviewers is an essential component of a systematic review. For randomized controlled trials Cochrane released the RoB 2 tool (revised tool for Risk of Bias in randomized trials). Risk of bias is assessed at the outcome level for the following domains: randomization process, deviations from the intended interventions, missing outcome data, measurement of the outcome and selection of the reported result.\nAfter completing all seven bias domains, an overall judgment is made regarding the risk of bias of the study for the outcome under assessment: “low risk of bias”, “some concerns”, or “high risk of bias”. The overall risk-of-bias judgment is derived from the domain-level judgments using a predefined algorithm (Figure 8.6).\n\n\n\n\n\n\nFigure 8.6: Traffic light plot for ROB 2 tool.\n\n\n\n \n\n\n\n\n\n\nFigure 8.7: Summary barplot for ROB 2 tool.\n\n\n\nFor observational studies evaluation of methodological quality is based on the ROBINS-I tool V2 (Risk Of Bias in Non-randomized Studies - of Interventions Version 2). Risk of bias is assessed at the outcome level for the following domains: confounding, selection of participants into the study, classification of interventions, deviations from intended interventions, missing data, bias arising from measurement of the outcome, selection of the reported result.\nAfter completing all seven bias domains, an overall judgment is made regarding the risk of bias: “low risk of bias,” “moderate risk of bias,” “serious risk of bias,” or “critical risk of bias.” The overall risk-of-bias judgment is derived from the domain-level judgments using a predefined algorithm (Figure 8.8).\n\n\n\n\n\n\nFigure 8.8: Traffic light plot for ROBINS-I tool.\n\n\n\n \n\n\n\n\n\n\nFigure 8.9: Summary barplot for ROBINS-I tool.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#synthesize-the-results",
    "href": "ma1.html#synthesize-the-results",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.11 Synthesize the results",
    "text": "8.11 Synthesize the results\nOne of the most important steps in conducting a systematic review is synthesizing the results from the included primary studies. Authors should present the findings using narrative descriptions and summary tables, grouping the results according to key characteristics such as intervention, population, outcomes, or study design—this is referred to as qualitative synthesis.\nWhen the data are suitable for statistical aggregation, authors may also perform a meta-analysis (quantitative synthesis). In this process, a summary statistic is calculated for each included study—typically a (standardized) mean difference for continuous outcomes, or a risk ratio (RR) or odds ratio (OR) for dichotomous outcomes. An overall effect estimate is then computed as a weighted average of the individual study effects.\n\nMeta-analysis is an optional component of a systematic review, meaning that not every systematic review includes a meta-analysis. However, every systematic review does include a qualitative synthesis.\n\nIt is important to note that every study is unique, and those included in a systematic review will inevitably differ to some extent. Reviewers should assess heterogeneity, which may arise from factors such as participant characteristics, disease severity, concomitant treatments, or methodological quality. Depending on the presence and extent of heterogeneity, two basic meta-analytic models are available: the fixed-effect model and the random-effects model.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#assess-reporting-bias",
    "href": "ma1.html#assess-reporting-bias",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.12 Assess reporting bias",
    "text": "8.12 Assess reporting bias\nReviewers should assess the risk of bias in the result of a synthesis (such as meta-analysis) due to missing studies or missing results within studies. Missing studies/results may introduce bias when the decision to publish a study/result is influenced by the observed p-value or magnitude or direction of the effect (Page et al. 2021).\nFor example, studies with statistically non-significant results may not have been submitted for publication (publication bias), or particular results that were statistically non-significant may have been omitted from study reports (selective outcome reporting bias).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#grade-quality-of-evidence-grade-approach",
    "href": "ma1.html#grade-quality-of-evidence-grade-approach",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.13 Grade Quality of Evidence (GRADE approach)",
    "text": "8.13 Grade Quality of Evidence (GRADE approach)\nThe most common approach to rating the certainty of the evidence is the GRADE (Grading of Recommendations Assessment, Development and Evaluation) framework. GRADE has four levels of evidence ranging from very low quality, which suggests that we are very uncertain about the true estimate, to high quality, which suggests that further research is very unlikely to change our confidence in the estimate of effect (Balshem et al. 2011).\nRandomized controlled trials provide high quality evidence which may be downgraded for several reasons including high risk of bias, imprecision, inconsistency, indirectness, or concerns about publication bias. Conversely, evidence that includes observational data starts at low quality due to the possibility of residual confounding (i.e., confounding that persists after Adjustment for the putatively measured confounders) (Figure 8.10).\n\n\n\n\n\n\nFigure 8.10: A summary of GRADE’s approach to rating quality of evidence.\n\n\n\nThe evaluation should be performed independently by two reviewers, while any disagreement should be discussed with a third, independent reviewer.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma1.html#update-report-and-submit-for-publication",
    "href": "ma1.html#update-report-and-submit-for-publication",
    "title": "8  Systematic Review and Meta-analysis (1)",
    "section": "8.14 Update, report, and submit for publication",
    "text": "8.14 Update, report, and submit for publication\nWhen ready to submit the study for publication, if the interval since beginning the search of bibliographic databases is greater than 6–12 months the search should be updated to identify recently published articles (Muka et al. 2019).\nReporting guidelines exist to help ensure that systematic reviews with or without meta-analysis are reported with transparency, reproducibility, and comparability. The most commonly used guideline is PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses), which assists authors in clearly reporting why the review was conducted, what methods were used, and what the review found.\nFinally, additional experts with content expertise may be invited to review and comment on the manuscript (and the published work should acknowledge their assistance). It is still possible to improve the quality of the publication further by appraising the interpretation of the results one last time.\n\n\n\n\nBalshem, Howard, Mark Helfand, Holger J. Schünemann, Andrew D. Oxman, Regina Kunz, Jan Brozek, Gunn E. Vist, Yngve Falck-Ytter, Joerg Meerpohl, and Susan Norris. 2011. “GRADE Guidelines: 3. Rating the Quality of Evidence.” Journal of Clinical Epidemiology 64 (4): 401–6. https://doi.org/10.1016/j.jclinepi.2010.07.015.\n\n\nIddagoda, Mayura Thilanka, and Leon Flicker. 2023. “Clinical Systematic Reviews  a Brief Overview.” BMC Medical Research Methodology 23 (1). https://doi.org/10.1186/s12874-023-02047-8.\n\n\nMantsiou, Chrysanthi, Aris Liakos, Maria Mainou, Nikolaos Papanas, Apostolos Tsapas, and Eleni Bekiari. 2023. “A Simple Guide to Systematic Reviews and Meta-Analyses.” The International Journal of Lower Extremity Wounds, May. https://doi.org/10.1177/15347346231169842.\n\n\nMuka, Taulant, Marija Glisic, Jelena Milic, Sanne Verhoog, Julia Bohlius, Wichor Bramer, Rajiv Chowdhury, and Oscar H. Franco. 2019. “A 24-Step Guide on How to Design, Conduct, and Successfully Publish a Systematic Review and Meta-Analysis in Medical Research.” European Journal of Epidemiology 35 (1): 49–60. https://doi.org/10.1007/s10654-019-00576-5.\n\n\nPage, Matthew J, David Moher, Patrick M Bossuyt, Isabelle Boutron, Tammy C Hoffmann, Cynthia D Mulrow, Larissa Shamseer, et al. 2021. “PRISMA 2020 Explanation and Elaboration: Updated Guidance and Exemplars for Reporting Systematic Reviews.” BMJ, March, n160. https://doi.org/10.1136/bmj.n160.\n\n\nSaldanha, Ian J., Kay Dickersin, Xue Wang, and Tianjing Li. 2014. “Outcomes in Cochrane Systematic Reviews Addressing Four Common Eye Conditions: An Evaluation of Completeness and Comparability.” Edited by Kypros Kypri. PLoS ONE 9 (10): e109400. https://doi.org/10.1371/journal.pone.0109400.\n\n\nSutton, Anthea, Mark Clowes, Louise Preston, and Andrew Booth. 2019. “Meeting the Review Family: Exploring Review Types and Associated Information Retrieval Requirements.” Health Information & Libraries Journal 36 (3): 202–22. https://doi.org/10.1111/hir.12276.\n\n\nThabrew, Hiran, Karolina Stasiak, Sarah E Hetrick, Liesje Donkin, Jessica H Huss, April Highlander, Stephen Wong, and Sally N Merry. 2018. “Psychological Therapies for Anxiety and Depression in Children and Adolescents with Long-Term Physical Conditions.” Cochrane Database of Systematic Reviews 2019 (1). https://doi.org/10.1002/14651858.cd012488.pub2.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (1)</span>"
    ]
  },
  {
    "objectID": "ma2.html",
    "href": "ma2.html",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "",
    "text": "9.1 Introduction\nAlthough the term meta-analysis was first introduced by Smith and Glass in 1976 (Smith and Glass 1977), the first use of meta-analysis in the sense of combining quantitative studies is attributed to Karl Pearson (“Report on Certain Enteric Fever Inoculation Statistics” 1904), who analyzed data from five studies on the correlations between immunity and inoculation, as well as mortality and inoculation. In the late 1970s and early 1980s, following the work of Smith and Glass, meta-analysis gained widespread popularity, and the statistical methods necessary for its application were further refined and developed.\nIn a meta-analysis, a set of independent studies is included. Each study is summarized by an estimate of effect or association (the “study result”)—such as a mean difference, percentage, risk ratio, or correlation coefficient. The primary goal of a meta-analysis is to estimate an overall, or combined, effect size.\nIf all the studies included in the analysis were equally precise, we could simply calculate the average of their effect sizes. However, when some studies are more precise than others, it’s important to give more weight to those that provide more reliable information. This is exactly what a meta-analysis does. Instead of computing a simple average, it calculates a weighted average, assigning greater weight to more precise studies and less to those with higher uncertainty (Figure 9.1).\nThe key question, then, is how weights are assigned to individual studies. The answer depends on how we define the “combined effect”. There are two primary models used in meta-analysis, the fixed-effect model (also known as common effect model) and the random-effects model. Each model has different assumptions regarding the included studies, leading to different definitions of the combined effect and different mechanisms for assigning weights.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#introduction",
    "href": "ma2.html#introduction",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "",
    "text": "Meta-analysis is an optional component of a systematic review. It is the statistical analysis which combines the results of several independent studies considered by the analyst to be “combinable”. This definition highlights that the reviewer has to make the decision whether the studies are similar enough to be combined in a meta-analysis.\n\n\n\n\n\n\n\n\n\n\nFigure 9.1: The framework of meta-analysis for evidence integration.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#fixed-effect-model",
    "href": "ma2.html#fixed-effect-model",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "9.2 Fixed-effect model",
    "text": "9.2 Fixed-effect model\nThe framework of fixed effect model\nIn a fixed-effect (FE) model we assume that all \\(k\\) studies considered in the meta-analysis share a common effect size, \\(\\theta_1 = \\theta_2= ...=\\theta_k = \\theta\\) (hence, the term fixed). Each observed effect, \\(Y_i\\), is considered to be distributed around \\(\\theta\\), with a variance \\(V_{Y_i}\\) informed entirely by the within-study variance (sampling error).\n\n\n\n\n\n\nFigure 9.2: Fixed-effect model – distribution of sampling error.\n\n\n\nThe observed effect \\(Y_i\\) for any study (squares) is given by the common effect size, \\(\\theta\\), plus the sampling error in that study, \\(e_i\\). That is,\n\\[Y_i = \\theta + e_i\\]\nwhere \\(e_i \\sim N(0, V_{Y_i})\\).\nWhile the error in any given study is random, we can estimate the sampling distribution of the errors. In Figure 9.2 we have placed a normal curve about the true effect size for each study, with the width of the curve being based on the variance in that study. For example, in Study 1 the sample size is small, the variance large, and the observed effect is likely to fall anywhere within a relatively wide range. By contrast, in Study 2 the sample size is relatively large, the variance is small, and the observed effect is likely to fall in a relatively narrow range. (The width of the normal curve is based on the square root of the variance, or standard error).\nThe weight assigned to each study in a fixed-effect meta-analysis is the inverse of the variance \\(V_{Y_i}\\):\n\\[W_i = \\frac{1}{V_{Y_i}}\\]\n \nSummary effect and confidence interval\nThe summary effect, \\(\\theta_F\\), in a fixed-effect model represents the estimate of a common true effect shared by all included studies. The associated confidence interval (CI) reflects the uncertainty around this estimate. The width of the normal distribution curve for each study is determined by its variance—studies with smaller variances (typically due to larger sample sizes) yield narrower curves, indicating more precise estimates.\nThe summary effect and its confidence interval are displayed at the bottom of Figure 9.2.\n\\[\\theta_F = \\frac{\\sum_{i=1}^k W_i Y_i}{\\sum_{i=1}^k W_i}\\]\nThe variance of \\(\\theta_F\\) is given by\n\\[V_{\\theta_F} = \\frac{1}{\\sum_{i=1}^k W_i}\\]\nand the estimated standard error of the summary effect is the square root of the variance,\n\\[SE_{\\theta_F} = \\sqrt{V_{\\theta_F}}\\]\n \nThen, 95% lower and upper limits for the summary effect are estimated as\n\\[LL_{\\theta_F} = \\theta_F - 1.96 \\times SE_{\\theta_F}\\]\nand\n\\[UL_{\\theta_F} = \\theta_F + 1.96 \\times SE_{\\theta_F}\\]",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#random-effects-model",
    "href": "ma2.html#random-effects-model",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "9.3 Random effects model",
    "text": "9.3 Random effects model\nThe framework of fixed effect model\nWhen we decide to incorporate a group of studies in a meta-analysis, we assume that the studies have enough in common that it makes sense to synthesize their results. Nevertheless, there is generally no reason to believe that the true effect size is exactly the same in every study.\nInstead of assuming all \\(\\theta_i\\) are equal (as in a fixed-effect model), the random-effects model assumes:\n\\[\\theta_i \\sim N(\\mu, \\tau^2)\\]\nThat is, the true effect sizes (represented by orange circles in Figure 9.3) are distributed around a mean, \\(\\mu\\), and can be considered a random sample from a normal distribution with variance \\(\\tau^2\\)—hence, the term random. In Figure 9.3 this distribution is illustrated by the orange normal curve at the bottom of the graph.\n\n\n\n\n\n\nFigure 9.3: Random-effects model – between-study and within-study variance.\n\n\n\nFigure 9.3 also highlights that the distance between the overall mean and the observed effect in any given study consists of two distinct parts: true variation in effect sizes (\\(u_i\\)) and sampling error (\\(e_i\\)).\nTherefore, the observed effect \\(Y_i\\) for any study is given by the grand mean (\\(\\mu\\)), the deviation of the study’s true effect from the grand mean (\\(u_i\\)), and the deviation of the study’s observed effect from the study’s true effect (\\(e_i\\)). That is,\n\\[Y_i = \\theta_i + e_i = \\mu + u_i + e_i\\]\nwhere \\(e_i \\sim N(0, V_{Y_i})\\) and \\(u_i \\sim N(0, \\tau^2)\\).\nTo compute a study’s variance under the random-effects model, we need to know both the within-study variance and \\(\\tau^2\\):\n\\[V^*_{Y_i} = V_{Y_i} + \\tau^2\\]\nIt is important to note that the same value of \\(\\tau^2\\) applies to all studies in the meta-analysis.\nUnder the random-effects model the weight assigned to each study is:\n\\[W^*_i = \\frac{1}{V^*_{Y_i}} = \\frac{1}{V_{Y_i} + \\tau^2}\\] Study weights are more balanced under the random-effects model than under the fixed-effect model. Large studies are assigned less relative weight and small studies are assigned more relative weight as compared with the fixed-effect model.\n(NOTE: To highlight the parallel between the formulas of random effects model and those in the fixed effect model we use the same notations but add an asterisk * to represent the random-effects version.)\n \nSummary effect and confidence interval\nThe summary effect in random effect meta-analysis provides an estimation of the average treatment effect, and the CI reflects the uncertainty around this estimate, including the component of heterogeneity.\n\\[\\theta_R = \\frac{\\sum_{i=1}^k W^*_i Y_i}{\\sum_{i=1}^k W^*_i}\\]\nThe variance of \\(\\theta_R\\) is given by\n\\[V_{\\theta_R} = \\frac{1}{\\sum_{i=1}^k W^*_i}\\]\nand the estimated standard error of the summary effect is the square root of the variance,\n\\[SE_{\\theta_R} = \\sqrt{V_{\\theta_R}}\\]\n \nThen, 95% lower and upper limits for the summary effect are estimated as\n\\[LL_{\\theta_R} = \\theta_R - 1.96 \\times SE_{\\theta_R}\\]\nand\n\\[UL_{\\theta_R} = \\theta_R + 1.96 \\times SE_{\\theta_R}\\]\nIn the presence of heterogeneity, the relative weights assigned under a random-effects model are more balanced than those in a fixed-effect model. This is because standard random-effects methods add a common component of variance (\\(\\tau^2\\)) to each study’s weight to account for between-study variability in treatment effects. As a result, this dual source of variability—within-study and between-study—leads to larger overall variance, wider standard errors, and broader confidence intervals for the summary effect estimate.\nMultiple estimators have been proposed for \\(\\tau^2\\) such as the Der Simonian and Laird, the restricted maximum-likelihood and maximum likelihood, the Paul-Mantel, Hedges, and Hunter-Schmidt estimator.\nNOTE: Hartung and Knapp introduced a new meta-analysis method based on a refined variance estimator in the random effects model. It has been argued that the Hartung–Knapp method is preferred over the DerSimonian–Laird method.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#forest-plot",
    "href": "ma2.html#forest-plot",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "9.4 Forest plot",
    "text": "9.4 Forest plot\nThe main output of a meta-analysis is a graph called a forest plot. This plot depicts results from each primary study as well as the summary effect estimate.\nEach study is identified by the first author and date of publication and is presented in a single row at the left side of the plot. Results from individual studies are shown as a square which represents the estimate of the effect size and a horizontal line which corresponds to the confidence interval. The size of the square is proportional to the weight of the study, which indicates its relative impact on the calculations of the summary effect (Figure 9.4).\nThere is also a vertical reference line at the null hypothesis (0.0 for mean difference results and 1.0 for ratio results), which denotes no effect between intervention and comparison groups.\nThe overall effect estimate is presented graphically as a diamond, with the endpoints representing the limits of the 95% confidence interval (CI). This confidence interval indicates how precisely we have estimated the effect size, based on the standard error of the mean.\nIn contrast, the 95% prediction interval reflects the expected range of effect sizes in future studies, considering the standard deviation of the effect sizes observed across studies. Unlike the confidence interval, which reflects the precision of the overall estimate, the prediction interval is an absolute measure that accounts for the heterogeneity between studies (Borenstein 2023).\n\n\n\n\n\n\nFigure 9.4: A typical forest plot.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#heterogeneity",
    "href": "ma2.html#heterogeneity",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "9.5 Heterogeneity",
    "text": "9.5 Heterogeneity\n\n9.5.1 Types of Heterogeneity\nThere are three types of heterogeneity: clinical, methodological, and statistical.\n\nClinical heterogeneity: Variability in participants (e.g., inclusion criteria, geographical location), interventions (e.g., dose, nature of control interventions) and outcomes (e.g., follow-up duration, cut-off points).\nMethodological heterogeneity: Variability in the study design, the quality of conduct, and approach to analysis. For example, when the sequence of assigning participants to treatment groups is not concealed, randomized clinical trials tend to estimate larger treatment effects.\nStatistical heterogeneity: Variability in effect sizes, resulting from clinical and/or methodological diversity. Statistical heterogeneity is present if the observed effects are more different from each other than would be expected due to random sampling.\n\n\n\n9.5.2 Assessing heterogeneity in meta-analysis\nAssessment of the consistency of effects across studies is an essential part of meta-analysis. Unless we know how consistent the results of studies are, we cannot determine the generalisability of the findings of the meta-analysis.\nCochran’s Q statistic\nThe statistical test usually applied in meta-analysis for detecting true heterogeneity among studies is the Q test, proposed by Cochran. Under the null hypothesis of no heterogeneity (\\(H_o\\): the true effects are the same in all the primary studies included in meta-analysis; or \\(H_o\\): \\(\\tau^2 = 0\\)), the Q statistic follows a chi-square distribution with k-1 degrees of freedom, where k is the number of studies.\nThe statistical power of Cochran’s Q test is often low, particularly in meta-analyses that include a small number of studies. Consequently, true heterogeneity may go undetected when conventional significance thresholds, such as 0.05, are applied. To mitigate this limitation, a more lenient threshold of 0.10 has been proposed; however, this increases the risk of a Type I error. As such, the Q test should be interpreted with caution, especially when the analysis includes fewer than 20 studies. Furthermore, it is not recommended to determine the choice between a fixed-effect and a random-effects model solely based on the Q test results, as it does not provide sufficient evidence to guide model selection.\n\nStatistical heterogeneity may not always be observed, even in the presence of clinical and/or methodological heterogeneity. Therefore, the absence of statistical heterogeneity should not be interpreted as evidence of no heterogeneity.\n\n \n\\(\\tau^2\\) measure\n\\(\\tau^2\\) describes the underlying between-study variability. Its square root, \\(\\tau\\), is measured in the same units as the outcome. Its estimate does not systematically increase with either the number of studies or the sample size.\n \n\\(I^2\\) index\nAnother statistic used to assess heterogeneity is \\(I^2\\), which represents the part of total variation that is due to between-studies variance. \\(I^2\\) is a percentage and its values lie between 0% and 100%. For example, an \\(I^2\\) value of 0% indicates that all variability in effect size estimates is due to sampling error within studies, whereas an \\(I^2\\) value of 50% indicates that half of the total variability among effect sizes is caused by true heterogeneity between studies. Importantly, \\(I^2\\) is a relative measure and can be directly compared between meta-analyses with different numbers of studies and various types of outcome data.\n\\(I^2\\) values of approximately 25%, 50%, and 75% have been proposed to indicate low, moderate, and high heterogeneity, respectively (Higgins 2003). However, it should be interpreted with caution when the number of included studies is small (e.g., fewer than 20). Moreover, when the study sizes become very large, the sampling error tends to 0 and \\(I^2\\) tends to 1 and such heterogeneity may not be clinically relevant.\nThe majority of meta-analyses use the \\(I^2\\) index to quantify heterogeneity. While this practice is common it is nevertheless incorrect. I-squared does not tell us how much the effect size varies (except when I-squared is zero percent). The statistic that does convey this information is the prediction interval (Borenstein 2023).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#small-study-effects-in-meta-analysis",
    "href": "ma2.html#small-study-effects-in-meta-analysis",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "9.6 Small-study effects in meta-Analysis",
    "text": "9.6 Small-study effects in meta-Analysis\n“Small-study effects” is a generic term for the phenomenon that smaller studies sometimes show different, often larger, treatment effects than large ones.\nPotential sources of asymmetry in funnel plots\n\nOne possible, and probably the most well-known, reason is publication bias. This occurs when the likelihood of a study being published—particularly a small study—increases if it shows a stronger, statistically significant, and favorable effect. Conversely, small studies with null or negative findings are less likely to be published, especially since such studies are often perceived as less robust or less interesting.\n\nNOTE: Publication bias affects all review methods (not a problem exclusive to MAs!)\n\nThere are a number of other possible reasons for small-study effects. One is selective reporting of the most favourable outcomes, known as outcome reporting bias.\nAnother possible cause of small-study effects is clinical heterogeneity between patients in large and small studies; e.g., patients in smaller studies may have been selected so that a favourable outcome of the experimental treatment may be expected.\n\n \nTools to assess small-study effects\nA funnel plot is a graphical tool commonly used in meta-analysis to assess small-study effects. It is a simple scatterplot that presents the treatment effects estimated from individual studies on the x-axis and a measure of precision, usually the standard error of the effect estimate, on the y-axis. At the top of the graph, studies with greater precision (smaller standard errors) are located, while those with less precision (larger standard errors) are found lower on the plot. A vertical solid line indicates the estimate based on the model. A pseudo confidence interval region is drawn around this value with bounds equal to ±1.96 SE, where SE is the standard error value from the y‐axis (assuming level = 95)(Figure 9.5).\nIf no excessive between-study heterogeneity exists, smaller studies (with larger standard errors) would scatter more than larger studies. That is, the funnel plot would show the form of a triangle (inverted funnel) symmetric with respect to the average treatment effect, with broad variability for small imprecise studies (at the bottom of the plot) and small dispersion for large, precise studies (at the top) (Figure 9.5).\n\n\n\n\n\n\nFigure 9.5: Symmetrical funnel plot.\n\n\n\nIn an asymmetrical funnel plot, one side may exhibit a higher density of studies than the other, or there may be a noticeable absence of studies on one side, both of which suggest potential bias (Figure 9.6).\n\n\n\n\n\n\nFigure 9.6: Asymmetrical funnel plot.\n\n\n\nReviewers might attempt to assess small-study effects by inspecting the funnel plot for asymmetry, either visually or formally, using methods such as Egger’s test or the Begg and Mazumdar rank correlation. For these statistical tests, a p-value &lt; 0.05 indicates asymmetry in the funnel plot. In general, these tests are relatively imprecise, and it is not advisable to test for asymmetry in the funnel plot when fewer than ten studies are available (Figure 9.5).\nFunnel-plot asymmetry thus raises the possibility of bias, but it is not proof of bias (Sterne, Gavaghan, and Egger 2000). It is important to note, however, that asymmetry (unless produced by chance alone) will always lead us to question the interpretation of the overall estimate of effect when studies are combined in a meta-analysis. It is suggested that the funnel plot should be seen as a generic means of examining “small-study effects” (the tendency for the smaller studies in a meta-analysis to show larger treatment effects) rather than as a tool to diagnose specific types of bias.\nThe Test of Excess Significance (TES) is a statistical method used to detect and quantify publication bias or selective reporting in the literature. Specifically, it examines whether the number of statistically significant findings in a set of studies exceeds what would be expected by chance. P-values less than 0.05 indicate that there are more significant results than expected, which may suggest publication bias or selective reporting.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "ma2.html#meta-analysis-using-jamovi",
    "href": "ma2.html#meta-analysis-using-jamovi",
    "title": "9  Systematic Review and Meta-analysis (2)",
    "section": "9.7 Meta-analysis using Jamovi",
    "text": "9.7 Meta-analysis using Jamovi\nThe aim of this meta-analysis is to investigate whether psychological therapies are more effective than any comparator in improving quality of life immediately post-intervention. Seven studies examined this outcome, and the following data were extracted for each group:\n\n\n\n\n\n\n\n\nFigure 9.7: Table with raw data.\n\n\n\n\n\nstudy: name and year of the study\nMean1: mean of the psychological therapy group\nSD1: standard deviation of the psychological therapy group\nTotal1: number of participants of the psychological therapy group\nMean2: mean of the comparator group\nSD2: standard deviation of the comparator group\nTotal2: number of participants of the comparator group\n\nStandardized mean differences (SMDs) will be used to summarize the data from each group, as the studies employed different scales to assess the outcome.\nOpen the dataset named “meta” from the file tab in the menu (Figure 9.8).\n\n\n\n\n\n\nFigure 9.8: The meta dataset.\n\n\n\nOn the Jamovi top menu navigate to\n\n\n\n\n\nflowchart LR\n  A(Analyses) -.-&gt; B(Meta Analysis) -.-&gt; C(Mean Differences)\n\n\n\n\n\n\nas shown below (Figure 9.9).\n\n\n\n\n\n\nFigure 9.9: In the menu at the top, choose Analyses -&gt; Meta Analysis -&gt; Mean Differences.\n\n\n\nThe The Mean Differences box opens (Figure 9.10). From the left-hand pane drag the variables into the right-hand fields, as shown below:\n\n\n\n\n\n\nFigure 9.10: The Mean Differences box options. Drag and drop the variables into the right-hand field.\n\n\n\nFrom the Model Options we select “Restricted Maximum-Likelihood” for estimating the \\(\\tau^2\\), and “Standardized Mean Difference” as the measure of effect size.\n\n\n\n\n\n\nFigure 9.11: Model options of meta-analysis.\n\n\n\n \nNext, from the Plot section tick the box “Prediction Interval”, “Model fitting weights”, and in the X-Axis Title type “SMD”.\n\n\n\n\n\n\nFigure 9.12: The Plots check options.\n\n\n\n \n\n\n\n\n\n\nFigure 9.13: Random-Effects model. Overall effect.\n\n\n\nA total of k=7 studies were included in the analysis. The observed standardized mean differences (SMD) ranged from 0.064 to 5.20, with all estimates being positive. The estimated average SMD based on the random-effects model was 1.28 (95% CI: 0.05 to 2.52). Therefore, the average outcome differed significantly from zero (z = 2.04, p = 0.04).\n \n\n\n\n\n\n\nFigure 9.14: Heterogeneity Statistics results.\n\n\n\nAccording to the Q-test, the true effects do not appear to be the same across all primary studies (Q(6) = 60.3, p &lt; 0.001). The proportion of total variance attributable to between-study differences is substantial, with an I² value of 96.9%; however, the small number of studies limits the reliability of this estimate. Most importantly, the 95% prediction interval for the true effect, ranging from –2.12 to 4.69, reflects considerable heterogeneity across studies.\n \nFigure 9.15 presents the forest plot comparing psychological therapy with any comparator for the outcome Quality of life (short-term).\n\n\n\n\n\n\nFigure 9.15: Forest plot.\n\n\n\nThe psychological therapies were more effective than any comparator in improving quality of life immediately post-intervention (SMD = 1.28, CI 0.05 to 2.52).\nObserve that the forest plot clearly demonstrates that the Monghanloo (2015) study (n = 34) exhibits a large standardized mean difference (SMD) of approximately 5.20, with a confidence interval ranging from 3.8 to 6.6. This finding is markedly different from the other studies (it may be a potential outlier in the context of this model), which show effect sizes closer to zero or slightly positive.\n(Note: The authors of the systematic review considered a SMD effect size of 0.2 to be small, 0.5 medium, and greater than 0.8 large).\nSmall-study effects and publication bias\nWe check Show Test of Excess Significance output from the Publication Bias (Figure 9.16).\n\n\n\n\n\n\nFigure 9.16: Tests for publication bias.\n\n\n\n\n\n\n\n\n\nFigure 9.17: Test of Excess Significance (TES).\n\n\n\n\n\n\n\n\n\nFigure 9.18: Funnel plot.\n\n\n\n\n\n\n\n\n\nFigure 9.19: Results of the tests for publication bias.\n\n\n\nThe visual asymmetry of the funnel plot, particularly the absence of smaller studies showing non-positive effects, raises concerns about a small-study effect (). Egger’s test also suggests the presence of funnel plot asymmetry (z = 4.4, p &lt; 0.001). However, the Begg and Mazumdar rank correlation test was not statistically significant (Kendall’s tau = 0.62, p = 0.069) and the Test of Excess Significance indicated no evidence of excess significance bias (i.e., no suspiciously high number of significant findings). Given the small number of studies (n = 7), the results from both the statistical tests and the funnel plot are not very clear and should be interpreted with caution.\n(NOTE: Research has found that funnel plots using the standardized mean difference (SMD) in combination with the standard error (SE) are unsuitable for assessing publication bias and can lead to false-positive results (Zwetsloot et al. 2017))\n\n\n\n\nBorenstein, Michael. 2023. “How to Understand and Report Heterogeneity in a Meta-Analysis: The Difference Between I-Squared and Prediction Intervals.” Integrative Medicine Research 12 (4): 101014. https://doi.org/10.1016/j.imr.2023.101014.\n\n\nHiggins, J. P T. 2003. “Measuring Inconsistency in Meta-Analyses.” BMJ 327 (7414): 557–60. https://doi.org/10.1136/bmj.327.7414.557.\n\n\n“Report on Certain Enteric Fever Inoculation Statistics.” 1904. BMJ 2 (2288): 1243–46. https://doi.org/10.1136/bmj.2.2288.1243.\n\n\nSmith, Mary L., and Gene V. Glass. 1977. “Meta-Analysis of Psychotherapy Outcome Studies.” American Psychologist 32 (9): 752–60. https://doi.org/10.1037/0003-066x.32.9.752.\n\n\nSterne, Jonathan A. C, David Gavaghan, and Matthias Egger. 2000. “Publication and Related Bias in Meta-Analysis.” Journal of Clinical Epidemiology 53 (11): 1119–29. https://doi.org/10.1016/s0895-4356(00)00242-0.\n\n\nZwetsloot, Peter-Paul, Mira Van Der Naald, Emily S Sena, David W Howells, Joanna IntHout, Joris AH De Groot, Steven AJ Chamuleau, Malcolm R MacLeod, and Kimberley E Wever. 2017. “Standardized Mean Differences Cause Funnel Plot Distortion in Publication Bias Assessments.” eLife 6 (September). https://doi.org/10.7554/elife.24260.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Systematic Review and Meta-analysis (2)</span>"
    ]
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "10  Presentations",
    "section": "",
    "text": "Lecture 1: Introduction\n\n\n\n\npsy-introduction\n\n\n     \n\nLecture 2: Between-subjects: One-way ANOVA\n\n\n\n\npsy-anova1\n\n\n     \n\nLecture 3: Within-subjects: Repeated ANOVA\n\n\n\n\npsy-anova2\n\n\n     \n\nLecture 4: Within-subjects: Two-way ANOVA\n\n\n\n\npsy-anova3\n\n\n     \n\nLecture: Linear Regression (Simple Models)\n\n\n\n\npsy-linear1\n\n\n     \n\nLecture: Linear Regression (Multi-variable models)\n\n\n\n\npsy-linear2\n\n\n     \n\nLecture: Systematic Reviews\n\n\n\n\npsy-SR_meta1",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Presentations</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Balshem, Howard, Mark Helfand, Holger J. Schünemann, Andrew D. Oxman,\nRegina Kunz, Jan Brozek, Gunn E. Vist, Yngve Falck-Ytter, Joerg\nMeerpohl, and Susan Norris. 2011. “GRADE Guidelines: 3. Rating the\nQuality of Evidence.” Journal of Clinical Epidemiology\n64 (4): 401–6. https://doi.org/10.1016/j.jclinepi.2010.07.015.\n\n\nBorenstein, Michael. 2023. “How to Understand and Report\nHeterogeneity in a Meta-Analysis: The Difference Between I-Squared and\nPrediction Intervals.” Integrative Medicine Research 12\n(4): 101014. https://doi.org/10.1016/j.imr.2023.101014.\n\n\nHiggins, J. P T. 2003. “Measuring Inconsistency in\nMeta-Analyses.” BMJ 327 (7414): 557–60. https://doi.org/10.1136/bmj.327.7414.557.\n\n\nIddagoda, Mayura Thilanka, and Leon Flicker. 2023. “Clinical\nSystematic Reviews  a Brief Overview.” BMC\nMedical Research Methodology 23 (1). https://doi.org/10.1186/s12874-023-02047-8.\n\n\nMantsiou, Chrysanthi, Aris Liakos, Maria Mainou, Nikolaos Papanas,\nApostolos Tsapas, and Eleni Bekiari. 2023. “A Simple Guide to\nSystematic Reviews and Meta-Analyses.” The International\nJournal of Lower Extremity Wounds, May. https://doi.org/10.1177/15347346231169842.\n\n\nMuka, Taulant, Marija Glisic, Jelena Milic, Sanne Verhoog, Julia\nBohlius, Wichor Bramer, Rajiv Chowdhury, and Oscar H. Franco. 2019.\n“A 24-Step Guide on How to Design, Conduct, and Successfully\nPublish a Systematic Review and Meta-Analysis in Medical\nResearch.” European Journal of Epidemiology 35 (1):\n49–60. https://doi.org/10.1007/s10654-019-00576-5.\n\n\nPage, Matthew J, David Moher, Patrick M Bossuyt, Isabelle Boutron, Tammy\nC Hoffmann, Cynthia D Mulrow, Larissa Shamseer, et al. 2021.\n“PRISMA 2020 Explanation and Elaboration: Updated Guidance and\nExemplars for Reporting Systematic Reviews.” BMJ, March,\nn160. https://doi.org/10.1136/bmj.n160.\n\n\n“Report on Certain Enteric Fever Inoculation Statistics.”\n1904. BMJ 2 (2288): 1243–46. https://doi.org/10.1136/bmj.2.2288.1243.\n\n\nSaldanha, Ian J., Kay Dickersin, Xue Wang, and Tianjing Li. 2014.\n“Outcomes in Cochrane Systematic Reviews Addressing Four Common\nEye Conditions: An Evaluation of Completeness and Comparability.”\nEdited by Kypros Kypri. PLoS ONE 9 (10): e109400. https://doi.org/10.1371/journal.pone.0109400.\n\n\nSmith, Mary L., and Gene V. Glass. 1977. “Meta-Analysis of\nPsychotherapy Outcome Studies.” American Psychologist 32\n(9): 752–60. https://doi.org/10.1037/0003-066x.32.9.752.\n\n\nSterne, Jonathan A. C, David Gavaghan, and Matthias Egger. 2000.\n“Publication and Related Bias in Meta-Analysis.”\nJournal of Clinical Epidemiology 53 (11): 1119–29. https://doi.org/10.1016/s0895-4356(00)00242-0.\n\n\nSutton, Anthea, Mark Clowes, Louise Preston, and Andrew Booth. 2019.\n“Meeting the Review Family: Exploring Review Types and Associated\nInformation Retrieval Requirements.” Health Information &\nLibraries Journal 36 (3): 202–22. https://doi.org/10.1111/hir.12276.\n\n\nThabrew, Hiran, Karolina Stasiak, Sarah E Hetrick, Liesje Donkin,\nJessica H Huss, April Highlander, Stephen Wong, and Sally N Merry. 2018.\n“Psychological Therapies for Anxiety and Depression in Children\nand Adolescents with Long-Term Physical Conditions.” Cochrane\nDatabase of Systematic Reviews 2019 (1). https://doi.org/10.1002/14651858.cd012488.pub2.\n\n\nZwetsloot, Peter-Paul, Mira Van Der Naald, Emily S Sena, David W\nHowells, Joanna IntHout, Joris AH De Groot, Steven AJ Chamuleau, Malcolm\nR MacLeod, and Kimberley E Wever. 2017. “Standardized Mean\nDifferences Cause Funnel Plot Distortion in Publication Bias\nAssessments.” eLife 6 (September). https://doi.org/10.7554/elife.24260.",
    "crumbs": [
      "References"
    ]
  }
]