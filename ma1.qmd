# Systematic Review and Meta-analysis (1) {#sec-ma1}

```{r}
#| include: false

library(fontawesome)
```

When we have finished this chapter, we should be able to:

::: {.callout-caution icon="false"}
## Learning objectives

-   Understand the concept and purpose of a systematic review.
-   Learn the main steps involved in conducting a systematic review.
-   Explore the tools available to facilitate the review process.
:::

## Meeting the review family

As more primary studies are conducted in research, the body of relevant research literature continues to grow. This expansion is a welcome development for psychologists working across various fields—such as clinical, educational, school, industrial-organizational, health, and sports psychology—who aim to ground their practice in evidence-based findings. However, the growing volume of research also presents new challenges in gathering, analyzing, and synthesizing the vast amount of available information.

To manage this complexity, researchers are increasingly turning to research reviews, which help organize, evaluate, and interpret existing studies. These reviews make the growing body of knowledge more accessible and applicable to both practice and future research. Forty-eight review types have been identiﬁed and categorized into seven families [@sutton2019]:

-   Traditional literature review
-   Systematic review
-   Rapid review
-   Qualitative review
-   Mixed-methods review
-   Purpose-specific review (Health Technology Assessment-HTA)
-   Review of reviews

But there are much more:

-   Scoping review
-   Living review
-   Economic evaluation review
-   Measurement properties review

## Evidence based pyramid in research

The levels of evidence, or hierarchy of evidence, provide a framework for ranking medical studies according to the quality and reliability of their design. This hierarchy is often represented as a pyramid, which reflects both the quality and quantity of evidence available. In this model, higher levels represent more rigor and reliable evidence. Each level builds upon the data and research found in the tiers below (@fig-ma9).

Evidence based pyramids are typically divided into two or three sections. The top section includes secondary evidence such as systematic reviews, meta-analyses, and critical appraisals. The middle section contains primary evidence, including randomized controlled trials (RCTs), cohort studies, case-control studies, case series, and case reports. Some models also include a bottom tier that represents background information and expert opinion (Source: [openmd](https://openmd.com/guide/levels-of-evidence)).

![Evidence based pyramid (Based on Source: https://openmd.com/guide/levels-of-evidence).](images/ma9.png){#fig-ma9 width="75%"}

## Systematic review

Among all types of reviews (@fig-ma10), the systematic review is considered one of the most rigorous and trusted forms of research synthesis. Therefore, conducting reliable, well-organized systematic reviews is essential for effectively synthesizing the findings of primary studies .

![Evidence pyramid.](images/ma10.png){#fig-ma10 width="75%"}

::: content-box-green
**Definition of systematic review**

Systematic review (SR) is a review of clearly formulated question that uses explicit, pre-planned scientific methods to identify, select, appraise, and synthesize results from similar but separate primary studies. (NOTE: Meta-analysis (MA), the statistical analysis of a large collection of results from individual studies is an optional component of a systematic review).
:::

For example, let’s consider the Cochrane systematic review titled "Psychological therapies for anxiety and depression in children and adolescents with long-term physical conditions" [@thabrew2018].

Next, we outline the **fundamental steps** involved in conducting a systematic review.

## Establish a team and develop a focused research question

The first step in conducting a systematic review is typically initiated by independent researchers, universities, institutes, or organizations such as the Cochrane Collaboration, the Joanna Briggs Institute (JBI), and the Centre for Reviews and Dissemination at the University of York. Policy-focused groups, including professional societies, government agencies, and healthcare payers, may also initiate such reviews. These entities undertake systematic reviews to address well-defined research questions or explore specific hypotheses, aiming to generate high-quality evidence that can guide practice, inform policy, and shape future research directions.

Initially, a **preliminary search** of the existing literature is conducted to identify knowledge gaps within the field. The existence of previous systematic reviews on similar topics does not preclude the need for a new review—provided the new review addresses unresolved issues, incorporates updated evidence, or offers a novel analytical perspective that adds meaningful value.

**Establish a research team**

The research core team must clearly specify and agree on the reasons for the study as these are the driving force for any systematic reviews. All the team members must be fully aware and convinced of the reasons behind the proposed review and why the study is important.

Conduct of a systematic review is a complex procedure involving collaboration of **content experts**, **librarians**, **methodologists**, and **statisticians**. A well-organized and coordinated team is essential for conducting a successful systematic review. Many steps—such as the literature search, screening process, and quality assessment—require independent verification by multiple reviewers.

Careful selection of colleagues and experts for the team is essential, evaluating both their expertise in the field and their professional integrity. The complexity of the research question and the anticipated number of primary studies will also influence the size of the team.

Finally, no team can function effectively without a leader. The team leader is responsible for coordinating the project, ensuring adherence to the study protocol, keeping all members informed, and facilitating active participation throughout all phases of the review.

**Develop a focused research question**

The formulation of research question determines all the subsequent steps of the review: what studies should be included, where and how to search for studies, how to critically appraise those studies, and so on. The review question is usually based on the **"PICO"** mnemonic, which stands for:

-   **P**opulation

-   **I**ntervention

-   **C**omparison(s)

-   **O**utcome(s)

::: content-box-blue
**Example**

**Population:** Children and adolescents aged up to 18 years with depression or anxiety or both with "long-term conditions"

**Iintervention:** Individual or group-based psychological or psychologically-oriented therapy excluding e-health therapies.

**Comparator:** Controls (treatment-as-usual, waiting list, attention placebo, psychological placebo, or non-psychological treatment).

**Outcome:** Changes in severity of anxiety and depression symptoms measured separately using validated scales.
:::

It is important to note that a systematic review with a broad scope provides a comprehensive summary of the available evidence base, nevertheless it is resource-intensive and usually comes with substantial heterogeneity that hinders interpretation of the findings. In contrast, a systematic review with a narrow focus is more manageable, but the available evidence may be limited, and the generalizability of the findings may be reduced.

## Develop your research plan and (pre) register the project

A pre-study plan (or protocol) outlines objectives, methods, and criteria for a systematic review. In other words, it provides a structured framework to guide the review process through its various stages.

To increase the openness and transparency of a systematic review and streamlines the review process, researchers can preregister or register their projects using a registry. Preregistration and registration differ primarily in terms of timing. Preregistration occurs when researchers document essential information about a research project before they begin collecting data or analyzing primary sources. In contrast, registration refers to documenting the research project after the research process has already begun.

## Specify the inclusion and exclusion criteria

The PICO framework is commonly used to specify the inclusion and exclusion criteria (eligibility criteria) for reviews of interventions. A critical step in setting these criteria is the evaluation of the type(s) of study design that may best answer the research question. Another important step is the clear definition of the outcomes. Specifically, an outcome can include five elements(@fig-ma8) [@saldanha2014]:

1.  The domain or outcome title (e.g., anxiety).

2.  The specific measurement or technique/instrument used to make the measurement (e.g., Hamilton Anxiety Rating Scale).

3.  The specific metric or format of the outcome data from each participant that will be used for analysis (e.g., value at a time-point, change from baseline).

4.  The method of aggregation or how data from each group will be summarized (e.g., mean, median, proportion).

5.  The time-points that will be used for analysis (e.g., 3 months, 6 months) .

![Each outcome has five elements.](images/ma8.png){#fig-ma8 width="55%"}

::: content-box-blue
**Example of eligibility criteria in PICO format**

-   Types of studies: We included all randomised controlled trials (RCTs) and cluster randomised trials. Cross-over trials were also included, though we only used data from the first phase in order to avoid carryover effects.

-   Types of participants: We included trials performed on children and adolescents aged up to 18 years (or at least 80% of the sample within this age range). We included studies performed on participants with any single or mixed long-term physical condition(s) of more than three months duration, who also had depression/subthreshold depression or anxiety, or both. We included studies conducted in hospital and community settings.

-   Types of interventions: **Experimental interventions** included any individual or group-based psychological or psychologically-oriented therapy excluding e-health therapies designed with the primary aim of treating clinical or subthreshold levels of anxiety or depression and tested in children and adolescents with long-term conditions (behaviour therapies such as relaxation training; cognitive behaviour therapies such as CBT; psychodynamic therapies such as psychoanalytic therapy; humanistic therapies such as person-centred psychotherapy; integrative therapies; and systemic therapies such as structural family therapy). **Comparator interventions** included any of the following: Attention placebo (AP); psychological placebo (PP); non-psychological therapies; Treatment-as-usual (TAU).

-   Types of outcome measures: **Primary outcomes** including treatment efficacy (hanges in severity of anxiety and depression symptoms measured), and treatment acceptability (measured via validated scales). **Secondary outcomes** including changes in caseness (remission/response), suicide-related behavior, i.e. number of: a) deaths by suicide, b) suicide attempts and c) episodes of self harm.
:::

**NOTE:** Researchers should consider the risk of **inclusion bias**. For example, review investigators may be aware of the results from various clinical trials when setting inclusion criteria, and may unintentionally include only those trials that support the hypothesis of the systematic review.

## Search information sources

It is recommended to search at least two major bibliographic databases, along with other sources of published and unpublished studies—including backward and forward citation tracking, reviews, consultation with field experts, and grey and non-English literature. Be sure to specify the date each source was last searched.

**NOTE:** Researchers must be cautious of **ascertainment bias**, which occurs when certain studies are more likely to be identified (e.g., published in open-access journals or high-impact international journals) and included in a systematic review — not because they are necessarily better or more relevant, but simply because they are easier to find.

### Search in multiple electronic databases, platforms and engines

Before initiating the search, the team must develop a well-defined search strategy, identify relevant electronic databases, platforms and appropriate search engines, and, if necessary, create access accounts for those databases.

::: content-box-green
**Search algorithm**

1.  Start with simple search strategy.
2.  Run search, and retrieve reports.
3.  Analyze controlled vocabulary terms and keywords of studies fitting the eligibility criteria, and revise strategy.
4.  Re-run search with revised strategy.
5.  Repeat steps 2 through 4 if necessary.
6.  Run optimal search strategy.
7.  Retrieve reports identified with optimal search strategy.
8.  Run the search strategy in multiple databases.
:::

**Major bibliographic databases for RCTs and observational studies:**

-   [MEDLINE/PubMED](https://pubmed.ncbi.nlm.nih.gov/)

-   [EMBASE](https://www.embase.com/)

-   [Cochrane Central Register of Controlled Trials (CENTRAL)](https://www.cochranelibrary.com/)

**National and regional databases (often local language):**

-   [LILACS](https://lilacs.bvsalud.org/en/)

-   [CNKI (China National Knowledge Infrastructure)](https://www.cnki.net/index/)

-   [Korean Medical Database (KMBASE)](https://kmbase.medric.or.kr/)

**Subject-specific databases**

-   [CINAHL (Cumulative Index to Nursing and Allied Health Literature)](https://www.ebsco.com/products/research-databases/cinahl-database)

-   [PsycINFO](https://www.apa.org/pubs/databases/psycinfo/index)

-   [OTseeker (Occupational Therapy Systematic Evaluation of Evidence)](https://www.otseeker.com/)

**Citation databases (platforms)**

-   [Web of Science](https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/)

-   [Web of Science](https://lilacs.bvsalud.org/en/)

-   [Scopus](https://www.scopus.com)

**Search Engines**

-   [Google Scholar](https://scholar.google.com)

**Gray literature databases**

-   [Opengrey](https://opengrey.eu/)

-   [National Guidelines Clearing House](http://www.guideline.gov/)

### Build a high-quality and effective search strategy

When searching for academic papers, selecting the right search terms is crucial for finding relevant studies. These terms are typically derived from key concepts related to the topic of interest. There are two main types of search terms that should be used:

-   **Controlled vocabulary terms:** These are standardized subject terms used by databases to tag articles consistently, regardless of the terminology used by the authors. They help retrieve articles even if they use different words to describe the same concept. For example, MeSH (Medical Subject Headings) – used in PubMed/MEDLINE; Emtree – used in EMBASE; APA Thesaurus of Psychological Index Terms – used in PsycINFO.

-   **Keywords:** These are natural language terms—the words and phrases that researchers might use in titles, abstracts, or full texts.

For systematic review searches, researchers should use both controlled vocabulary and keywords. Using only keywords may result in missing articles that use different terminology, while relying solely on controlled vocabulary could exclude articles that have not yet been indexed or were indexed using outdated terms. Boolean operators (OR, AND, NOT) are crucial, as they allow researchers to combine search terms and help narrow or expand the search results, making them more relevant to the research (@fig-ma1).

![Boolean operators.](images/ma1.png){#fig-ma1 width="35%"}

A comprehensive search for eligible studies is one of the most critical steps in a systematic review. Involvement of an **information specialist** or an experienced **librarian** is essential for developing a robust and effective search strategy. Note that each database has its own way of writing a search strategy.

::: content-box-blue
**Example**

The Cochrane Group's Information Specialist initially searched the Cochrane Common Mental Disorders Controlled Trials Register (CCMD-CTR) (all years to 6 May 2016), using the following terms.

Condition = (anxiety or depressi\* or mood or mutism or neuroses or neurotic or “obsessive compulsive” or panic or *phobi* or psychoneuroses or “stress disorder\*” or “psychological stress” or “school refusal”) and Comorbidity = not empty and Age Group = (child or adolescent)
:::

This search included a more sensitive set of terms to find additional untagged/uncoded reports of RCTs. For example, regarding the age group:

::: content-box-blue
**Example**

\[Age Group\] 1. (child\* or boy\* or girl\* or infant\* or juvenil\* or minors or paediatric\* or pediatric\* or school\* or preschool\* or pre-school\* or kindergarten or nursery or adolesc\* or preadolesc\* or pre-adolesc\* or pubert\* or pubescen\* or prepube\* or pre-pube\* or high-school or teen\* or (young next (adult\* or people or patient\* or men\* or women\* or mother\* or male or female or survivor\* or oCender\* or minorit*)) or youth* or student\* or undergrad\* or college or campus or classroom):ti,ab
:::

### Search citations using both backward and forward citation tracking methods

Citation searching in the context of systematic reviews is a method used to identify relevant literature that may not be captured through standard database searches. It involves tracking how research articles are connected through citations. There are two main types of citation searching: backward citation searching (also known as reference list checking) and forward citation searching.

-   **Backward Citation Search:** A search to find all the references cited within a single article. This search looks backwards in time to trace the prior research and sources that informed the development of the article.

-   **Forward Citation Search:** A search to find all subsequent articles that have cited a specific article. This search looks forward in time to explore how the article has influenced later research and contributed to the broader scholarly conversation.

## Screen and select studies

The search process most often yields a large number of potentially pertinent citations that need to be checked against the pre-specified eligibility criteria. Study selection is a staged process, which needs to be explicit and objective in order to minimize errors and biases.

At least two reviewers should first **screen** records retrieved at title and abstract level working independently (meaning that each reviewer is blinded to the decisions of the other). The initially selected reports will then qualify for **full-text** screening in a similar manner to reach a final decision about studies that will be included in the systematic review. Disagreements at any stage between assessors need to be resolved either with consensus or through arbitration with a senior reviewer.

Automation tools are available to facilitate both the de-duplication of records (i.e., removing duplicate records retrieved from multiple databases) and the study selection process. Software such as [Rayyan](https://www.rayyan.ai/), [Covidence](https://www.covidence.org/), [EPPI-Reviewer](https://eppi.ioe.ac.uk/cms/Default.aspx?tabid=2914), [CADIMA](https://www.cadima.info/), [DistillerSR](https://www.distillersr.com/products/distillersr-systematic-review-software) are specifically designed to support systematic reviews. Additionally, reference management tools like [EndNote](https://endnote.com/), [Mendeley](https://www.mendeley.com/) or [Zotero](https://www.zotero.org/) can also be used to organize and manage citations, including handling duplicates.

The entire process should be documented using a well-designed flow diagram, known as the PRISMA flow chart, which outlines the number of records or studies reviewed at each stage and provides detailed reasons for exclusion (@fig-ma2) [@iddagoda2023].

![PRISMA flow chart.](images/ma2.png){#fig-ma2 width="75%"}

## Collect data form included studies

Having completed the study selection process, the reviewers should proceed with data extraction, during which they obtain all necessary information and outcome data from each eligible study. The data items to be extracted are agreed upon by the review team, and electronic data extraction forms are typically pilot tested on a small sample of eligible studies. This process is again conducted in duplicate to ensure accuracy and data integrity. At this stage unreported information or missing data might be sought through communication with authors of original reports.

During data extraction, reviewers should ensure the use of clear abbreviations, consistent unit conversions, standardized definitions, and concise presentation of information.

## Assess the methodological quality and risk of bias of the included studies

A systematic review is only as good as the studies upon which is built. Evidence and results should be interpreted in light of the quality of the included studies. The quality of the research encompasses how a study has been conducted (methodological quality) and how it has been described (reporting quality and reproducibility). Poor methodological and reporting quality of primary studies included in the review may introduce bias and spurious conclusions [@muka2019; @mantsiou2023].

Therefore, assessment of the methodological quality and risk of bias in the included studies by two independent reviewers is an essential component of a systematic review. For randomized controlled trials Cochrane released the [RoB 2 tool](https://www.riskofbias.info/welcome/rob-2-0-tool) (revised tool for Risk of Bias in randomized trials). Risk of bias is assessed at the outcome level for the following domains: randomization process, deviations from the intended interventions, missing outcome data, measurement of the outcome and selection of the reported result.

After completing all seven bias domains, an overall judgment is made regarding the risk of bias of the study for the outcome under assessment: “low risk of bias”, “some concerns”, or “high risk of bias”. The overall risk-of-bias judgment is derived from the domain-level judgments using a predefined algorithm (@fig-ma3).

![Traffic light plot for ROB 2 tool.](images/ma3.png){#fig-ma3 width="65%"}

 

![Summary barplot for ROB 2 tool.](images/ma6.png){#fig-ma6 width="95%"}

For observational studies evaluation of methodological quality is based on the [ROBINS-I tool V2](https://www.riskofbias.info/welcome/robins-i-v2) (Risk Of Bias in Non-randomized Studies - of Interventions Version 2). Risk of bias is assessed at the outcome level for the following domains: confounding, selection of participants into the study, classification of interventions, deviations from intended interventions, missing data, bias arising from measurement of the outcome, selection of the reported result.

After completing all seven bias domains, an overall judgment is made regarding the risk of bias: "low risk of bias," "moderate risk of bias," "serious risk of bias," or "critical risk of bias." The overall risk-of-bias judgment is derived from the domain-level judgments using a predefined algorithm (@fig-ma4).

![Traffic light plot for ROBINS-I tool.](images/ma4.png){#fig-ma4 width="75%"}

 

![Summary barplot for ROBINS-I tool.](images/ma7.png){#fig-ma7 width="95%"}

## Synthesize the results

One of the most important steps in conducting a systematic review is synthesizing the results from the included primary studies. Authors should present the findings using narrative descriptions and summary tables, grouping the results according to key characteristics such as intervention, population, outcomes, or study design—this is referred to as qualitative synthesis.

When the data are suitable for statistical aggregation, authors may also perform a meta-analysis (quantitative synthesis). In this process, a summary statistic is calculated for each included study—typically a (standardized) mean difference for continuous outcomes, or a risk ratio (RR) or odds ratio (OR) for dichotomous outcomes. An overall effect estimate is then computed as a weighted average of the individual study effects.

> Meta-analysis is an optional component of a systematic review, meaning that not every systematic review includes a meta-analysis. However, every systematic review does include a qualitative synthesis.

It is important to note that every study is unique, and those included in a systematic review will inevitably differ to some extent. Reviewers should assess heterogeneity, which may arise from factors such as participant characteristics, disease severity, concomitant treatments, or methodological quality. Depending on the presence and extent of heterogeneity, two basic meta-analytic models are available: the fixed-effect model and the random-effects model.

## Assess reporting bias

Reviewers should assess the risk of bias in the result of a synthesis (such as meta-analysis) due to missing studies or missing results within studies. Missing studies/results may introduce bias when the decision to publish a study/result is influenced by the observed p-value or magnitude or direction of the effect [@page2021].

For example, studies with statistically non-significant results may not have been submitted for publication (**publication bias**), or particular results that were statistically non-significant may have been omitted from study reports (**selective outcome reporting bias**).

## Grade Quality of Evidence (GRADE approach)

The most common approach to rating the certainty of the evidence is the GRADE (Grading of Recommendations Assessment, Development and Evaluation) framework. GRADE has four levels of evidence ranging from very low quality, which suggests that we are very uncertain about the true estimate, to high quality, which suggests that further research is very unlikely to change our confidence in the estimate of effect [@balshem2011].

Randomized controlled trials provide high quality evidence which may be downgraded for several reasons including high risk of bias, imprecision, inconsistency, indirectness, or concerns about publication bias. Conversely, evidence that includes observational data starts at low quality due to the possibility of residual confounding (i.e., confounding that persists after Adjustment for the putatively measured confounders) (@fig-ma5).

![A summary of GRADE’s approach to rating quality of evidence.](images/ma5.png){#fig-ma5 width="95%"}

The evaluation should be performed independently by two reviewers, while any disagreement should be discussed with a third, independent reviewer.

## Update, report, and submit for publication

When ready to submit the study for publication, if the interval since beginning the search of bibliographic databases is greater than 6–12 months the search should be updated to identify recently published articles [@muka2019].

Reporting guidelines exist to help ensure that systematic reviews with or without meta-analysis are reported with transparency, reproducibility, and comparability. The most commonly used guideline is [PRISMA](https://www.prisma-statement.org/) (Preferred Reporting Items for Systematic Reviews and Meta-Analyses), which assists authors in clearly reporting why the review was conducted, what methods were used, and what the review found.

Finally, additional experts with content expertise may be invited to review and comment on the manuscript (and the published work should acknowledge their assistance). It is still possible to improve the quality of the publication further by appraising the interpretation of the results one last time.
