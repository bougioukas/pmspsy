# Exploratory Factor Analysis {#sec-efa}

```{r}
#| include: false

library(fontawesome)


library(here)
library(tidyverse)


library(readxl)
dat <- read_excel(here("data", "dfGRMS.xlsx"))
```

When we have finished this chapter, we should be able to:

::: {.callout-caution icon="false"}
## Learning objectives

-   Understand when and why to use Principal Component Analysis (PCA), and recognize appropriate data conditions
-   Understand the concept of eigen decomposition
-   Perform PCA through a step-by-step process
-   Interpret component loadings and the proportion of explained variance
-   Extract and interpret component scores for further analysis
:::

## Introduction

As we discussed in the previous chapter, Principal Component Analysis (PCA) is used to reduce the dimensionality of the data while retaining as much variance as possible. In this chapter, Exploratory Factor Analysis (EFA) focuses on identifying underlying **latent** factors that explain the correlations among observed (or manifest) variables, with the aim of uncovering the data's underlying structure.

**EXAMPLE DATA**

We will use the same data from the study by Lewis and Neville on the Gendered Racial Microaggressions Scale for Black Women.

```{r}
#| echo: false
#| label: fig-dfGRMS0
#| fig-cap: Table with raw data.

DT::datatable(dat, extensions = c('Scroller', 'Buttons'), rownames = FALSE,
              options = list(deferRender = F, dom = 'Bt', scrollY = 452, scroller = TRUE, scrollX = T, pageLength = 10, buttons = 
      list(list(
        extend = 'csv',
        filename = 'dfGRMS'
      ))))

```

Lewis and Neville provided support for both a total scale score, consisting of 25 items, and four subscales. Below, we outline the four subscales, including the number of items in each, their abbreviations, and a sample item representing each factor:

-   Assumptions of Beauty and Sexual Objectification (10 items)
    -   Unattractive because of size of butt (Obj1)
    -   Negative comments about size of facial features (Obj2)
    -   Imitated the way they think Black women speak (Obj3)
    -   Someone made me feel unattractive (Obj4)
    -   Negative comment about skin tone (Obj5)
    -   Someone assumed I speak a certain way (Obj6)
    -   Objectified me based on physical features(Obj7)
    -   Someone assumed I have a certain body type (Obj8)
    -   Made a sexually inappropriate comment (Obj9)
    -   Negative comments about my hair when natural (Obj10)
-   Silenced and Marginalized (7 items)
    -   I have felt unheard (Marg1)
    -   My comments have been ignored (Marg2)
    -   Someone challenged my authority (Marg3)
    -   I have been disrespected in workplace (Marg4)
    -   Someone has tried to “put me in my place” (Marg5)
    -   Felt excluded from networking opportunities (Marg6)
    -   Assumed I did not have much to contribute to the conversation (Marg7)
-   Strong Black Woman Stereotype (5 items)
    -   Someone assumed I was sassy and straightforward (Str1)
    -   I have been told that I am too independent (Str2)
    -   Someone made me feel exotic as a Black woman (Str3)
    -   I have been told that I am too assertive (Str4)
    -   Assumed to be a strong Black woman (Str5)
-   Angry Black Woman Stereotype (3 items)
    -   Someone has told me to calm down (Ang1)
    -   Perceived to be “angry Black woman" (Ang2)
    -   Someone accused me of being angry when speaking calm (Ang3)

## Steps in the process of EFA

-   **Prepare the Data:** Create a dataframe where any observed variables (items) are scaled in the same direction (e.g., negatively worded items are reverse scored).

-   **Evaluate Assumptions:** Assess the suitability of the data for EFA using diagnostic tests such as the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and Bartlett’s test of sphericity. Additionally, examine the correlation matrix to ensure that no pair of variables is perfectly correlated (correlation = 1 or -1; singularity). These tests determine whether the correlation matrix is appropriate for factor extraction.

-   **Choose the Extraction Method:** Select an extraction method for factors (e.g., Principal Axis Factoring, Maximum Likelihood, or Maximum Residuals). Principal Axis Factoring is commonly used when you assume that underlying latent factors are driving correlations.

-   **Determine the Number of Factors:** Identify how many components to extract, guided by criteria such as eigenvalues greater than one, scree plot inspection, or parallel analysis. These components often correspond to underlying subscales.

-   **Factor Rotation:** Apply a rotation method to simplify the factor structure. Orthogonal rotation (e.g., Varimax) assumes factors are uncorrelated. Oblique rotation (e.g., Oblimin, Promax) assumes factors are correlated.

-   **Interpret the Factors:** Examine the factor loadings to interpret each factor. Look for variables that load highly on each factor and assign meaningful labels to the factors.

-   **Assess Factor Reliability:** Use Cronbach's Alpha to assess the internal consistency or reliability of the factors. A value above 0.7 indicates good reliability.

-   **Refine the Model:** Based on the results, you may choose to drop items with low factor loadings or revise the number of factors. Ensure that any issues of singularity are addressed by removing highly correlated variables.

-   **Finalize the Factor Solution:** Once the factors are interpretable and reliable, finalize the model and prepare the results for reporting.

## Example of GRMS Stress Appraisal

On the Jamovi top menu navigate to

```{mermaid}
flowchart LR
  A(Analyses) -.-> B(Factor) -.-> C(Exploratory Factor Analysis)
```

as shown below (@fig-mlinear30).

![Select Exploratory Factor Analysis from Factor.](images/fa1.png){#fig-fa1 width="70%"}

The *Exploratory Factor Analysis box* opens (@fig-mlinear30). From the left-hand pane drag all the variables into the *Variables* field on the right-hand side, as shown below (@fig-fa2):

![Exploratory Factor Analysis box options. Drag and drop the variables in the fields on the right-hand side.](images/fa2.png){#fig-fa2 width="65%"}

All variables in the dataset are on the same scale (Likert scale).

### Assumptions

The assumption checks for EFA are similar to those in PCA. However, in Exploratory Factor Analysis, we are also particularly concerned with issues of multicollinearity and singularity in the data. One way to assess this is by examining the determinant of the correlation matrix. If the determinant is smaller than 0.00001, this may indicate that some variables are too highly correlated (multicollinearity), or some variables are perfectly correlated (singularity), which can distort factor extraction.

In our example, the determinant of the correlation matrix can be calculated using a simple line of code in the Rj Editor of Jamovi:

![Calculation of determinant of correlation matrix in RJ Editor.](images/Rj1.png){#fig-Rj1 width="55%"}

```{r, echo=FALSE}
round(det(cor(dat)), 4) 
```

With a value of 0.0075, the determinant is comfortably above the 0.00001 threshold, indicating that our data is appropriate for factor analysis.

If the determinant were below the threshold, we would need to identify and address problematic variables—those that are either overly correlated or not correlated sufficiently with others—and then re-run the diagnostic checks.

### Specify the Number of Components

When researchers lack a clear theoretical framework to guide their analysis, they often adopt an iterative approach, exploring multiple solutions by extracting different numbers of factors. For instance, Lewis and Neville (2015) examined solutions with 2, 3, 4, and 5 factors using parallel analysis to inform their decision. In contrast, this example demonstrates the use of Principal Axis Factoring (PAF), extracting a **four-factor** solution as the chosen model:

-   Factor 1: Assumptions of Beauty and Sexual Objectification
-   Factor 2: Silenced and Marginalized
-   Factor 3: Strong Woman Stereotype
-   Factor 4: Angry Woman Stereotype

### Factor Rotation

We select Principal axis for extraction method and Oblimin for rotation method:

![Select the Oblimin method of rotation.](images/fa3.png){#fig-fa3 width="35%"}

Additionally, we hide loading below 0.23:

![Hide loadings below 0.23.](images/fa9.png){#fig-fa9 width="28%"}

@fig-fa4 shows the loadings of the factors after rotation.

![Factor Loadings using Pricipal axis factoring in combination with Oblimin rotation.](images/fa4.png){#fig-fa4 width="55%"}

In the rotated factor matrix, a few items exhibit cross-loadings, meaning they load significantly on more than one factor:

-  Obj6 loads on both Factor 1 (Objectification) and Factor 4 (Angry), with loadings of 0.43 and 0.25, respectively. While the item shows some association with both factors, its stronger loading on Factor 1 suggests it aligns more closely with the Objectification construct.

-  Marg6 also displays cross-loadings, with loadings of 0.31 on Factor 1 (Objectification) and 0.25 on Factor 2 (Marginalized). Though both values are relatively low, the item may still require closer evaluation to determine its conceptual alignment.

-   Ang1 loads on both Factor 3 (Strong) and Factor 4 (Angry), with loadings of 0.33 and 0.24, respectively. Although neither loading is particularly high, this item should be reviewed in the context of theoretical expectations.

 

Moreover, under the **Additional Output** section, select *Factor summary*, *Factor correlations*, and *Model fit measures*:

![Select Factor summary, correlations, and model fit measures.](images/fa7.png){#fig-fa7 width="25%"}

@fig-fa5 presents the percentage of variance in the variable set that is captured by the derived components after Oblimin rotation.

![Variance with oblique rotation.](images/fa5.png){#fig-fa5 width="50%"}

The SS Loadings column represents the eigenvalues for each component after Oblimin rotation, with Factor 1 explaining 11.2%, factor 2 explaining an additional 8.1%, factor 3 explaining an additional 5.5%, and Factor 4 explaining an additional 3.6%, resulting a cumulative variance of 28.4%. 

Although an explained variance of around 30% may seem modest, it is not uncommon in social science research, particularly when dealing with psychological or behavioral constructs. These constructs are often complex and difficult to measure precisely, which can lead to lower levels of explained variance.

The Inter-Component Correlation Matrix reveals that the four components are positively correlated with each other, with correlations ranging from 0.17 to 0.46 (@fig-fa16).

![Inter-Component Correlation Matrix.](images/fa16.png){#fig-fa16 width="50%"}

 

The chi-square test can be used to assess whether the model fits the data. The null hypothesis for the chi-square test is that the model fits the data perfectly. Therefore, a non-significant chi-square value (e.g., p > 0.05) indicates that the model fits the data reasonably well. However, the chi-square test is sensitive to sample size and non-normal variable distributions. 

In addition to the chi-square test, the root mean square error of approximation (RMSEA) serves as an absolute fit index that takes model complexity into account by incorporating a penalty for lack of parsimony. RMSEA values less than or equal to 0.08 are typically interpreted as good model fit.


![Measures of model fit.](images/fa21.png){#fig-fa21 width="60%"}

In our model: $\chi^2(206)= 189.19$, p = 0.794, which is non-significant and suggests that the model fits the data well. Moreover, the RMSEA value is 0.00, indicating a close fit between the model and the observed data.

These results suggest that the model structure is appropriate, even if the strength of the factors is modest.

 

The path diagram for the factor analysis follows:

```{r, echo=FALSE, warning=FALSE, message=FALSE}

FA1 <- psych::fa(dat, nfactors = 4, fm = "pa", rotate = "oblimin")

colnames(FA1$loadings) <- c("F1", "F2", "F3", "F4")

psych::fa.diagram(FA1, cut = 0, digits = 2, l.cex=0.8,
                  marg=c(0.0, 0.5, 0.5, 0.1), sort = F)
```

It is important to note that the paths point from the factor (oval) to the observed variables (items in squares) illustrating that the factor “causes” the item’s score. Additionally, note that the path diagram includes links with numerical values between components, representing the correlation coefficients among them. 



## Reliability analysis

An important step in establishing the integrity of factors derived from a factor analysis (which will ultimately be presented as subscales of the scale) is to assess their internal consistency as an initial indicator of reliability.

On the Jamovi top menu navigate to

```{mermaid}
flowchart LR
  A(Analyses) -.-> B(Factor) -.-> C(Reliability Analysis)
```

as shown below (@fig-fa8).

![Select Reliability Analysis from Factor.](images/fa8.png){#fig-fa8 width="60%"}

 

We have four derived factors, so we will run Cronbach’s reliability analyis four times-once for each subset of observed variables (items) grouped by the factor analysis.

From the Scale Statistics options, select Cronbach’s $\alpha$ :

![Select Cronbach’s alpha from Scale Statistics.](images/fa10.png){#fig-fa10 width="60%"}

(Note that there is also a menu option for “Reverse Scaled Items” for items that need to have their scores reversed).

 

![Cronbach’s alpha for factor 1.](images/fa17.png){#fig-fa17 width="25%"}

 

![Cronbach’s alpha for factor 2.](images/fa18.png){#fig-fa18 width="25%"}

 

![Cronbach’s alpha for factor 3.](images/fa19.png){#fig-fa19 width="25%"}

 

![Cronbach’s alpha for factor 4.](images/fa20.png){#fig-fa20 width="25%"}

 

Next, based on theoretical guidance, we suppose that Marg6 is included in the second factor (Marginalized) and Ang1 in the fourth factor (Angry). We re-calculate the Cronbach’s alpha.

![Cronbach’s alpha for factor 1.](images/fa11.png){#fig-fa11 width="25%"}

 

![Cronbach’s alpha for factor 2.](images/fa12.png){#fig-fa12 width="25%"}

 

![Cronbach’s alpha for factor 3.](images/fa13.png){#fig-fa13 width="25%"}

 

![Cronbach’s alpha for factor 4.](images/fa14.png){#fig-fa14 width="25%"}

 

The overall Cronbach’s $\alpha$ is:

![Overall Cronbach’s alpha.](images/fa15.png){#fig-fa15 width="25%"}
